<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>paddle2.0高层API实现人脸关键点检测(人脸关键点检测综述_自定义网络_paddleHub_趣味ps) | Personnal Blog of YUAN Tingyi</title><meta name="author" content="YUAN Tingyi"><meta name="copyright" content="YUAN Tingyi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="[toc]  本文包含了：  12345- 人脸关键点检测综述- 人脸关键点检测数据集介绍以及数据处理实现- 自定义网络实现关键点检测- paddleHub实现关键点检测- 基于关键点检测的趣味ps 『深度学习 7 日打卡营·day3』 零基础解锁深度学习神器飞桨框架高层 API，七天时间助你掌握 CV、NLP 领域最火模型及应用。  课程地址  传送门：https:&#x2F;&#x2F;aistudio.baid">
<meta property="og:type" content="article">
<meta property="og:title" content="paddle2.0高层API实现人脸关键点检测(人脸关键点检测综述_自定义网络_paddleHub_趣味ps)">
<meta property="og:url" content="http://example.com/2022/06/01/63e0d330af4f4b7c818e86e056b93ab8/index.html">
<meta property="og:site_name" content="Personnal Blog of YUAN Tingyi">
<meta property="og:description" content="[toc]  本文包含了：  12345- 人脸关键点检测综述- 人脸关键点检测数据集介绍以及数据处理实现- 自定义网络实现关键点检测- paddleHub实现关键点检测- 基于关键点检测的趣味ps 『深度学习 7 日打卡营·day3』 零基础解锁深度学习神器飞桨框架高层 API，七天时间助你掌握 CV、NLP 领域最火模型及应用。  课程地址  传送门：https:&#x2F;&#x2F;aistudio.baid">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/6.jpg">
<meta property="article:published_time" content="2022-06-01T12:47:20.390Z">
<meta property="article:modified_time" content="2022-06-01T12:47:29.637Z">
<meta property="article:author" content="YUAN Tingyi">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/6.jpg"><link rel="shortcut icon" href="/img/favicon-32x32.png"><link rel="canonical" href="http://example.com/2022/06/01/63e0d330af4f4b7c818e86e056b93ab8/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'paddle2.0高层API实现人脸关键点检测(人脸关键点检测综述_自定义网络_paddleHub_趣味ps)',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-06-01 20:47:29'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">28</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/6.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Personnal Blog of YUAN Tingyi</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">paddle2.0高层API实现人脸关键点检测(人脸关键点检测综述_自定义网络_paddleHub_趣味ps)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-06-01T12:47:20.390Z" title="Created 2022-06-01 20:47:20">2022-06-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-06-01T12:47:29.637Z" title="Updated 2022-06-01 20:47:29">2022-06-01</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="paddle2.0高层API实现人脸关键点检测(人脸关键点检测综述_自定义网络_paddleHub_趣味ps)"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>[toc]</p>
<blockquote>
<p>本文包含了：</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- 人脸关键点检测综述</span><br><span class="line">- 人脸关键点检测数据集介绍以及数据处理实现</span><br><span class="line">- 自定义网络实现关键点检测</span><br><span class="line">- paddleHub实现关键点检测</span><br><span class="line">- 基于关键点检测的趣味ps</span><br></pre></td></tr></table></figure>
<p>『深度学习 7 日打卡营·day3』</p>
<p>零基础解锁深度学习神器飞桨框架高层 API，七天时间助你掌握 CV、NLP 领域最火模型及应用。</p>
<ol>
<li>课程地址</li>
</ol>
<p>传送门：<a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/course/introduce/6771">https://aistudio.baidu.com/aistudio/course/introduce/6771</a></p>
<ol start="2">
<li>目标</li>
</ol>
<ul>
<li>掌握深度学习常用模型基础知识</li>
<li>熟练掌握一种国产开源深度学习框架</li>
<li>具备独立完成相关深度学习任务的能力</li>
<li>能用所学为 AI 加一份年味</li>
</ul>
<h2 id="一、问题定义">一、问题定义</h2>
<p>人脸关键点检测，是输入一张人脸图片，模型会返回人脸关键点的一系列坐标，从而定位到人脸的关键信息。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/2aead1c9391422cd84d7d21a1af783ce.png" alt=""></p>
<p>人脸关键点检测是人脸识别和分析领域中的关键一步，它是诸如自动人脸识别、表情分析、三维人脸重建及三维动画等其它人脸相关问题的前提和突破口。近些年来，深度学习方法由于其自动学习及持续学习能力，已被成功应用到了图像识别与分析、语音识别和自然语言处理等很多领域，且在这些方面都带来了很显著的改善。因此，本文针对深度学习方法进行了人脸关键点检测的研究。</p>
<h2 id="人脸关键点检测深度学习方法综述">人脸关键点检测深度学习方法综述</h2>
<h3 id="Deep-Convolutional-Network-Cascade-for-Facial-Point-Detection">Deep Convolutional Network Cascade for Facial Point Detection</h3>
<p>2013 年，Sun 等人首次将 CNN 应用到人脸关键点检测，提出一种级联的 CNN(拥有三个层级)——DCNN(Deep Convolutional Network)，此种方法属于级联回归方法。作者通过精心设计拥有三个层级的级联卷积神经网络，不仅改善初始不当导致陷入局部最优的问题，而且借助于 CNN 强大的特征提取能力，获得更为精准的关键点检测。</p>
<p>如图所示，DCNN 由三个 Level 构成。Level-1 由 3 个 CNN 组成;Level-2 由 10 个 CNN 组成(每个关键点采用两个 CNN);Level-3 同样由 10 个 CNN 组成。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/6b6a9873d6444caa87181de4c1ca2ed5.png" alt=""></p>
<p>DCNN 采用级联回归的思想，从粗到精的逐步得到精确的关键点位置，不仅设计了三级级联的卷积神经网络，还引入局部权值共享机制，从而提升网络的定位性能。最终在数据集 BioID 和 LFPW 上均获得当时最优结果。速度方面，采用 3.3GHz 的 CPU，每 0.12 秒检测一张图片的 5 个关键点。</p>
<h3 id="Extensive-Facial-Landmark-Localization-with-Coarse-to-fine-Convolutional-Network-Cascade">Extensive Facial Landmark Localization with Coarse-to-fine Convolutional Network Cascade</h3>
<p>2013 年，Face++在 DCNN 模型上进行改进，提出从粗到精的人脸关键点检测算法，实现了 68 个人脸关键点的高精度定位。该算法将人脸关键点分为内部关键点和轮廓关键点，内部关键点包含眉毛、眼睛、鼻子、嘴巴共计 51 个关键点，轮廓关键点包含 17 个关键点。</p>
<p>针对内部关键点和外部关键点，该算法并行的采用两个级联的 CNN 进行关键点检测，网络结构如图所示。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/01a425c3fd5887f0f787ae7967886bca.png" alt=""></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/190e43a69ba567e10d7cb2039f5a2edf.png" alt=""></p>
<p>算法主要创新点由以下三点：</p>
<ul>
<li>把人脸的关键点定位问题，划分为内部关键点和轮廓关键点分开预测，有效的避免了 loss 不均衡问题</li>
<li>在内部关键点检测部分，并未像 DCNN 那样每个关键点采用两个 CNN 进行预测，而是每个器官采用一个 CNN 进行预测，从而减少计算量</li>
<li>相比于 DCNN，没有直接采用人脸检测器返回的结果作为输入，而是增加一个边界框检测层(Level-1)，可以大大提高关键点粗定位网络的精度。</li>
</ul>
<p>Face++版 DCNN 首次利用卷积神经网络进行 68 个人脸关键点检测，针对以往人脸关键点检测受人脸检测器影响的问题，作者设计 Level-1 卷积神经网络进一步提取人脸边界框，为人脸关键点检测获得更为准确的人脸位置信息，最终在当年 300-W 挑战赛上获得领先成绩。</p>
<h3 id="TCDCN-Facial-Landmark-Detection-by-Deep-Multi-task-Learning">TCDCN-Facial Landmark Detection by Deep Multi-task Learning</h3>
<p>优点是快和多任务，不仅使用简单的端到端的人脸关键点检测方法，而且能够做到去分辨人脸的喜悦、悲伤、愤怒等分类标签属性，这样跟文章的标题或者说是文章的主题贴合——多任务。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/a2f5609870bb3b145768c4d999646943.png" alt=""></p>
<h3 id="Joint-Face-Detection-and-Alignment-using-Multi-task-Cascaded-Convolutional-Networks">Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks</h3>
<p>2016 年，Zhang 等人提出一种多任务级联卷积神经网络(MTCNN, Multi-task Cascaded Convolutional Networks)用以同时处理人脸检测和人脸关键点定位问题。作者认为人脸检测和人脸关键点检测两个任务之间往往存在着潜在的联系，然而大多数方法都未将两个任务有效的结合起来，本文为了充分利用两任务之间潜在的联系，提出一种多任务级联的人脸检测框架，将人脸检测和人脸关键点检测同时进行。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/b0445220291b2c637beec82cfbccb870.png" alt=""></p>
<p>MTCNN 包含三个级联的多任务卷积神经网络，分别是 Proposal Network (P-Net)、Refine Network (R-Net)、Output Network (O-Net)，每个多任务卷积神经网络均有三个学习任务，分别是人脸分类、边框回归和关键点定位。网络结构如图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/b6e8884f06a3925e30a4a68c29dcc66c.png" alt=""></p>
<p>MTCNN 实现人脸检测和关键点定位分为三个阶段。首先由 P-Net 获得了人脸区域的候选窗口和边界框的回归向量，并用该边界框做回归，对候选窗口进行校准，然后通过非极大值抑制(NMS)来合并高度重叠的候选框。然后将 P-Net 得出的候选框作为输入，输入到 R-Net，R-Net 同样通过边界框回归和 NMS 来去掉那些 false-positive 区域，得到更为准确的候选框;最后，利用 O-Net 输出 5 个关键点的位置。</p>
<h3 id="DAN-Deep-Alignment-Networks">DAN(Deep Alignment Networks)</h3>
<p>2017 年，Kowalski 等人提出一种新的级联深度神经网络——DAN(Deep Alignment Network)，以往级联神经网络输入的是图像的某一部分，与以往不同，DAN 各阶段网络的输入均为整张图片。当网络均采用整张图片作为输入时，DAN 可以有效的克服头部姿态以及初始化带来的问题，从而得到更好的检测效果。之所以 DAN 能将整张图片作为输入，是因为其加入了关键点热图(Landmark Heatmaps)，关键点热图的使用是本文的主要创新点。DAN 基本框架如图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/88517620128a0e38f81d5937b7b10a1e.png" alt=""></p>
<p>DAN 包含多个阶段，每一个阶段含三个输入和一个输出，输入分别是被矫正过的图片、关键点热图和由全连接层生成的特征图，输出是面部形状(Face Shape)。其中，CONNECTION LAYER 的作用是将本阶段得输出进行一系列变换，生成下一阶段所需要的三个输入</p>
<h3 id="PFLD-A-Practical-Facial-Landmark-Detector">PFLD: A Practical Facial Landmark Detector</h3>
<p>这个人脸检测算法 PFLD，全文名称为《PFLD: A Practical Facial Landmark Detector》。作者分别来自天津大学、武汉大学、腾讯 AI 实验室、美国天普大学。该算法对嵌入式设备非常优化，在骁龙 845 的芯片中效率可达 140fps；另外模型大小较小，仅 2.1MB；此外在许多关键点检测的 benchmark 中也取得了相当好的结果。综上，该算法在实际的应用场景中（如低算力的端上设备）有很大的应用空间。</p>
<h4 id="PFLD-模型设计">PFLD 模型设计</h4>
<p>在模型设计上，PFLD 的模型设计上骨干网络没有采用 VGG16、ResNet 等大模型，但是为了增加模型的表达能力，对 Mobilenet 的输出特征进行了结构上的修改。</p>
<h4 id="PFLD-的模型训练策略">PFLD 的模型训练策略</h4>
<p>一开始我们设计的那个简单的网络，采用的损失函数为 MSE，所以为了平衡各种情况的训练数据，我们只能通过增加极端情况下的训练数据、平衡各类情况下的训练数据的比例、控制数据数据的采样形式（非完全随机采样）等方式进行性能调优。</p>
<ul>
<li>
<p>损失函数设计</p>
<p>PFLD 采用了一种很优雅的方式来处理上述各情况样本不均衡的问题，我们先看看其损失函数的设计：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/54ca8b209ee1064728ff2d67770d8272.png" alt=""></p>
<p>上式中 wn 为可调控的权值函数（针对不同的情况选取不同的权值，如正常情况、遮挡情况、暗光情况等等），theta 为人脸姿态的三维欧拉角（K=3），d 为回归的 landmark 和 groundtrue 的度量（一般情况下为 MSE，也可以选 L1 度量）。该损失函数设计的目的是，对于样本量比较大的数据（如正脸，即欧拉角都相对较小的情况），给予一个小的权值，在进行梯度的反向传播的时候，对模型训练的贡献小一些；对于样本量比较少的数据（侧脸、低头、抬头、表情极端），给予一个较大的权值，从而使在进行梯度的反向传播的时候，对模型训练的贡献大一些。该模型的损失函数的设计，非常巧妙的解决了平衡各类情况训练样本不均衡的问题。</p>
</li>
<li>
<p>配合训练的子网络</p>
<p>PFLD 的训练过程中引入了一个子网络，用以监督 PFLD 网络模型的训练。该子网络仅在训练的阶段起作用，在 inference 的时候不参与；该子网络的用处，是对于每一个输入的人脸样本，对该样本进行三维欧拉角的估计，其 groundtruth 由训练数据中的关键点信息进行估计，虽然估计的不够精确，但是作为区分数据分布的依据已经足够了，毕竟还该网络的目的是监督和辅助训练收敛，主要是为了服务关键点检测网络。有一个地方挺有意思的是，该子网络的输入不是训练数据，而是 PFLD 主网络的中间输出，如下图：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/0c38571527622f32d549ddeb0079f8be.png" alt=""></p>
</li>
</ul>
<p>主网络和姿态估计子网络的详细配置如下表：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/10c85cdd527c1b175e90a68fca999343.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 环境导入</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.image <span class="keyword">as</span> mpimg</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">paddle.set_device(<span class="string">&#x27;gpu&#x27;</span>) <span class="comment"># 设置为GPU</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>) <span class="comment"># 忽略 warning</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">paddle.__version__</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;2.0.0&#x27;</span><br></pre></td></tr></table></figure>
<h2 id="二、数据准备">二、数据准备</h2>
<p>传统人脸关键点检测数据库为室内环境下采集的数据库，比如<code>Multi-pie</code>、<code>Feret、Frgc</code>、<code>AR、BioID</code> 等人脸数据库。而现阶段人脸关键点检测数据库通常为复杂环境下采集的数据库.LFPW 人脸数据库有 1132 幅训练人脸图像和 300 幅测试人脸图像，大部分为正面人脸图像，每个人脸标定 29 个关键点。<code>AFLW</code> 人脸数据库包含 25993 幅从 <code>Flickr</code> 采集的人脸图像，每个人脸标定 21 个关键点。<code>COFW</code> 人脸数据库包含 <code>LFPW</code> 人脸数据库训练集中的 845 幅人脸图像以及其他 500 幅遮挡人脸图像，而测试集为 507 幅严重遮挡(同时包含姿态和表情的变化)的人脸图像，每个人脸标定 29 个关键点。<code>MVFW</code> 人脸数据库为多视角人脸数据集，包括 2050 幅训练人脸图像和 450 幅测试人脸图像，每个人脸标定 68 个关键点。<code>OCFW</code> 人脸数据库包含 2951 幅训练人脸图像(均为未遮挡人脸)和 1246 幅测试人脸图像(均为遮挡人脸)，每个人脸标定 68 个关键点。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/099f78bf5bee8885edb93b0b2913460a.png" alt=""></p>
<h3 id="2-1-下载数据集">2.1 下载数据集</h3>
<p>本次实验所采用的数据集来源为 github 的<a target="_blank" rel="noopener" href="https://github.com/udacity/P1_Facial_Keypoints">开源项目</a></p>
<p>目前该数据集已上传到 AI Studio <a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/datasetdetail/69065">人脸关键点识别</a>，加载后可以直接使用下面的命令解压。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 覆盖且不显示</span></span><br><span class="line"><span class="comment"># !unzip -o -q data/data69065/data.zip</span></span><br></pre></td></tr></table></figure>
<p>解压后的数据集结构为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">data/</span><br><span class="line">|—— test</span><br><span class="line">|   |—— Abdel_Aziz_Al-Hakim_00.jpg</span><br><span class="line">    ... ...</span><br><span class="line">|—— test_frames_keypoints.csv</span><br><span class="line">|—— training</span><br><span class="line">|   |—— Abdullah_Gul_10.jpg</span><br><span class="line">    ... ...</span><br><span class="line">|—— training_frames_keypoints.csv</span><br></pre></td></tr></table></figure>
<p>其中，<code>training</code> 和 <code>test</code> 文件夹分别存放训练集和测试集。<code>training_frames_keypoints.csv</code> 和 <code>test_frames_keypoints.csv</code> 存放着训练集和测试集的标签。接下来，我们先来观察一下 <code>training_frames_keypoints.csv</code> 文件，看一下训练集的标签是如何定义的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">key_pts_frame = pd.read_csv(<span class="string">&#x27;data/training_frames_keypoints.csv&#x27;</span>) <span class="comment"># 读取数据集</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Number of images: &#x27;</span>, key_pts_frame.shape[<span class="number">0</span>]) <span class="comment"># 输出数据集大小</span></span><br><span class="line">key_pts_frame.head(<span class="number">5</span>) <span class="comment"># 看前五条数据</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Number of images:  3462</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.dataframe tbody tr th &#123;</span><br><span class="line">    vertical-align: top;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">.dataframe thead th &#123;</span><br><span class="line">    text-align: right;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>...</th>
      <th>126</th>
      <th>127</th>
      <th>128</th>
      <th>129</th>
      <th>130</th>
      <th>131</th>
      <th>132</th>
      <th>133</th>
      <th>134</th>
      <th>135</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Luis_Fonsi_21.jpg</td>
      <td>45.0</td>
      <td>98.0</td>
      <td>47.0</td>
      <td>106.0</td>
      <td>49.0</td>
      <td>110.0</td>
      <td>53.0</td>
      <td>119.0</td>
      <td>56.0</td>
      <td>...</td>
      <td>83.0</td>
      <td>119.0</td>
      <td>90.0</td>
      <td>117.0</td>
      <td>83.0</td>
      <td>119.0</td>
      <td>81.0</td>
      <td>122.0</td>
      <td>77.0</td>
      <td>122.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Lincoln_Chafee_52.jpg</td>
      <td>41.0</td>
      <td>83.0</td>
      <td>43.0</td>
      <td>91.0</td>
      <td>45.0</td>
      <td>100.0</td>
      <td>47.0</td>
      <td>108.0</td>
      <td>51.0</td>
      <td>...</td>
      <td>85.0</td>
      <td>122.0</td>
      <td>94.0</td>
      <td>120.0</td>
      <td>85.0</td>
      <td>122.0</td>
      <td>83.0</td>
      <td>122.0</td>
      <td>79.0</td>
      <td>122.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Valerie_Harper_30.jpg</td>
      <td>56.0</td>
      <td>69.0</td>
      <td>56.0</td>
      <td>77.0</td>
      <td>56.0</td>
      <td>86.0</td>
      <td>56.0</td>
      <td>94.0</td>
      <td>58.0</td>
      <td>...</td>
      <td>79.0</td>
      <td>105.0</td>
      <td>86.0</td>
      <td>108.0</td>
      <td>77.0</td>
      <td>105.0</td>
      <td>75.0</td>
      <td>105.0</td>
      <td>73.0</td>
      <td>105.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Angelo_Reyes_22.jpg</td>
      <td>61.0</td>
      <td>80.0</td>
      <td>58.0</td>
      <td>95.0</td>
      <td>58.0</td>
      <td>108.0</td>
      <td>58.0</td>
      <td>120.0</td>
      <td>58.0</td>
      <td>...</td>
      <td>98.0</td>
      <td>136.0</td>
      <td>107.0</td>
      <td>139.0</td>
      <td>95.0</td>
      <td>139.0</td>
      <td>91.0</td>
      <td>139.0</td>
      <td>85.0</td>
      <td>136.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Kristen_Breitweiser_11.jpg</td>
      <td>58.0</td>
      <td>94.0</td>
      <td>58.0</td>
      <td>104.0</td>
      <td>60.0</td>
      <td>113.0</td>
      <td>62.0</td>
      <td>121.0</td>
      <td>67.0</td>
      <td>...</td>
      <td>92.0</td>
      <td>117.0</td>
      <td>103.0</td>
      <td>118.0</td>
      <td>92.0</td>
      <td>120.0</td>
      <td>88.0</td>
      <td>122.0</td>
      <td>84.0</td>
      <td>122.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 137 columns</p>
</div>
<p>上表中每一行都代表一条数据，其中，第一列是图片的文件名，之后从第 0 列到第 135 列，就是该图的关键点信息。因为每个关键点可以用两个坐标表示，所以 136/2 = 68，就可以看出这个数据集为 68 点人脸关键点数据集。</p>
<p>Tips1: 目前常用的人脸关键点标注，有如下点数的标注</p>
<ul>
<li>5 点</li>
<li>21 点</li>
<li>68 点</li>
<li>98 点</li>
</ul>
<p>Tips2：本次所采用的 68 标注，标注顺序如下：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/0933bdce12e4571b6167f81b9554d59b.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算标签的均值和标准差，用于标签的归一化</span></span><br><span class="line">key_pts_values = key_pts_frame.values[:,<span class="number">1</span>:] <span class="comment"># 取出标签信息</span></span><br><span class="line">data_mean = key_pts_values.mean() <span class="comment"># 计算均值</span></span><br><span class="line">data_std = key_pts_values.std()   <span class="comment"># 计算标准差</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;标签的均值为:&#x27;</span>, data_mean)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;标签的标准差为:&#x27;</span>, data_std)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">标签的均值为: 104.4724870017331</span><br><span class="line">标签的标准差为: 43.17302271754281</span><br></pre></td></tr></table></figure>
<h3 id="2-2-查看图像">2.2 查看图像</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">show_keypoints</span>(<span class="params">image, key_pts</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        image: 图像信息</span></span><br><span class="line"><span class="string">        key_pts: 关键点信息，</span></span><br><span class="line"><span class="string">    展示图片和关键点信息</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    plt.imshow(image.astype(<span class="string">&#x27;uint8&#x27;</span>))  <span class="comment"># 展示图片信息</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(key_pts)//<span class="number">2</span>,):</span><br><span class="line">        plt.scatter(key_pts[i*<span class="number">2</span>], key_pts[i*<span class="number">2</span>+<span class="number">1</span>], s=<span class="number">20</span>, marker=<span class="string">&#x27;.&#x27;</span>, c=<span class="string">&#x27;b&#x27;</span>)  <span class="comment"># 展示关键点信息 蓝色散点</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 展示单条数据</span></span><br><span class="line"></span><br><span class="line">n = <span class="built_in">int</span>(np.random.randint(<span class="number">1</span>, <span class="number">3462</span>, size=<span class="number">1</span>)) <span class="comment"># n为数据在表格中的索引</span></span><br><span class="line">image_name = key_pts_frame.iloc[n, <span class="number">0</span>] <span class="comment"># 获取图像名称</span></span><br><span class="line">key_pts = key_pts_frame.iloc[n, <span class="number">1</span>:].as_matrix() <span class="comment"># 将图像label格式转为numpy.array的格式</span></span><br><span class="line">key_pts = key_pts.astype(<span class="string">&#x27;float&#x27;</span>).reshape(-<span class="number">1</span>) <span class="comment"># 获取图像关键点信息</span></span><br><span class="line"><span class="built_in">print</span>(key_pts.shape)</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>)) <span class="comment"># 展示的图像大小</span></span><br><span class="line">show_keypoints(mpimg.imread(os.path.join(<span class="string">&#x27;data/training/&#x27;</span>, image_name)), key_pts) <span class="comment"># 展示图像与关键点信息</span></span><br><span class="line">plt.show() <span class="comment"># 展示图像</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(136,)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20210206024056525.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzI2Mjgw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="2-3-数据集定义-2">2.3 数据集定义</h3>
<p>使用飞桨框架高层 API 的 <code>paddle.io.Dataset</code> 自定义数据集类，具体可以参考官网文档 <a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/02_paddle2.0_develop/02_data_load_cn.html#id3">自定义数据集</a>。</p>
<h3 id="作业-1：自定义-Dataset，完成人脸关键点数据集定义">作业 1：自定义 Dataset，完成人脸关键点数据集定义</h3>
<p>按照 <code>__init__</code> 中的定义，实现 <code>__getitem__</code> 和 <code>__len__</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按照Dataset的使用规范，构建人脸关键点数据集</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> paddle.io <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FacialKeypointsDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="comment"># 人脸关键点数据集</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    步骤一：继承paddle.io.Dataset类</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, csv_file, root_dir, transform=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        步骤二：实现构造函数，定义数据集大小</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            csv_file (string): 带标注的csv文件路径</span></span><br><span class="line"><span class="string">            root_dir (string): 图片存储的文件夹路径</span></span><br><span class="line"><span class="string">            transform (callable, optional): 应用于图像上的数据处理方法</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.key_pts_frame = pd.read_csv(csv_file) <span class="comment"># 读取csv文件</span></span><br><span class="line">        self.root_dir = root_dir <span class="comment"># 获取图片文件夹路径</span></span><br><span class="line">        self.transform = transform <span class="comment"># 获取 transform 方法</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        步骤三：实现__getitem__方法，定义指定index时如何获取数据，并返回单条数据（训练数据，对应的标签）</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 实现 __getitem__</span></span><br><span class="line">        image_dir = os.path.join(self.root_dir, self.key_pts_frame.iloc[idx, <span class="number">0</span>])</span><br><span class="line">        <span class="comment"># 读取图像</span></span><br><span class="line">        image = mpimg.imread(image_dir)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 去除图像\alpha通道</span></span><br><span class="line">        <span class="keyword">if</span> image.shape[-<span class="number">1</span>] == <span class="number">4</span>:</span><br><span class="line">            image = image[..., <span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 读取关键点</span></span><br><span class="line">        key_pts = self.key_pts_frame.iloc[idx, <span class="number">1</span>:].as_matrix()  <span class="comment"># 不读取name</span></span><br><span class="line">        key_pts = key_pts.astype(<span class="string">&#x27;float&#x27;</span>).reshape(-<span class="number">1</span>)  <span class="comment"># [136, 1]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 数据增强</span></span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            image, key_pts = self.transform([image, key_pts])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># to_numpy</span></span><br><span class="line">        image = np.array(image, dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">        key_pts = np.array(key_pts, dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> image, key_pts</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        步骤四：实现__len__方法，返回数据集总数目</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 实现 __len__</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.key_pts_frame)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="2-4-训练集可视化">2.4 训练集可视化</h3>
<p>实例化数据集并显示一些图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建一个数据集类</span></span><br><span class="line">face_dataset = FacialKeypointsDataset(csv_file=<span class="string">&#x27;data/training_frames_keypoints.csv&#x27;</span>,</span><br><span class="line">                                      root_dir=<span class="string">&#x27;data/training/&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出数据集大小</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;数据集大小为: &#x27;</span>, <span class="built_in">len</span>(face_dataset))</span><br><span class="line"><span class="comment"># 根据 face_dataset 可视化数据集</span></span><br><span class="line">num_to_display = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_to_display):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义图片大小</span></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 随机选择图片</span></span><br><span class="line">    rand_i = np.random.randint(<span class="number">0</span>, <span class="built_in">len</span>(face_dataset))</span><br><span class="line">    sample = face_dataset[rand_i]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出图片大小和关键点的数量</span></span><br><span class="line">    <span class="built_in">print</span>(i, sample[<span class="number">0</span>].shape, sample[<span class="number">1</span>].shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置图片打印信息</span></span><br><span class="line">    ax = plt.subplot(<span class="number">1</span>, num_to_display, i + <span class="number">1</span>)</span><br><span class="line">    ax.set_title(<span class="string">&#x27;Sample #&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出图片</span></span><br><span class="line">    show_keypoints(sample[<span class="number">0</span>], sample[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">数据集大小为:  3462</span><br><span class="line">0 (300, 250, 3) (136,)</span><br><span class="line">1 (140, 142, 3) (136,)</span><br><span class="line">2 (208, 174, 3) (136,)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20210206024109247.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzI2Mjgw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>
<img src="https://img-blog.csdnimg.cn/20210206024112700.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzI2Mjgw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/20210206024116618.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzI2Mjgw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>上述代码虽然完成了数据集的定义，但是还有一些问题，如：</p>
<ul>
<li>每张图像的大小不一样，图像大小需要统一以适配网络输入要求</li>
<li>图像格式需要适配模型的格式输入要求</li>
<li>数据量比较小，没有进行数据增强</li>
</ul>
<p>这些问题都会影响模型最终的性能，所以需要对数据进行预处理。</p>
<h3 id="2-5-Transforms">2.5 Transforms</h3>
<p>对图像进行预处理，包括灰度化、归一化、重新设置尺寸、随机裁剪，修改通道格式等等，以满足数据要求；每一类的功能如下：</p>
<ul>
<li>灰度化：丢弃颜色信息，保留图像边缘信息；识别算法对于颜色的依赖性不强，加上颜色后鲁棒性会下降，而且灰度化图像维度下降（3-&gt;1），保留梯度的同时会加快计算。</li>
<li>归一化：加快收敛</li>
<li>重新设置尺寸：数据增强</li>
<li>随机裁剪：数据增强</li>
<li>修改通道格式：改为模型需要的结构</li>
</ul>
<h3 id="作业-2：实现自定义-ToCHW">作业 2：实现自定义 ToCHW</h3>
<p>实现数据预处理方法 ToCHW</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标准化自定义 transform 方法</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TransformAPI</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    步骤一：继承 object 类</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, data</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        步骤二：在 __call__ 中定义数据处理方法</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        processed_data = data</span><br><span class="line">        <span class="keyword">return</span>  processed_data</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle.vision.transforms.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GrayNormalize</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="comment"># 将图片变为灰度图，并将其值放缩到[0, 1]</span></span><br><span class="line">    <span class="comment"># 将 label 放缩到 [-1, 1] 之间</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, data</span>):</span><br><span class="line">        image = data[<span class="number">0</span>]   <span class="comment"># 获取图片</span></span><br><span class="line">        key_pts = data[<span class="number">1</span>] <span class="comment"># 获取标签</span></span><br><span class="line"></span><br><span class="line">        image_copy = np.copy(image)</span><br><span class="line">        key_pts_copy = np.copy(key_pts)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 灰度化图片</span></span><br><span class="line">        gray_scale = paddle.vision.transforms.Grayscale(num_output_channels=<span class="number">3</span>)</span><br><span class="line">        image_copy = gray_scale(image_copy)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将图片值放缩到 [0, 1]</span></span><br><span class="line">        image_copy = image_copy / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将坐标点放缩到 [-1, 1]</span></span><br><span class="line">        mean = data_mean <span class="comment"># 获取标签均值</span></span><br><span class="line">        std = data_std   <span class="comment"># 获取标签标准差</span></span><br><span class="line">        key_pts_copy = (key_pts_copy - mean)/std</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> image_copy, key_pts_copy</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Resize</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="comment"># 将输入图像调整为指定大小</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, output_size</span>):</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(output_size, (<span class="built_in">int</span>, <span class="built_in">tuple</span>))</span><br><span class="line">        self.output_size = output_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, data</span>):</span><br><span class="line"></span><br><span class="line">        image = data[<span class="number">0</span>]    <span class="comment"># 获取图片</span></span><br><span class="line">        key_pts = data[<span class="number">1</span>]  <span class="comment"># 获取标签</span></span><br><span class="line"></span><br><span class="line">        image_copy = np.copy(image)</span><br><span class="line">        key_pts_copy = np.copy(key_pts)</span><br><span class="line"></span><br><span class="line">        h, w = image_copy.shape[:<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(self.output_size, <span class="built_in">int</span>):</span><br><span class="line">            <span class="keyword">if</span> h &gt; w:</span><br><span class="line">                new_h, new_w = self.output_size * h / w, self.output_size</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                new_h, new_w = self.output_size, self.output_size * w / h</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            new_h, new_w = self.output_size</span><br><span class="line"></span><br><span class="line">        new_h, new_w = <span class="built_in">int</span>(new_h), <span class="built_in">int</span>(new_w)</span><br><span class="line"></span><br><span class="line">        img = F.resize(image_copy, (new_h, new_w))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># scale the pts, too</span></span><br><span class="line">        key_pts_copy[::<span class="number">2</span>] = key_pts_copy[::<span class="number">2</span>] * new_w / w</span><br><span class="line">        key_pts_copy[<span class="number">1</span>::<span class="number">2</span>] = key_pts_copy[<span class="number">1</span>::<span class="number">2</span>] * new_h / h</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> img, key_pts_copy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RandomCrop</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="comment"># 随机位置裁剪输入的图像</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, output_size</span>):</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(output_size, (<span class="built_in">int</span>, <span class="built_in">tuple</span>))</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(output_size, <span class="built_in">int</span>):</span><br><span class="line">            self.output_size = (output_size, output_size)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">assert</span> <span class="built_in">len</span>(output_size) == <span class="number">2</span></span><br><span class="line">            self.output_size = output_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, data</span>):</span><br><span class="line">        image = data[<span class="number">0</span>]</span><br><span class="line">        key_pts = data[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        image_copy = np.copy(image)</span><br><span class="line">        key_pts_copy = np.copy(key_pts)</span><br><span class="line"></span><br><span class="line">        h, w = image_copy.shape[:<span class="number">2</span>]</span><br><span class="line">        new_h, new_w = self.output_size</span><br><span class="line"></span><br><span class="line">        top = np.random.randint(<span class="number">0</span>, h - new_h)</span><br><span class="line">        left = np.random.randint(<span class="number">0</span>, w - new_w)</span><br><span class="line"></span><br><span class="line">        image_copy = image_copy[top: top + new_h,</span><br><span class="line">                      left: left + new_w]</span><br><span class="line"></span><br><span class="line">        key_pts_copy[::<span class="number">2</span>] = key_pts_copy[::<span class="number">2</span>] - left</span><br><span class="line">        key_pts_copy[<span class="number">1</span>::<span class="number">2</span>] = key_pts_copy[<span class="number">1</span>::<span class="number">2</span>] - top</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> image_copy, key_pts_copy</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ToCHW</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="comment"># 将图像的格式由HWC改为CHW</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, data</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 实现ToCHW，可以使用 paddle.vision.transforms.Transpose 实现</span></span><br><span class="line">        image = data[<span class="number">0</span>]</span><br><span class="line">        key_pts = data[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        transpose = paddle.vision.transforms.Transpose((<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)) <span class="comment"># [h w c] -&gt; [c h w]</span></span><br><span class="line">        image = transpose(image)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> image, key_pts</span><br></pre></td></tr></table></figure>
<p>看一下每种图像预处理方法的的效果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle.vision.transforms <span class="keyword">as</span> T</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试 Resize</span></span><br><span class="line">resize = Resize(<span class="number">256</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试 RandomCrop</span></span><br><span class="line">random_crop = RandomCrop(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试 GrayNormalize</span></span><br><span class="line">norm = GrayNormalize()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试 Resize + RandomCrop，图像大小变到250*250， 然后截取出224*224的图像块</span></span><br><span class="line">composed = paddle.vision.transforms.Compose([Resize(<span class="number">250</span>), RandomCrop(<span class="number">224</span>)])</span><br><span class="line"></span><br><span class="line">test_num = <span class="number">800</span> <span class="comment"># 测试的数据下标</span></span><br><span class="line">data = face_dataset[test_num]</span><br><span class="line"></span><br><span class="line">transforms = &#123;<span class="string">&#x27;None&#x27;</span>: <span class="literal">None</span>,</span><br><span class="line">              <span class="string">&#x27;norm&#x27;</span>: norm,</span><br><span class="line">              <span class="string">&#x27;random_crop&#x27;</span>: random_crop,</span><br><span class="line">              <span class="string">&#x27;resize&#x27;</span>: resize,</span><br><span class="line">              <span class="string">&#x27;composed&#x27;</span>: composed&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, func_name <span class="keyword">in</span> <span class="built_in">enumerate</span>(transforms):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义图片大小</span></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">40</span>, <span class="number">40</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理图片</span></span><br><span class="line">    <span class="keyword">if</span> transforms[func_name] != <span class="literal">None</span>:</span><br><span class="line">        transformed_sample = transforms[func_name](data)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        transformed_sample = data</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置图片打印信息</span></span><br><span class="line">    ax = plt.subplot(<span class="number">1</span>, <span class="number">5</span>, i + <span class="number">1</span>)</span><br><span class="line">    ax.set_title(<span class="string">&#x27; Transform is #&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(func_name))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出图片</span></span><br><span class="line">    show_keypoints(transformed_sample[<span class="number">0</span>], transformed_sample[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20210206024137350.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzI2Mjgw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>
<img src="https://img-blog.csdnimg.cn/20210206024141275.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzI2Mjgw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>
<img src="https://img-blog.csdnimg.cn/20210206024144318.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzI2Mjgw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>
<img src="https://img-blog.csdnimg.cn/20210206024147748.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzI2Mjgw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>
<img src="https://img-blog.csdnimg.cn/20210206024150688.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzI2Mjgw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="2-6-使用数据预处理的方式完成数据定义">2.6 使用数据预处理的方式完成数据定义</h3>
<p>让我们将 <code>Resize、RandomCrop、GrayNormalize、ToCHW</code> 应用于新的数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> paddle.vision.transforms <span class="keyword">import</span> Compose</span><br><span class="line"></span><br><span class="line">data_transform = Compose([Resize(<span class="number">256</span>), RandomCrop(<span class="number">224</span>), GrayNormalize(), ToCHW()])</span><br><span class="line"></span><br><span class="line"><span class="comment"># create the transformed dataset</span></span><br><span class="line">train_dataset = FacialKeypointsDataset(csv_file=<span class="string">&#x27;data/training_frames_keypoints.csv&#x27;</span>,</span><br><span class="line">                                       root_dir=<span class="string">&#x27;data/training/&#x27;</span>,</span><br><span class="line">                                       transform=data_transform)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Number of train dataset images: &#x27;</span>, <span class="built_in">len</span>(train_dataset))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    sample = train_dataset[i]</span><br><span class="line">    <span class="built_in">print</span>(i, sample[<span class="number">0</span>].shape, sample[<span class="number">1</span>].shape)</span><br><span class="line"></span><br><span class="line">test_dataset = FacialKeypointsDataset(csv_file=<span class="string">&#x27;data/test_frames_keypoints.csv&#x27;</span>,</span><br><span class="line">                                      root_dir=<span class="string">&#x27;data/test/&#x27;</span>,</span><br><span class="line">                                      transform=data_transform)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Number of test dataset images: &#x27;</span>, <span class="built_in">len</span>(test_dataset))</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Number of train dataset images:  3462</span><br><span class="line">0 (3, 224, 224) (136,)</span><br><span class="line">1 (3, 224, 224) (136,)</span><br><span class="line">Number of test dataset images:  770</span><br></pre></td></tr></table></figure>
<h2 id="3、模型组建">3、模型组建</h2>
<h3 id="3-1-组网可以很简单">3.1 组网可以很简单</h3>
<p>根据前文的分析可知，人脸关键点检测和分类，可以使用同样的网络结构，如 LeNet、Resnet50 等完成特征的提取，只是在原来的基础上，需要修改模型的最后部分，将输出调整为 人脸关键点的数量*2，即每个人脸关键点的横坐标与纵坐标，就可以完成人脸关键点检测任务了，具体可以见下面的代码，也可以参考官网案例:<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/tutorial/cv_case/landmark_detection/landmark_detection.html">人脸关键点检测</a></p>
<p>网络结构如下：<br>
<img src="https://img-blog.csdnimg.cn/img_convert/90300cac29d44951b09d4ff8cf468a23.png" alt=""></p>
<h3 id="作业-3：根据上图，实现网络结构">作业 3：根据上图，实现网络结构</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> paddle.vision.models <span class="keyword">import</span> resnet50</span><br><span class="line"></span><br><span class="line"><span class="comment"># Sequential继承</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleNet</span>(paddle.nn.Sequential):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 实现 __init__</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, key_pts</span>):</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>(SimpleNet, self).__init__(</span><br><span class="line">            paddle.vision.models.resnet50(pretrained=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">1000</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, key_pts*<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="3-2-网络结构可视化">3.2 网络结构可视化</h3>
<p>使用<code>model.summary</code>可视化网络结构。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = paddle.Model(SimpleNet(key_pts=<span class="number">68</span>))</span><br><span class="line">model.summary((-<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br></pre></td><td class="code"><pre><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">   Layer (type)         Input Shape          Output Shape         Param #</span><br><span class="line">===============================================================================</span><br><span class="line">    Conv2D-107       [[1, 3, 224, 224]]   [1, 64, 112, 112]        9,408</span><br><span class="line">  BatchNorm2D-107   [[1, 64, 112, 112]]   [1, 64, 112, 112]         256</span><br><span class="line">      ReLU-37       [[1, 64, 112, 112]]   [1, 64, 112, 112]          0</span><br><span class="line">    MaxPool2D-3     [[1, 64, 112, 112]]    [1, 64, 56, 56]           0</span><br><span class="line">    Conv2D-109       [[1, 64, 56, 56]]     [1, 64, 56, 56]         4,096</span><br><span class="line">  BatchNorm2D-109    [[1, 64, 56, 56]]     [1, 64, 56, 56]          256</span><br><span class="line">      ReLU-38        [[1, 256, 56, 56]]    [1, 256, 56, 56]          0</span><br><span class="line">    Conv2D-110       [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864</span><br><span class="line">  BatchNorm2D-110    [[1, 64, 56, 56]]     [1, 64, 56, 56]          256</span><br><span class="line">    Conv2D-111       [[1, 64, 56, 56]]     [1, 256, 56, 56]       16,384</span><br><span class="line">  BatchNorm2D-111    [[1, 256, 56, 56]]    [1, 256, 56, 56]        1,024</span><br><span class="line">    Conv2D-108       [[1, 64, 56, 56]]     [1, 256, 56, 56]       16,384</span><br><span class="line">  BatchNorm2D-108    [[1, 256, 56, 56]]    [1, 256, 56, 56]        1,024</span><br><span class="line">BottleneckBlock-33   [[1, 64, 56, 56]]     [1, 256, 56, 56]          0</span><br><span class="line">    Conv2D-112       [[1, 256, 56, 56]]    [1, 64, 56, 56]        16,384</span><br><span class="line">  BatchNorm2D-112    [[1, 64, 56, 56]]     [1, 64, 56, 56]          256</span><br><span class="line">      ReLU-39        [[1, 256, 56, 56]]    [1, 256, 56, 56]          0</span><br><span class="line">    Conv2D-113       [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864</span><br><span class="line">  BatchNorm2D-113    [[1, 64, 56, 56]]     [1, 64, 56, 56]          256</span><br><span class="line">    Conv2D-114       [[1, 64, 56, 56]]     [1, 256, 56, 56]       16,384</span><br><span class="line">  BatchNorm2D-114    [[1, 256, 56, 56]]    [1, 256, 56, 56]        1,024</span><br><span class="line">BottleneckBlock-34   [[1, 256, 56, 56]]    [1, 256, 56, 56]          0</span><br><span class="line">    Conv2D-115       [[1, 256, 56, 56]]    [1, 64, 56, 56]        16,384</span><br><span class="line">  BatchNorm2D-115    [[1, 64, 56, 56]]     [1, 64, 56, 56]          256</span><br><span class="line">      ReLU-40        [[1, 256, 56, 56]]    [1, 256, 56, 56]          0</span><br><span class="line">    Conv2D-116       [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864</span><br><span class="line">  BatchNorm2D-116    [[1, 64, 56, 56]]     [1, 64, 56, 56]          256</span><br><span class="line">    Conv2D-117       [[1, 64, 56, 56]]     [1, 256, 56, 56]       16,384</span><br><span class="line">  BatchNorm2D-117    [[1, 256, 56, 56]]    [1, 256, 56, 56]        1,024</span><br><span class="line">BottleneckBlock-35   [[1, 256, 56, 56]]    [1, 256, 56, 56]          0</span><br><span class="line">    Conv2D-119       [[1, 256, 56, 56]]    [1, 128, 56, 56]       32,768</span><br><span class="line">  BatchNorm2D-119    [[1, 128, 56, 56]]    [1, 128, 56, 56]         512</span><br><span class="line">      ReLU-41        [[1, 512, 28, 28]]    [1, 512, 28, 28]          0</span><br><span class="line">    Conv2D-120       [[1, 128, 56, 56]]    [1, 128, 28, 28]       147,456</span><br><span class="line">  BatchNorm2D-120    [[1, 128, 28, 28]]    [1, 128, 28, 28]         512</span><br><span class="line">    Conv2D-121       [[1, 128, 28, 28]]    [1, 512, 28, 28]       65,536</span><br><span class="line">  BatchNorm2D-121    [[1, 512, 28, 28]]    [1, 512, 28, 28]        2,048</span><br><span class="line">    Conv2D-118       [[1, 256, 56, 56]]    [1, 512, 28, 28]       131,072</span><br><span class="line">  BatchNorm2D-118    [[1, 512, 28, 28]]    [1, 512, 28, 28]        2,048</span><br><span class="line">BottleneckBlock-36   [[1, 256, 56, 56]]    [1, 512, 28, 28]          0</span><br><span class="line">    Conv2D-122       [[1, 512, 28, 28]]    [1, 128, 28, 28]       65,536</span><br><span class="line">  BatchNorm2D-122    [[1, 128, 28, 28]]    [1, 128, 28, 28]         512</span><br><span class="line">      ReLU-42        [[1, 512, 28, 28]]    [1, 512, 28, 28]          0</span><br><span class="line">    Conv2D-123       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456</span><br><span class="line">  BatchNorm2D-123    [[1, 128, 28, 28]]    [1, 128, 28, 28]         512</span><br><span class="line">    Conv2D-124       [[1, 128, 28, 28]]    [1, 512, 28, 28]       65,536</span><br><span class="line">  BatchNorm2D-124    [[1, 512, 28, 28]]    [1, 512, 28, 28]        2,048</span><br><span class="line">BottleneckBlock-37   [[1, 512, 28, 28]]    [1, 512, 28, 28]          0</span><br><span class="line">    Conv2D-125       [[1, 512, 28, 28]]    [1, 128, 28, 28]       65,536</span><br><span class="line">  BatchNorm2D-125    [[1, 128, 28, 28]]    [1, 128, 28, 28]         512</span><br><span class="line">      ReLU-43        [[1, 512, 28, 28]]    [1, 512, 28, 28]          0</span><br><span class="line">    Conv2D-126       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456</span><br><span class="line">  BatchNorm2D-126    [[1, 128, 28, 28]]    [1, 128, 28, 28]         512</span><br><span class="line">    Conv2D-127       [[1, 128, 28, 28]]    [1, 512, 28, 28]       65,536</span><br><span class="line">  BatchNorm2D-127    [[1, 512, 28, 28]]    [1, 512, 28, 28]        2,048</span><br><span class="line">BottleneckBlock-38   [[1, 512, 28, 28]]    [1, 512, 28, 28]          0</span><br><span class="line">    Conv2D-128       [[1, 512, 28, 28]]    [1, 128, 28, 28]       65,536</span><br><span class="line">  BatchNorm2D-128    [[1, 128, 28, 28]]    [1, 128, 28, 28]         512</span><br><span class="line">      ReLU-44        [[1, 512, 28, 28]]    [1, 512, 28, 28]          0</span><br><span class="line">    Conv2D-129       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456</span><br><span class="line">  BatchNorm2D-129    [[1, 128, 28, 28]]    [1, 128, 28, 28]         512</span><br><span class="line">    Conv2D-130       [[1, 128, 28, 28]]    [1, 512, 28, 28]       65,536</span><br><span class="line">  BatchNorm2D-130    [[1, 512, 28, 28]]    [1, 512, 28, 28]        2,048</span><br><span class="line">BottleneckBlock-39   [[1, 512, 28, 28]]    [1, 512, 28, 28]          0</span><br><span class="line">    Conv2D-132       [[1, 512, 28, 28]]    [1, 256, 28, 28]       131,072</span><br><span class="line">  BatchNorm2D-132    [[1, 256, 28, 28]]    [1, 256, 28, 28]        1,024</span><br><span class="line">      ReLU-45       [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">    Conv2D-133       [[1, 256, 28, 28]]    [1, 256, 14, 14]       589,824</span><br><span class="line">  BatchNorm2D-133    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">    Conv2D-134       [[1, 256, 14, 14]]   [1, 1024, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-134   [[1, 1024, 14, 14]]   [1, 1024, 14, 14]        4,096</span><br><span class="line">    Conv2D-131       [[1, 512, 28, 28]]   [1, 1024, 14, 14]       524,288</span><br><span class="line">  BatchNorm2D-131   [[1, 1024, 14, 14]]   [1, 1024, 14, 14]        4,096</span><br><span class="line">BottleneckBlock-40   [[1, 512, 28, 28]]   [1, 1024, 14, 14]          0</span><br><span class="line">    Conv2D-135      [[1, 1024, 14, 14]]    [1, 256, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-135    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">      ReLU-46       [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">    Conv2D-136       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824</span><br><span class="line">  BatchNorm2D-136    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">    Conv2D-137       [[1, 256, 14, 14]]   [1, 1024, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-137   [[1, 1024, 14, 14]]   [1, 1024, 14, 14]        4,096</span><br><span class="line">BottleneckBlock-41  [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">    Conv2D-138      [[1, 1024, 14, 14]]    [1, 256, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-138    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">      ReLU-47       [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">    Conv2D-139       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824</span><br><span class="line">  BatchNorm2D-139    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">    Conv2D-140       [[1, 256, 14, 14]]   [1, 1024, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-140   [[1, 1024, 14, 14]]   [1, 1024, 14, 14]        4,096</span><br><span class="line">BottleneckBlock-42  [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">    Conv2D-141      [[1, 1024, 14, 14]]    [1, 256, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-141    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">      ReLU-48       [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">    Conv2D-142       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824</span><br><span class="line">  BatchNorm2D-142    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">    Conv2D-143       [[1, 256, 14, 14]]   [1, 1024, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-143   [[1, 1024, 14, 14]]   [1, 1024, 14, 14]        4,096</span><br><span class="line">BottleneckBlock-43  [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">    Conv2D-144      [[1, 1024, 14, 14]]    [1, 256, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-144    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">      ReLU-49       [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">    Conv2D-145       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824</span><br><span class="line">  BatchNorm2D-145    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">    Conv2D-146       [[1, 256, 14, 14]]   [1, 1024, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-146   [[1, 1024, 14, 14]]   [1, 1024, 14, 14]        4,096</span><br><span class="line">BottleneckBlock-44  [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">    Conv2D-147      [[1, 1024, 14, 14]]    [1, 256, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-147    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">      ReLU-50       [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">    Conv2D-148       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824</span><br><span class="line">  BatchNorm2D-148    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">    Conv2D-149       [[1, 256, 14, 14]]   [1, 1024, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-149   [[1, 1024, 14, 14]]   [1, 1024, 14, 14]        4,096</span><br><span class="line">BottleneckBlock-45  [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">    Conv2D-151      [[1, 1024, 14, 14]]    [1, 512, 14, 14]       524,288</span><br><span class="line">  BatchNorm2D-151    [[1, 512, 14, 14]]    [1, 512, 14, 14]        2,048</span><br><span class="line">      ReLU-51        [[1, 2048, 7, 7]]     [1, 2048, 7, 7]           0</span><br><span class="line">    Conv2D-152       [[1, 512, 14, 14]]     [1, 512, 7, 7]       2,359,296</span><br><span class="line">  BatchNorm2D-152     [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048</span><br><span class="line">    Conv2D-153        [[1, 512, 7, 7]]     [1, 2048, 7, 7]       1,048,576</span><br><span class="line">  BatchNorm2D-153    [[1, 2048, 7, 7]]     [1, 2048, 7, 7]         8,192</span><br><span class="line">    Conv2D-150      [[1, 1024, 14, 14]]    [1, 2048, 7, 7]       2,097,152</span><br><span class="line">  BatchNorm2D-150    [[1, 2048, 7, 7]]     [1, 2048, 7, 7]         8,192</span><br><span class="line">BottleneckBlock-46  [[1, 1024, 14, 14]]    [1, 2048, 7, 7]           0</span><br><span class="line">    Conv2D-154       [[1, 2048, 7, 7]]      [1, 512, 7, 7]       1,048,576</span><br><span class="line">  BatchNorm2D-154     [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048</span><br><span class="line">      ReLU-52        [[1, 2048, 7, 7]]     [1, 2048, 7, 7]           0</span><br><span class="line">    Conv2D-155        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296</span><br><span class="line">  BatchNorm2D-155     [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048</span><br><span class="line">    Conv2D-156        [[1, 512, 7, 7]]     [1, 2048, 7, 7]       1,048,576</span><br><span class="line">  BatchNorm2D-156    [[1, 2048, 7, 7]]     [1, 2048, 7, 7]         8,192</span><br><span class="line">BottleneckBlock-47   [[1, 2048, 7, 7]]     [1, 2048, 7, 7]           0</span><br><span class="line">    Conv2D-157       [[1, 2048, 7, 7]]      [1, 512, 7, 7]       1,048,576</span><br><span class="line">  BatchNorm2D-157     [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048</span><br><span class="line">      ReLU-53        [[1, 2048, 7, 7]]     [1, 2048, 7, 7]           0</span><br><span class="line">    Conv2D-158        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296</span><br><span class="line">  BatchNorm2D-158     [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048</span><br><span class="line">    Conv2D-159        [[1, 512, 7, 7]]     [1, 2048, 7, 7]       1,048,576</span><br><span class="line">  BatchNorm2D-159    [[1, 2048, 7, 7]]     [1, 2048, 7, 7]         8,192</span><br><span class="line">BottleneckBlock-48   [[1, 2048, 7, 7]]     [1, 2048, 7, 7]           0</span><br><span class="line">AdaptiveAvgPool2D-3  [[1, 2048, 7, 7]]     [1, 2048, 1, 1]           0</span><br><span class="line">     Linear-7           [[1, 2048]]           [1, 1000]          2,049,000</span><br><span class="line">     ResNet-3        [[1, 3, 224, 224]]       [1, 1000]              0</span><br><span class="line">     Linear-8           [[1, 1000]]            [1, 512]           512,512</span><br><span class="line">      ReLU-54            [[1, 512]]            [1, 512]              0</span><br><span class="line">     Linear-9            [[1, 512]]            [1, 136]           69,768</span><br><span class="line">===============================================================================</span><br><span class="line">Total params: 26,192,432</span><br><span class="line">Trainable params: 26,086,192</span><br><span class="line">Non-trainable params: 106,240</span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">Input size (MB): 0.57</span><br><span class="line">Forward/backward pass size (MB): 261.50</span><br><span class="line">Params size (MB): 99.92</span><br><span class="line">Estimated Total Size (MB): 361.99</span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;&#x27;total_params&#x27;: 26192432, &#x27;trainable_params&#x27;: 26086192&#125;</span><br></pre></td></tr></table></figure>
<h2 id="四、模型训练">四、模型训练</h2>
<h3 id="4-1-模型配置">4.1 模型配置</h3>
<p>训练模型前，需要设置训练模型所需的优化器，损失函数和评估指标。</p>
<ul>
<li>优化器：Adam 优化器，快速收敛。</li>
<li>损失函数：SmoothL1Loss</li>
<li>评估指标：NME</li>
</ul>
<h3 id="4-2-自定义评估指标">4.2 自定义评估指标</h3>
<p>特定任务的 Metric 计算方式在框架既有的 Metric 接口中不存在，或算法不符合自己的需求，那么需要我们自己来进行 Metric 的自定义。这里介绍如何进行 Metric 的自定义操作，更多信息可以参考官网文档<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/02_paddle2.0_develop/07_customize_cn.html#metric">自定义 Metric</a>；首先来看下面的代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> paddle.metric <span class="keyword">import</span> Metric</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NME</span>(<span class="title class_ inherited__">Metric</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    1. 继承paddle.metric.Metric</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name=<span class="string">&#x27;nme&#x27;</span>, *args, **kwargs</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        2. 构造函数实现，自定义参数即可</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(NME, self).__init__(*args, **kwargs)</span><br><span class="line">        self._name = name</span><br><span class="line">        self.rmse = <span class="number">0</span></span><br><span class="line">        self.sample_num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">name</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        3. 实现name方法，返回定义的评估指标名字</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self._name</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, preds, labels</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        4. 实现update方法，用于单个batch训练时进行评估指标计算。</span></span><br><span class="line"><span class="string">        - 当`compute`类函数未实现时，会将模型的计算输出和标签数据的展平作为`update`的参数传入。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        N = preds.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        preds = preds.reshape((N, -<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">        labels = labels.reshape((N, -<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">        self.rmse = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">            pts_pred, pts_gt = preds[i, ], labels[i, ]</span><br><span class="line">            interocular = np.linalg.norm(pts_gt[<span class="number">36</span>, ] - pts_gt[<span class="number">45</span>, ])</span><br><span class="line"></span><br><span class="line">            self.rmse += np.<span class="built_in">sum</span>(np.linalg.norm(pts_pred - pts_gt, axis=<span class="number">1</span>)) / (interocular * preds.shape[<span class="number">1</span>])</span><br><span class="line">            self.sample_num += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.rmse / N</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accumulate</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        5. 实现accumulate方法，返回历史batch训练积累后计算得到的评价指标值。</span></span><br><span class="line"><span class="string">        每次`update`调用时进行数据积累，`accumulate`计算时对积累的所有数据进行计算并返回。</span></span><br><span class="line"><span class="string">        结算结果会在`fit`接口的训练日志中呈现。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.rmse / self.sample_num</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        6. 实现reset方法，每个Epoch结束后进行评估指标的重置，这样下个Epoch可以重新进行计算。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.rmse = <span class="number">0</span></span><br><span class="line">        self.sample_num = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h3 id="作业-4：实现模型的配置和训练">作业 4：实现模型的配置和训练</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 paddle.Model 封装模型</span></span><br><span class="line">model = paddle.Model(SimpleNet(key_pts=<span class="number">68</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置模型</span></span><br><span class="line">model.prepare(optimizer=paddle.optimizer.Adam(learning_rate=<span class="number">0.001</span>, weight_decay=<span class="number">5e-4</span>, parameters=model.parameters()),</span><br><span class="line">              loss=paddle.nn.SmoothL1Loss(),</span><br><span class="line">              metrics=NME())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练可视化VisualDL工具的回调函数</span></span><br><span class="line">visualdl = paddle.callbacks.VisualDL(log_dir=<span class="string">&#x27;visualdl_log&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">model.fit(train_dataset,</span><br><span class="line">          test_dataset,</span><br><span class="line">          epochs=<span class="number">50</span>,</span><br><span class="line">          batch_size=<span class="number">64</span>,</span><br><span class="line">          shuffle=<span class="literal">True</span>,</span><br><span class="line">          verbose=<span class="number">1</span>,</span><br><span class="line">          save_freq=<span class="number">10</span>,</span><br><span class="line">          save_dir=<span class="string">&#x27;./checkpoints&#x27;</span>,</span><br><span class="line">          callbacks=[visualdl])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br></pre></td><td class="code"><pre><span class="line">The loss value printed in the log is the current step, and the metric is the average value of previous step.</span><br><span class="line">Epoch 1/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0314 - nme: 3.5256e-04 - 519ms/step</span><br><span class="line">save checkpoint at /home/aistudio/checkpoints/0</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.1009 - nme: 8.2678e-04 - 392ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 2/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0243 - nme: 3.5679e-04 - 515ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.1283 - nme: 9.6968e-04 - 384ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 3/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0842 - nme: 5.4441e-04 - 516ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.1667 - nme: 0.0011 - 384ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 4/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0288 - nme: 3.6530e-04 - 508ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0784 - nme: 6.5352e-04 - 386ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 5/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0151 - nme: 2.4205e-04 - 515ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.1389 - nme: 9.6945e-04 - 395ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 6/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0566 - nme: 5.3502e-04 - 515ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0740 - nme: 7.7999e-04 - 387ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 7/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0764 - nme: 5.0105e-04 - 527ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.1483 - nme: 0.0010 - 394ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 8/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0620 - nme: 5.2153e-04 - 517ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0452 - nme: 5.5858e-04 - 388ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 9/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0319 - nme: 3.1529e-04 - 548ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0614 - nme: 5.9176e-04 - 389ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 10/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0278 - nme: 3.3610e-04 - 535ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0530 - nme: 5.8935e-04 - 395ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 11/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0287 - nme: 3.5150e-04 - 539ms/step</span><br><span class="line">save checkpoint at /home/aistudio/checkpoints/10</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0630 - nme: 6.0881e-04 - 391ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 12/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0568 - nme: 5.7893e-04 - 519ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.1034 - nme: 7.6108e-04 - 391ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 13/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0217 - nme: 3.2146e-04 - 516ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0812 - nme: 7.3246e-04 - 390ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 14/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0303 - nme: 4.3396e-04 - 519ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0300 - nme: 4.4063e-04 - 390ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 15/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0206 - nme: 3.6483e-04 - 512ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.1166 - nme: 8.2566e-04 - 384ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 16/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0557 - nme: 4.9904e-04 - 518ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0294 - nme: 4.3339e-04 - 404ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 17/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0132 - nme: 2.2774e-04 - 547ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0422 - nme: 4.7383e-04 - 389ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 18/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0101 - nme: 2.0102e-04 - 526ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0657 - nme: 6.2621e-04 - 401ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 19/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0243 - nme: 3.7471e-04 - 523ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0342 - nme: 4.0499e-04 - 388ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 20/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0149 - nme: 2.2458e-04 - 518ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0324 - nme: 4.5619e-04 - 389ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 21/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0239 - nme: 3.0768e-04 - 522ms/step</span><br><span class="line">save checkpoint at /home/aistudio/checkpoints/20</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0590 - nme: 6.0212e-04 - 398ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 22/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0136 - nme: 2.5585e-04 - 516ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0358 - nme: 4.5645e-04 - 394ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 23/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0138 - nme: 2.3678e-04 - 517ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0431 - nme: 4.7841e-04 - 403ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 24/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0118 - nme: 2.5309e-04 - 543ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0551 - nme: 5.4791e-04 - 394ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 25/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0194 - nme: 2.6883e-04 - 523ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0606 - nme: 6.2750e-04 - 395ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 26/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.1156 - nme: 8.1230e-04 - 507ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0253 - nme: 4.3194e-04 - 398ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 27/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0211 - nme: 2.9135e-04 - 524ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0242 - nme: 3.5315e-04 - 724ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 28/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0257 - nme: 3.4604e-04 - 527ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0165 - nme: 3.0425e-04 - 389ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 29/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0275 - nme: 3.3530e-04 - 571ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0216 - nme: 3.7149e-04 - 394ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 30/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0183 - nme: 2.9012e-04 - 513ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0315 - nme: 4.3564e-04 - 393ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 31/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0163 - nme: 2.7395e-04 - 510ms/step</span><br><span class="line">save checkpoint at /home/aistudio/checkpoints/30</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.1089 - nme: 8.2030e-04 - 400ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 32/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0181 - nme: 2.3484e-04 - 516ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0211 - nme: 3.9242e-04 - 401ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 33/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0474 - nme: 5.8619e-04 - 531ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0372 - nme: 4.5803e-04 - 395ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 34/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0225 - nme: 3.2990e-04 - 512ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0412 - nme: 4.8774e-04 - 392ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 35/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0155 - nme: 2.7035e-04 - 517ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0372 - nme: 5.1617e-04 - 396ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 36/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0179 - nme: 3.2274e-04 - 520ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0186 - nme: 3.1128e-04 - 396ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 37/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0360 - nme: 4.2556e-04 - 581ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0138 - nme: 2.6913e-04 - 389ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 38/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0098 - nme: 2.0373e-04 - 523ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0332 - nme: 5.0381e-04 - 390ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 39/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0453 - nme: 4.6348e-04 - 518ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0307 - nme: 4.7557e-04 - 392ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 40/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0291 - nme: 4.4760e-04 - 528ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0161 - nme: 2.9352e-04 - 395ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 41/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0886 - nme: 6.5529e-04 - 562ms/step</span><br><span class="line">save checkpoint at /home/aistudio/checkpoints/40</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0242 - nme: 3.5008e-04 - 392ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 42/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0636 - nme: 5.7302e-04 - 553ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0232 - nme: 3.2434e-04 - 393ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 43/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0363 - nme: 4.2757e-04 - 521ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0276 - nme: 4.5470e-04 - 383ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 44/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0244 - nme: 3.6430e-04 - 522ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0246 - nme: 3.7649e-04 - 574ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 45/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0382 - nme: 4.3469e-04 - 521ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0280 - nme: 4.2459e-04 - 409ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 46/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0487 - nme: 4.3741e-04 - 523ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0316 - nme: 4.8172e-04 - 390ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 47/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0146 - nme: 2.3825e-04 - 515ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0136 - nme: 2.7338e-04 - 391ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 48/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0224 - nme: 2.9963e-04 - 526ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0150 - nme: 2.8412e-04 - 394ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 49/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0139 - nme: 2.3343e-04 - 514ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0323 - nme: 4.2434e-04 - 388ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">Epoch 50/50</span><br><span class="line">step 55/55 [==============================] - loss: 0.0171 - nme: 2.8570e-04 - 515ms/step</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 13/13 [==============================] - loss: 0.0187 - nme: 3.2592e-04 - 385ms/step</span><br><span class="line">Eval samples: 770</span><br><span class="line">save checkpoint at /home/aistudio/checkpoints/final</span><br></pre></td></tr></table></figure>
<p><strong>损失函数的选择</strong>：L1Loss、L2Loss、SmoothL1Loss 的对比</p>
<ul>
<li>L1Loss: 在训练后期，预测值与 ground-truth 差异较小时， 损失对预测值的导数的绝对值仍然为 1，此时如果学习率不变，损失函数将在稳定值附近波动，难以继续收敛达到更高精度。</li>
<li>L2Loss: 在训练初期，预测值与 ground-truth 差异较大时，损失函数对预测值的梯度十分大，导致训练不稳定。</li>
<li>SmoothL1Loss: 在 x 较小时，对 x 梯度也会变小，而在 x 很大时，对 x 的梯度的绝对值达到上限 1，也不会太大以至于破坏网络参数。</li>
</ul>
<h3 id="模型保存">模型保存</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">checkpoints_path = <span class="string">&#x27;./output/models&#x27;</span></span><br><span class="line">model.save(checkpoints_path, training=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h2 id="五、模型预测">五、模型预测</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义功能函数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_all_keypoints</span>(<span class="params">image, predicted_key_pts</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    展示图像，预测关键点</span></span><br><span class="line"><span class="string">    Args：</span></span><br><span class="line"><span class="string">        image：裁剪后的图像 [224, 224, 3]</span></span><br><span class="line"><span class="string">        predicted_key_pts: 预测关键点的坐标</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 展示图像</span></span><br><span class="line">    plt.imshow(image.astype(<span class="string">&#x27;uint8&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 展示关键点</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(predicted_key_pts), <span class="number">2</span>):</span><br><span class="line">        plt.scatter(predicted_key_pts[i], predicted_key_pts[i+<span class="number">1</span>], s=<span class="number">20</span>, marker=<span class="string">&#x27;.&#x27;</span>, c=<span class="string">&#x27;m&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">visualize_output</span>(<span class="params">test_images, test_outputs, batch_size=<span class="number">1</span>, h=<span class="number">20</span>, w=<span class="number">10</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    展示图像，预测关键点</span></span><br><span class="line"><span class="string">    Args：</span></span><br><span class="line"><span class="string">        test_images：裁剪后的图像 [224, 224, 3]</span></span><br><span class="line"><span class="string">        test_outputs: 模型的输出</span></span><br><span class="line"><span class="string">        batch_size: 批大小</span></span><br><span class="line"><span class="string">        h: 展示的图像高</span></span><br><span class="line"><span class="string">        w: 展示的图像宽</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(test_images.shape) == <span class="number">3</span>:</span><br><span class="line">        test_images = np.array([test_images])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line"></span><br><span class="line">        plt.figure(figsize=(h, w))</span><br><span class="line">        ax = plt.subplot(<span class="number">1</span>, batch_size, i+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 随机裁剪后的图像</span></span><br><span class="line">        image = test_images[i]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 模型的输出，未还原的预测关键点坐标值</span></span><br><span class="line">        predicted_key_pts = test_outputs[i]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 还原后的真实的关键点坐标值</span></span><br><span class="line">        predicted_key_pts = predicted_key_pts * data_std + data_mean</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 展示图像和关键点</span></span><br><span class="line">        show_all_keypoints(np.squeeze(image), predicted_key_pts)</span><br><span class="line"></span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取图像</span></span><br><span class="line">img = mpimg.imread(<span class="string">&#x27;./test.jpeg&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(img.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关键点占位符</span></span><br><span class="line">kpt = np.ones((<span class="number">136</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># data_transform = Compose([Resize(256), RandomCrop(224), GrayNormalize(), ToCHW()])</span></span><br><span class="line">transform = Compose([Resize(<span class="number">256</span>), RandomCrop(<span class="number">224</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对图像先重新定义大小，并裁剪到 224*224的大小</span></span><br><span class="line">rgb_img, kpt = transform([img, kpt])</span><br><span class="line"></span><br><span class="line">norm = GrayNormalize()</span><br><span class="line">to_chw = ToCHW()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对图像进行归一化和格式变换</span></span><br><span class="line">img, kpt = norm([rgb_img, kpt])</span><br><span class="line">img, kpt = to_chw([img, kpt])</span><br><span class="line"></span><br><span class="line">img = np.array([img], dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载保存好的模型进行预测</span></span><br><span class="line">model = paddle.Model(SimpleNet(key_pts=<span class="number">68</span>))</span><br><span class="line">model.load(checkpoints_path)</span><br><span class="line">model.prepare()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果</span></span><br><span class="line">out = model.predict_batch([img])</span><br><span class="line">out = out[<span class="number">0</span>].reshape((out[<span class="number">0</span>].shape[<span class="number">0</span>], <span class="number">136</span>, -<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">visualize_output(rgb_img, out, batch_size=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(847, 700, 3)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20210206024221450.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzI2Mjgw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="使用-PaddleHub-进行测试">使用 PaddleHub 进行测试</h2>
<p>便捷地获取 PaddlePaddle 生态下的预训练模型，完成模型的管理和一键预测。配合使用 Fine-tune API，可以基于大规模预训练模型快速完成迁移学习，让预训练模型能更好地服务于用户特定场景的应用</p>
<p><code>图像 - 关键点检测</code>-&gt;<code>face_landmark_localization</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!hub install face_landmark_localization==<span class="number">1.0</span><span class="number">.2</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/tools/datetimes.py:3: DeprecationWarning: Using or importing the ABCs from &#x27;collections&#x27; instead of from &#x27;collections.abc&#x27; is deprecated, and in 3.8 it will stop working</span><br><span class="line">  from collections import MutableMapping</span><br><span class="line">/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from &#x27;collections&#x27; instead of from &#x27;collections.abc&#x27; is deprecated, and in 3.8 it will stop working</span><br><span class="line">  from collections import Iterable, Mapping</span><br><span class="line">/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from &#x27;collections&#x27; instead of from &#x27;collections.abc&#x27; is deprecated, and in 3.8 it will stop working</span><br><span class="line">  from collections import Sized</span><br><span class="line">/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/nltk/decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly</span><br><span class="line">  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: &quot;&quot;</span><br><span class="line">/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/nltk/lm/counter.py:15: DeprecationWarning: Using or importing the ABCs from &#x27;collections&#x27; instead of from &#x27;collections.abc&#x27; is deprecated, and in 3.8 it will stop working</span><br><span class="line">  from collections import Sequence, defaultdict</span><br><span class="line">Downloading face_landmark_localization</span><br><span class="line">[==================================================] 100.00%</span><br><span class="line">Uncompress /home/aistudio/.paddlehub/tmp/tmp2uffqr16/face_landmark_localization</span><br><span class="line">[==================================================] 100.00%</span><br><span class="line">Successfully installed face_landmark_localization-1.0.2</span><br><span class="line">[0m</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddlehub <span class="keyword">as</span> hub</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">face_landmark = hub.Module(name=<span class="string">&quot;face_landmark_localization&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Replace face detection module to speed up predictions but reduce performance</span></span><br><span class="line"><span class="comment"># face_landmark.set_face_detector_module(hub.Module(name=&quot;ultra_light_fast_generic_face_detector_1mb_320&quot;))</span></span><br><span class="line"></span><br><span class="line">result = face_landmark.keypoint_detection(images=[cv2.imread(<span class="string">&#x27;./test.jpeg&#x27;</span>)])</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line"><span class="comment"># result = face_landmark.keypoint_detection(paths=[&#x27;/PATH/TO/IMAGE&#x27;])</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[2021-02-06 01:30:35,589] [    INFO] - Installing face_landmark_localization module</span><br><span class="line">[2021-02-06 01:30:35,704] [    INFO] - Module face_landmark_localization already installed in /home/aistudio/.paddlehub/modules/face_landmark_localization</span><br><span class="line">[2021-02-06 01:30:35,707] [    INFO] - Installing ultra_light_fast_generic_face_detector_1mb_640 module</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading ultra_light_fast_generic_face_detector_1mb_640</span><br><span class="line">[==================================================] 100.00%</span><br><span class="line">Uncompress /home/aistudio/.paddlehub/tmp/tmp_7n8dm48/ultra_light_fast_generic_face_detector_1mb_640</span><br><span class="line">[==================================================] 100.00%</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[2021-02-06 01:30:40,971] [    INFO] - Successfully installed ultra_light_fast_generic_face_detector_1mb_640-1.1.2</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">image = cv2.imread(<span class="string">&#x27;./test.jpeg&#x27;</span>)</span><br><span class="line">image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)</span><br><span class="line">key_pts = np.array(result[<span class="number">0</span>][<span class="string">&#x27;data&#x27;</span>])</span><br><span class="line">key_pts = key_pts.reshape((<span class="number">136</span>, -<span class="number">1</span>))</span><br><span class="line">key_pts.shape</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(136, 1)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置画幅</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">16</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示图像</span></span><br><span class="line">plt.imshow(image.astype(<span class="string">&#x27;uint8&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示关键点</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(key_pts), <span class="number">2</span>):</span><br><span class="line">    plt.scatter(key_pts[i], key_pts[i+<span class="number">1</span>], s=<span class="number">20</span>, marker=<span class="string">&#x27;.&#x27;</span>, c=<span class="string">&#x27;m&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20210206024242293.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzI2Mjgw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="六、趣味应用">六、趣味应用</h2>
<p>当我们得到关键点的信息后，就可以进行一些趣味的应用。</p>
<h2 id="装饰预览">装饰预览</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">star_image = cv2.imread(<span class="string">&#x27;ps.jpeg&#x27;</span>)</span><br><span class="line">star_image = cv2.cvtColor(star_image, cv2.COLOR_BGR2RGB)</span><br><span class="line"><span class="comment"># star_image = cv2.resize(star_image, (40, 40))</span></span><br><span class="line"><span class="built_in">print</span>(star_image.shape)</span><br><span class="line">plt.imshow(star_image)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(524, 650, 3)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;matplotlib.image.AxesImage at 0x7fc5567f18d0&gt;</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20210206024233796.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzI2Mjgw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义功能函数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_fu</span>(<span class="params">image, predicted_key_pts, size=<span class="number">10</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    展示加了贴纸的图像</span></span><br><span class="line"><span class="string">    Args：</span></span><br><span class="line"><span class="string">        image：裁剪后的图像 [224, 224, 3]</span></span><br><span class="line"><span class="string">        predicted_key_pts: 预测关键点的坐标</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 3-32, 36-15</span></span><br><span class="line">    <span class="comment"># 计算坐标，15 和 34点的中间值</span></span><br><span class="line">    x1 = (<span class="built_in">int</span>(predicted_key_pts[<span class="number">28</span>]) + <span class="built_in">int</span>(predicted_key_pts[<span class="number">70</span>]))//<span class="number">2</span></span><br><span class="line">    y1 = (<span class="built_in">int</span>(predicted_key_pts[<span class="number">29</span>]) + <span class="built_in">int</span>(predicted_key_pts[<span class="number">71</span>]))//<span class="number">2</span></span><br><span class="line"></span><br><span class="line">    x2 = (<span class="built_in">int</span>(predicted_key_pts[<span class="number">4</span>]) + <span class="built_in">int</span>(predicted_key_pts[<span class="number">62</span>]))//<span class="number">2</span></span><br><span class="line">    y2 = (<span class="built_in">int</span>(predicted_key_pts[<span class="number">5</span>]) + <span class="built_in">int</span>(predicted_key_pts[<span class="number">63</span>]))//<span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># star_image = cv2.imread(&#x27;rat.jpg&#x27;)</span></span><br><span class="line">    star_image = cv2.imread(<span class="string">&#x27;ps.jpeg&#x27;</span>)</span><br><span class="line">    star_image = cv2.cvtColor(star_image, cv2.COLOR_BGR2RGB)</span><br><span class="line">    <span class="comment"># resize</span></span><br><span class="line">    star_image = cv2.resize(star_image, (size, size))</span><br><span class="line">    <span class="comment"># 处理通道</span></span><br><span class="line">    <span class="keyword">if</span>(star_image.shape[<span class="number">2</span>] == <span class="number">4</span>):</span><br><span class="line">        star_image = star_image[:,:,<span class="number">1</span>:<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将小图放到原图上</span></span><br><span class="line">    image[y1:y1+<span class="built_in">len</span>(star_image[<span class="number">0</span>]), x1:x1+<span class="built_in">len</span>(star_image[<span class="number">1</span>]),:] = star_image</span><br><span class="line"></span><br><span class="line">    image[y2:y2+<span class="built_in">len</span>(star_image[<span class="number">0</span>]), x2:x2+<span class="built_in">len</span>(star_image[<span class="number">1</span>]),:] = star_image</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 展示处理后的图片</span></span><br><span class="line">    plt.imshow(image.astype(<span class="string">&#x27;uint8&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 展示关键点信息</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predicted_key_pts)//<span class="number">2</span>,):</span><br><span class="line">        plt.scatter(predicted_key_pts[i*<span class="number">2</span>], predicted_key_pts[i*<span class="number">2</span>+<span class="number">1</span>], s=<span class="number">20</span>, marker=<span class="string">&#x27;.&#x27;</span>, c=<span class="string">&#x27;m&#x27;</span>) <span class="comment"># 展示关键点信息</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">custom_output</span>(<span class="params">test_images, test_outputs, batch_size=<span class="number">1</span>, h=<span class="number">20</span>, w=<span class="number">10</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    展示图像，预测关键点</span></span><br><span class="line"><span class="string">    Args：</span></span><br><span class="line"><span class="string">        test_images：裁剪后的图像 [224, 224, 3]</span></span><br><span class="line"><span class="string">        test_outputs: 模型的输出</span></span><br><span class="line"><span class="string">        batch_size: 批大小</span></span><br><span class="line"><span class="string">        h: 展示的图像高</span></span><br><span class="line"><span class="string">        w: 展示的图像宽</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(test_images.shape) == <span class="number">3</span>:</span><br><span class="line">        test_images = np.array([test_images])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line"></span><br><span class="line">        plt.figure(figsize=(h, w))</span><br><span class="line">        ax = plt.subplot(<span class="number">1</span>, batch_size, i+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 随机裁剪后的图像</span></span><br><span class="line">        image = test_images[i]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 模型的输出，未还原的预测关键点坐标值</span></span><br><span class="line">        predicted_key_pts = test_outputs[i]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 还原后的真实的关键点坐标值</span></span><br><span class="line">        predicted_key_pts = predicted_key_pts * data_std + data_mean</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 展示图像和关键点</span></span><br><span class="line">        show_fu(np.squeeze(image), predicted_key_pts)</span><br><span class="line"></span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="作业-6：实现趣味-PS">作业 6：实现趣味 PS</h3>
<p>根据人脸检测的结果，实现趣味 PS。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取图像</span></span><br><span class="line">img = mpimg.imread(<span class="string">&#x27;./test.jpeg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关键点占位符</span></span><br><span class="line">kpt = np.ones((<span class="number">136</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">transform = Compose([Resize(<span class="number">256</span>), RandomCrop(<span class="number">224</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对图像先重新定义大小，并裁剪到 224*224的大小</span></span><br><span class="line">rgb_img, kpt = transform([img, kpt])</span><br><span class="line"></span><br><span class="line">norm = GrayNormalize()</span><br><span class="line">to_chw = ToCHW()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对图像进行归一化和格式变换</span></span><br><span class="line">img, kpt = norm([rgb_img, kpt])</span><br><span class="line">img, kpt = to_chw([img, kpt])</span><br><span class="line"></span><br><span class="line">img = np.array([img], dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载保存好的模型进行预测</span></span><br><span class="line"><span class="comment"># model = paddle.Model(SimpleNet())</span></span><br><span class="line"><span class="comment"># model.load(checkpoints_path)</span></span><br><span class="line"><span class="comment"># model.prepare()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果</span></span><br><span class="line">out = model.predict_batch([img])</span><br><span class="line">out = out[<span class="number">0</span>].reshape((out[<span class="number">0</span>].shape[<span class="number">0</span>], <span class="number">136</span>, -<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化1</span></span><br><span class="line">custom_output(rgb_img, out, batch_size=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20210206024256453.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzI2Mjgw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># paddleHub 效果可视化</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置画幅</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">20</span>))</span><br><span class="line"></span><br><span class="line">)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="comment"># paddleHub 效果可视化</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置画幅</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">20</span>))</span><br><span class="line"></span><br><span class="line">show_fu(image, key_pts, size=<span class="number">40</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20210206024549531.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzI2Mjgw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="http://example.com">YUAN Tingyi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2022/06/01/63e0d330af4f4b7c818e86e056b93ab8/">http://example.com/2022/06/01/63e0d330af4f4b7c818e86e056b93ab8/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/6.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/gh/overtrue/share.js@master/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/06/01/234b53c9dbdf4d4595e8b9f095173105/"><img class="prev-cover" src="/img/6.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">paddle2.0高层API实现自定义数据集文本分类中的情感分析任务</div></div></a></div><div class="next-post pull-right"><a href="/2022/06/01/febcf959471d4ccb8df3760a6117820a/"><img class="next-cover" src="/img/2.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">paddle2.0高层API实现基于seq2seq的对联生成</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div><div id="comment-switch"><span class="first-comment">Valine</span><span class="switch-btn"></span><span class="second-comment">Disqus</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">YUAN Tingyi</div><div class="author-info__description">XianrenYty</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">28</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/XianrenYty"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E9%97%AE%E9%A2%98%E5%AE%9A%E4%B9%89"><span class="toc-number">1.</span> <span class="toc-text">一、问题定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%BA%E8%84%B8%E5%85%B3%E9%94%AE%E7%82%B9%E6%A3%80%E6%B5%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%BB%BC%E8%BF%B0"><span class="toc-number">2.</span> <span class="toc-text">人脸关键点检测深度学习方法综述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Deep-Convolutional-Network-Cascade-for-Facial-Point-Detection"><span class="toc-number">2.1.</span> <span class="toc-text">Deep Convolutional Network Cascade for Facial Point Detection</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Extensive-Facial-Landmark-Localization-with-Coarse-to-fine-Convolutional-Network-Cascade"><span class="toc-number">2.2.</span> <span class="toc-text">Extensive Facial Landmark Localization with Coarse-to-fine Convolutional Network Cascade</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TCDCN-Facial-Landmark-Detection-by-Deep-Multi-task-Learning"><span class="toc-number">2.3.</span> <span class="toc-text">TCDCN-Facial Landmark Detection by Deep Multi-task Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Joint-Face-Detection-and-Alignment-using-Multi-task-Cascaded-Convolutional-Networks"><span class="toc-number">2.4.</span> <span class="toc-text">Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DAN-Deep-Alignment-Networks"><span class="toc-number">2.5.</span> <span class="toc-text">DAN(Deep Alignment Networks)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PFLD-A-Practical-Facial-Landmark-Detector"><span class="toc-number">2.6.</span> <span class="toc-text">PFLD: A Practical Facial Landmark Detector</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#PFLD-%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1"><span class="toc-number">2.6.1.</span> <span class="toc-text">PFLD 模型设计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#PFLD-%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5"><span class="toc-number">2.6.2.</span> <span class="toc-text">PFLD 的模型训练策略</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87"><span class="toc-number">3.</span> <span class="toc-text">二、数据准备</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E4%B8%8B%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.1.</span> <span class="toc-text">2.1 下载数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E6%9F%A5%E7%9C%8B%E5%9B%BE%E5%83%8F"><span class="toc-number">3.2.</span> <span class="toc-text">2.2 查看图像</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%AE%9A%E4%B9%89-2"><span class="toc-number">3.3.</span> <span class="toc-text">2.3 数据集定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A-1%EF%BC%9A%E8%87%AA%E5%AE%9A%E4%B9%89-Dataset%EF%BC%8C%E5%AE%8C%E6%88%90%E4%BA%BA%E8%84%B8%E5%85%B3%E9%94%AE%E7%82%B9%E6%95%B0%E6%8D%AE%E9%9B%86%E5%AE%9A%E4%B9%89"><span class="toc-number">3.4.</span> <span class="toc-text">作业 1：自定义 Dataset，完成人脸关键点数据集定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E8%AE%AD%E7%BB%83%E9%9B%86%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">3.5.</span> <span class="toc-text">2.4 训练集可视化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-Transforms"><span class="toc-number">3.6.</span> <span class="toc-text">2.5 Transforms</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A-2%EF%BC%9A%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%AE%9A%E4%B9%89-ToCHW"><span class="toc-number">3.7.</span> <span class="toc-text">作业 2：实现自定义 ToCHW</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-6-%E4%BD%BF%E7%94%A8%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AE%8C%E6%88%90%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89"><span class="toc-number">3.8.</span> <span class="toc-text">2.6 使用数据预处理的方式完成数据定义</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3%E3%80%81%E6%A8%A1%E5%9E%8B%E7%BB%84%E5%BB%BA"><span class="toc-number">4.</span> <span class="toc-text">3、模型组建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E7%BB%84%E7%BD%91%E5%8F%AF%E4%BB%A5%E5%BE%88%E7%AE%80%E5%8D%95"><span class="toc-number">4.1.</span> <span class="toc-text">3.1 组网可以很简单</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A-3%EF%BC%9A%E6%A0%B9%E6%8D%AE%E4%B8%8A%E5%9B%BE%EF%BC%8C%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-number">4.2.</span> <span class="toc-text">作业 3：根据上图，实现网络结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">4.3.</span> <span class="toc-text">3.2 网络结构可视化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">5.</span> <span class="toc-text">四、模型训练</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E6%A8%A1%E5%9E%8B%E9%85%8D%E7%BD%AE"><span class="toc-number">5.1.</span> <span class="toc-text">4.1 模型配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">5.2.</span> <span class="toc-text">4.2 自定义评估指标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A-4%EF%BC%9A%E5%AE%9E%E7%8E%B0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%85%8D%E7%BD%AE%E5%92%8C%E8%AE%AD%E7%BB%83"><span class="toc-number">5.3.</span> <span class="toc-text">作业 4：实现模型的配置和训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98"><span class="toc-number">5.4.</span> <span class="toc-text">模型保存</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B"><span class="toc-number">6.</span> <span class="toc-text">五、模型预测</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-PaddleHub-%E8%BF%9B%E8%A1%8C%E6%B5%8B%E8%AF%95"><span class="toc-number">7.</span> <span class="toc-text">使用 PaddleHub 进行测试</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E8%B6%A3%E5%91%B3%E5%BA%94%E7%94%A8"><span class="toc-number">8.</span> <span class="toc-text">六、趣味应用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A3%85%E9%A5%B0%E9%A2%84%E8%A7%88"><span class="toc-number">9.</span> <span class="toc-text">装饰预览</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A-6%EF%BC%9A%E5%AE%9E%E7%8E%B0%E8%B6%A3%E5%91%B3-PS"><span class="toc-number">9.1.</span> <span class="toc-text">作业 6：实现趣味 PS</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/06/01/fd61228310d24c999c625f49b503f7ce/" title="train_test_split 参数详解"><img src="/img/8.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="train_test_split 参数详解"/></a><div class="content"><a class="title" href="/2022/06/01/fd61228310d24c999c625f49b503f7ce/" title="train_test_split 参数详解">train_test_split 参数详解</a><time datetime="2022-06-01T12:52:00.000Z" title="Created 2022-06-01 20:52:00">2022-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/01/224bdd4444be4fe0b7826959bc6b40a4/" title="StandardScaler(sklearn)参数详解"><img src="/img/1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="StandardScaler(sklearn)参数详解"/></a><div class="content"><a class="title" href="/2022/06/01/224bdd4444be4fe0b7826959bc6b40a4/" title="StandardScaler(sklearn)参数详解">StandardScaler(sklearn)参数详解</a><time datetime="2022-06-01T12:51:39.966Z" title="Created 2022-06-01 20:51:39">2022-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/01/2fd9e712ce6b4a49a24775586e47e44b/" title="八大排序算法(Python实现)"><img src="/img/6.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="八大排序算法(Python实现)"/></a><div class="content"><a class="title" href="/2022/06/01/2fd9e712ce6b4a49a24775586e47e44b/" title="八大排序算法(Python实现)">八大排序算法(Python实现)</a><time datetime="2022-06-01T12:51:26.086Z" title="Created 2022-06-01 20:51:26">2022-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/01/9d8547900901416593ba964e6757c6c3/" title="ResNet"><img src="/img/2.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ResNet"/></a><div class="content"><a class="title" href="/2022/06/01/9d8547900901416593ba964e6757c6c3/" title="ResNet">ResNet</a><time datetime="2022-06-01T12:50:56.055Z" title="Created 2022-06-01 20:50:56">2022-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/01/b6a6cbce3d7f45a8b2511edf86fb5a24/" title="Paddle高层API实现图像分类（CIFAR-100数据集_ResNet101）"><img src="/img/8.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Paddle高层API实现图像分类（CIFAR-100数据集_ResNet101）"/></a><div class="content"><a class="title" href="/2022/06/01/b6a6cbce3d7f45a8b2511edf86fb5a24/" title="Paddle高层API实现图像分类（CIFAR-100数据集_ResNet101）">Paddle高层API实现图像分类（CIFAR-100数据集_ResNet101）</a><time datetime="2022-06-01T12:48:23.363Z" title="Created 2022-06-01 20:48:23">2022-06-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By YUAN Tingyi</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'http://example.com/2022/06/01/63e0d330af4f4b7c818e86e056b93ab8/'
    this.page.identifier = '2022/06/01/63e0d330af4f4b7c818e86e056b93ab8/'
    this.page.title = 'paddle2.0高层API实现人脸关键点检测(人脸关键点检测综述_自定义网络_paddleHub_趣味ps)'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }
}

if ('Valine' === 'Disqus' || !true) {
  if (true) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>