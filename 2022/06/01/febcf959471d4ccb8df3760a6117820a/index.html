<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>paddle2.0高层API实现基于seq2seq的对联生成 | Personnal Blog of YUAN Tingyi</title><meta name="author" content="YUAN Tingyi"><meta name="copyright" content="YUAN Tingyi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="[toc] 『深度学习 7 日打卡营·day5』 零基础解锁深度学习神器飞桨框架高层 API，七天时间助你掌握 CV、NLP 领域最火模型及应用。  课程地址  传送门：https:&#x2F;&#x2F;aistudio.baidu.com&#x2F;aistudio&#x2F;course&#x2F;introduce&#x2F;6771  目标   掌握深度学习常用模型基础知识 熟练掌握一种国产开源深度学习框架 具备独立完成相关深度学习任务的能力 能">
<meta property="og:type" content="article">
<meta property="og:title" content="paddle2.0高层API实现基于seq2seq的对联生成">
<meta property="og:url" content="http://example.com/2022/06/01/febcf959471d4ccb8df3760a6117820a/index.html">
<meta property="og:site_name" content="Personnal Blog of YUAN Tingyi">
<meta property="og:description" content="[toc] 『深度学习 7 日打卡营·day5』 零基础解锁深度学习神器飞桨框架高层 API，七天时间助你掌握 CV、NLP 领域最火模型及应用。  课程地址  传送门：https:&#x2F;&#x2F;aistudio.baidu.com&#x2F;aistudio&#x2F;course&#x2F;introduce&#x2F;6771  目标   掌握深度学习常用模型基础知识 熟练掌握一种国产开源深度学习框架 具备独立完成相关深度学习任务的能力 能">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/2.jpeg">
<meta property="article:published_time" content="2022-06-01T12:46:57.066Z">
<meta property="article:modified_time" content="2022-06-01T12:47:05.296Z">
<meta property="article:author" content="YUAN Tingyi">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/2.jpeg"><link rel="shortcut icon" href="/img/favicon-32x32.png"><link rel="canonical" href="http://example.com/2022/06/01/febcf959471d4ccb8df3760a6117820a/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'paddle2.0高层API实现基于seq2seq的对联生成',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-06-01 20:47:05'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">28</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/2.jpeg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Personnal Blog of YUAN Tingyi</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">paddle2.0高层API实现基于seq2seq的对联生成</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-06-01T12:46:57.066Z" title="Created 2022-06-01 20:46:57">2022-06-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-06-01T12:47:05.296Z" title="Updated 2022-06-01 20:47:05">2022-06-01</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="paddle2.0高层API实现基于seq2seq的对联生成"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>[toc]</p>
<p>『深度学习 7 日打卡营·day5』</p>
<p>零基础解锁深度学习神器飞桨框架高层 API，七天时间助你掌握 CV、NLP 领域最火模型及应用。</p>
<ol>
<li>课程地址</li>
</ol>
<p>传送门：<a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/course/introduce/6771">https://aistudio.baidu.com/aistudio/course/introduce/6771</a></p>
<ol start="2">
<li>目标</li>
</ol>
<ul>
<li>掌握深度学习常用模型基础知识</li>
<li>熟练掌握一种国产开源深度学习框架</li>
<li>具备独立完成相关深度学习任务的能力</li>
<li>能用所学为 AI 加一份年味</li>
</ul>
<p>对联，是汉族传统文化之一，是写在纸、布上或刻在竹子、木头、柱子上的对偶语句。对联对仗工整，平仄协调，是一字一音的汉语独特的艺术形式，是中国传统文化瑰宝。</p>
<p>这里，我们将根据上联，自动写下联。这是一个典型的序列到序列(sequence2sequence, seq2seq）建模的场景，编码器-解码器（Encoder-Decoder）框架是解决 seq2seq 问题的经典方法，它能够将一个任意长度的源序列转换成另一个任意长度的目标序列：编码阶段将整个源序列编码成一个向量，解码阶段通过最大化预测序列概率，从中解码出整个目标序列。编码和解码的过程通常都使用 RNN 实现。</p>
<center><img src="https://ai-studio-static-online.cdn.bcebos.com/e9dde4be7d0142068c5c921a1ca6a227a49aad4a8751425faead42f0348f5e01" width="500" height="313" ></center>
<br><center>图1：encoder-decoder示意图</center></br>
<p>这里的 Encoder 采用 LSTM，Decoder 采用带有 attention 机制的 LSTM。</p>
<center><img src="https://ai-studio-static-online.cdn.bcebos.com/a791fee76388423da867676d667b7d4c2fbe9fe9096843878c6513a40c96c86d" width="500" height="313" ></center>
<br><center>图2：带有attention机制的encoder-decoder示意图</center></br>
<p>我们将以对联的上联作为 Encoder 的输出，下联作为 Decoder 的输入，训练模型。</p>
<h2 id="生成对联部分结果">生成对联部分结果</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">上联: 芳 草 绿 阳 关 塞 上 春 风 入 户	下联: 小 桥 流 水 人 家 中 喜 气 盈 门</span><br><span class="line"></span><br><span class="line">上联: 致 富 思 源 跟 党 走	下联: 脱 贫 致 富 为 民 圆</span><br><span class="line"></span><br><span class="line">上联: 欣 然 入 梦 抱 书 睡	下联: 快 意 临 风 把 酒 眠</span><br><span class="line"></span><br><span class="line">上联: 诗 赖 境 奇 赢 感 动	下联: 风 流 人 杰 显 精 神</span><br><span class="line"></span><br><span class="line">上联: 栀 子 牵 牛 犁 熟 地	下联: 莲 花 引 蝶 戏 开 花</span><br><span class="line"></span><br><span class="line">上联: 廿 载 相 交 成 知 己	下联: 千 秋 不 朽 著 文 章</span><br><span class="line"></span><br><span class="line">上联: 润	下联: 修</span><br><span class="line"></span><br><span class="line">上联: 设 帏 遇 芳 辰 百 岁 期 颐 刚 一 半	下联: 被 被 逢 盛 世 千 秋 俎 豆 尚 千 秋</span><br><span class="line"></span><br><span class="line">上联: 波 光 云 影 满 目 葱 茏 谁 道 人 间 无 胜 地	下联: 鸟 语 花 香 一 帘 幽 梦 我 听 天 下 有 知 音</span><br><span class="line"></span><br><span class="line">上联: 眸 中 映 月 心 如 镜	下联: 笔 底 生 花 气 若 虹</span><br><span class="line"></span><br><span class="line">上联: 何 事 营 生 闲 来 写 幅 青 山 卖	下联: 此 时 入 梦 醉 去 吟 诗 碧 水 流</span><br><span class="line"></span><br><span class="line">上联: 学 海 钩 深 毫 挥 具 见 三 长 足	下联: 书 山 登 绝 顶 摘 来 登 九 重 天</span><br><span class="line"></span><br><span class="line">上联: 女 子 千 金 一 笑 贵	下联: 男 儿 万 户 百 年 长</span><br><span class="line"></span><br><span class="line">上联: 柏 叶 为 铭 椒 花 献 瑞	下联: 梅 花 作 伴 凤 凤 鸣 春</span><br><span class="line"></span><br><span class="line">上联: 家 国 遽 亡 天 涯 有 客 图 恢 复	下联: 江 山 永 在 我 心 无 人 泪 滂 沱</span><br><span class="line"></span><br><span class="line">上联: 侍 郎 赋 咏 穷 三 峡	下联: 游 子 吟 诗 醉 九 江</span><br><span class="line"></span><br><span class="line">上联: 反 腐 堵 污 流 杜 渐 防 微 不 教 长 堤 崩 蚁 穴	下联: 倡 廉 增 正 气 阳 光 普 照 长 教 大 道 播 春 风</span><br><span class="line"></span><br><span class="line">上联: 已 兆 飞 熊 钓 渭 水	下联: 欲 栽 大 木 柱 长 天</span><br><span class="line"></span><br><span class="line">上联: 建 生 态 文 明 人 与 自 然 协 调 发 展	下联: 创 文 明 发 展 事 同 事 业 发 展 文 明</span><br><span class="line"></span><br><span class="line">上联: 于 自 不 高 于 他 不 下	下联: 以 人 为 本 为 我 无 为</span><br><span class="line"></span><br><span class="line">上联: 国 泰 民 安 军 民 人 人 歌 盛 世	下联: 民 安 国 泰 社 会 事 事 颂 和 谐</span><br><span class="line"></span><br><span class="line">上联: 金 龙 腾 大 地 看 四 野 平 畴 三 农 报 喜	下联: 玉 兔 跃 神 州 喜 九 州 大 地 万 户 迎 春</span><br><span class="line"></span><br><span class="line">上联: 兴 盛	下联: 平 安</span><br><span class="line"></span><br><span class="line">上联: 长 安 跑 马 谁 得 意	下联: 广 府 古 城 百 花 芳</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>AI Studio 平台后续会默认安装 PaddleNLP，在此之前可使用如下命令安装。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install --upgrade paddlenlp&gt;=<span class="number">2.0</span><span class="number">.0</span>b -i https://mirror.baidu.com/pypi/simple</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddlenlp</span><br><span class="line">paddlenlp.__version__</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;2.0.0rc1&#x27;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">import</span> paddle.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> paddle.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> paddlenlp.data <span class="keyword">import</span> Vocab, Pad</span><br><span class="line"><span class="keyword">from</span> paddlenlp.metrics <span class="keyword">import</span> Perplexity</span><br><span class="line"><span class="keyword">from</span> paddlenlp.datasets <span class="keyword">import</span> CoupletDataset</span><br></pre></td></tr></table></figure>
<h1>数据部分</h1>
<h2 id="数据集介绍-2">数据集介绍</h2>
<p>采用开源的对联数据集<a target="_blank" rel="noopener" href="https://github.com/v-zich/couplet-clean-dataset">couplet-clean-dataset</a>，该数据集过滤了<a target="_blank" rel="noopener" href="https://github.com/wb14123/couplet-dataset"><br>
couplet-dataset</a>中的低俗、敏感内容。</p>
<p>这个数据集包含 70w 多条训练样本，1000 条验证样本和 1000 条测试样本。</p>
<p>下面列出一些训练集中对联样例：</p>
<p>上联：晚风摇树树还挺 下联：晨露润花花更红</p>
<p>上联：愿景天成无墨迹 下联：万方乐奏有于阗</p>
<p>上联：丹枫江冷人初去 下联：绿柳堤新燕复来</p>
<p>上联：闲来野钓人稀处 下联：兴起高歌酒醉中</p>
<h2 id="加载数据集">加载数据集</h2>
<p><code>paddlenlp.datasets</code>中内置了多个常见数据集，包括这里的对联数据集<code>CoupletDataset</code>。</p>
<br>
<p><code>paddlenlp.datasets</code>均继承<code>paddle.io.Dataset</code>，支持<code>paddle.io.Dataset</code>的所有功能：</p>
<ul>
<li>通过<code>len()</code>函数返回数据集长度，即样本数量。</li>
<li>下标索引：通过下标索引[n]获取第 n 条样本。</li>
<li>遍历数据集，获取所有样本。</li>
</ul>
<p>此外，<code>paddlenlp.datasets</code>，还支持如下操作：</p>
<ul>
<li>调用<code>get_datasets()</code>函数，传入 list 或者 string，获取相对应的 train_dataset、development_dataset、test_dataset 等。其中 train 为训练集，用于模型训练； development 为开发集，也称验证集 validation_dataset，用于模型参数调优；test 为测试集，用于评估算法的性能，但不会根据测试集上的表现再去调整模型或参数。</li>
<li>调用<code>apply()</code>函数，对数据集进行指定操作。</li>
</ul>
<br>
<p>这里的<code>CoupletDataset</code>数据集继承<code>TranslationDataset</code>，继承自<code>paddlenlp.datasets</code>，除以上通用用法外，还有一些个性设计：</p>
<ul>
<li>在<code>CoupletDataset class</code>中，还定义了<code>transform</code>函数，用于在每个句子的前后加上起始符<code>&lt;s&gt;</code>和结束符<code>&lt;/s&gt;</code>，并将原始数据映射成 id 序列。</li>
</ul>
<center><img src="https://ai-studio-static-online.cdn.bcebos.com/d6c36cfd88eb4d0d87884f6c9cd47e466c2b562411394606be6683af08733045" width="200" height="200" ></center>
<br><center>图3：token-to-id示意图</center></br>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_ds, dev_ds, test_ds = CoupletDataset.get_datasets([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;dev&#x27;</span>, <span class="string">&#x27;test&#x27;</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">100%|██████████| 21421/21421 [00:00&lt;00:00, 26153.43it/s]</span><br></pre></td></tr></table></figure>
<p>来看看数据集有多大，长什么样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(train_ds), <span class="built_in">len</span>(test_ds), <span class="built_in">len</span>(dev_ds))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加入了起始符和终止符</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span>(train_ds[i])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span>(test_ds[i])</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">702594 999 1000</span><br><span class="line">([1, 447, 3, 509, 153, 153, 279, 1517, 2], [1, 816, 294, 378, 9, 9, 142, 32, 2])</span><br><span class="line">([1, 594, 185, 10, 71, 18, 158, 912, 2], [1, 14, 105, 107, 835, 20, 268, 3855, 2])</span><br><span class="line">([1, 335, 830, 68, 425, 4, 482, 246, 2], [1, 94, 51, 1115, 23, 141, 761, 17, 2])</span><br><span class="line">([1, 126, 17, 217, 802, 4, 1103, 118, 2], [1, 125, 205, 47, 55, 57, 78, 15, 2])</span><br><span class="line">([1, 1203, 228, 390, 10, 1921, 827, 474, 2], [1, 1699, 89, 426, 317, 314, 43, 374, 2])</span><br><span class="line"></span><br><span class="line">([1, 6, 201, 350, 54, 1156, 2], [1, 64, 522, 305, 543, 102, 2])</span><br><span class="line">([1, 168, 1402, 61, 270, 11, 195, 253, 2], [1, 435, 782, 1046, 36, 188, 1016, 56, 2])</span><br><span class="line">([1, 744, 185, 744, 6, 18, 452, 16, 1410, 2], [1, 286, 102, 286, 74, 20, 669, 280, 261, 2])</span><br><span class="line">([1, 2577, 496, 1133, 60, 107, 2], [1, 1533, 318, 625, 1401, 172, 2])</span><br><span class="line">([1, 163, 261, 6, 64, 116, 350, 253, 2], [1, 96, 579, 13, 463, 16, 774, 586, 2])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vocab, _ = CoupletDataset.get_vocab()</span><br><span class="line">trg_idx2word = vocab.idx_to_token</span><br><span class="line">vocab_size = <span class="built_in">len</span>(vocab)</span><br><span class="line"></span><br><span class="line">pad_id = vocab[CoupletDataset.EOS_TOKEN]</span><br><span class="line">bos_id = vocab[CoupletDataset.BOS_TOKEN]</span><br><span class="line">eos_id = vocab[CoupletDataset.EOS_TOKEN]</span><br><span class="line"><span class="built_in">print</span> (pad_id, bos_id, eos_id)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2 1 2</span><br></pre></td></tr></table></figure>
<h2 id="构造-dataloder-2">构造 dataloder</h2>
<p>使用<code>paddle.io.DataLoader</code>来创建训练和预测时所需要的<code>DataLoader</code>对象。</p>
<p><code>paddle.io.DataLoader</code>返回一个迭代器，该迭代器根据<code>batch_sampler</code>指定的顺序迭代返回 dataset 数据。支持单进程或多进程加载数据，快！</p>
<br>
<p>接收如下重要参数：</p>
<ul>
<li><code>batch_sampler</code>：批采样器实例，用于在<code>paddle.io.DataLoader</code> 中迭代式获取 mini-batch 的样本下标数组，数组长度与 batch_size 一致。</li>
<li><code>collate_fn</code>：指定如何将样本列表组合为 mini-batch 数据。传给它参数需要是一个<code>callable</code>对象，需要实现对组建的 batch 的处理逻辑，并返回每个 batch 的数据。在这里传入的是<code>prepare_input</code>函数，对产生的数据进行 pad 操作，并返回实际长度等。</li>
</ul>
<p>PaddleNLP 提供了许多 NLP 任务中，用于数据处理、组 batch 数据的相关 API。</p>
<table>
<thead>
<tr>
<th>API</th>
<th style="text-align:left">简介</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>paddlenlp.data.Stack</code></td>
<td style="text-align:left">堆叠 N 个具有相同 shape 的输入数据来构建一个 batch</td>
</tr>
<tr>
<td><code>paddlenlp.data.Pad</code></td>
<td style="text-align:left">将长度不同的多个句子 padding 到统一长度，取 N 个输入数据中的最大长度</td>
</tr>
<tr>
<td><code>paddlenlp.data.Tuple</code></td>
<td style="text-align:left">将多个 batchify 函数包装在一起</td>
</tr>
</tbody>
</table>
<p>更多数据处理操作详见： <a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/data.md">https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/data.md</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_data_loader</span>(<span class="params">dataset</span>):</span><br><span class="line">    data_loader = paddle.io.DataLoader(</span><br><span class="line">        dataset,</span><br><span class="line">        batch_sampler=<span class="literal">None</span>,</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        collate_fn=partial(prepare_input, pad_id=pad_id))</span><br><span class="line">    <span class="keyword">return</span> data_loader</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_input</span>(<span class="params">insts, pad_id</span>):</span><br><span class="line">    src, src_length = Pad(pad_val=pad_id, ret_length=<span class="literal">True</span>)([inst[<span class="number">0</span>] <span class="keyword">for</span> inst <span class="keyword">in</span> insts])</span><br><span class="line">    tgt, tgt_length = Pad(pad_val=pad_id, ret_length=<span class="literal">True</span>)([inst[<span class="number">1</span>] <span class="keyword">for</span> inst <span class="keyword">in</span> insts])</span><br><span class="line">    tgt_mask = (tgt[:, :-<span class="number">1</span>] != pad_id).astype(paddle.get_default_dtype())</span><br><span class="line">    <span class="keyword">return</span> src, src_length, tgt[:, :-<span class="number">1</span>], tgt[:, <span class="number">1</span>:, np.newaxis], tgt_mask</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">use_gpu = <span class="literal">True</span></span><br><span class="line">device = paddle.set_device(<span class="string">&quot;gpu&quot;</span> <span class="keyword">if</span> use_gpu <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">num_layers = <span class="number">2</span></span><br><span class="line">dropout = <span class="number">0.2</span></span><br><span class="line">hidden_size =<span class="number">256</span></span><br><span class="line">max_grad_norm = <span class="number">5.0</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line">max_epoch = <span class="number">20</span></span><br><span class="line">model_path = <span class="string">&#x27;./couplet_models&#x27;</span></span><br><span class="line">log_freq = <span class="number">200</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define dataloader</span></span><br><span class="line">train_loader = create_data_loader(train_ds)</span><br><span class="line">test_loader = create_data_loader(test_ds)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(train_ds), <span class="built_in">len</span>(train_loader), batch_size)</span><br><span class="line"><span class="comment"># 702594 5490 128  共5490个batch</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> train_loader:</span><br><span class="line">    <span class="built_in">print</span> (<span class="built_in">len</span>(i))</span><br><span class="line">    <span class="keyword">for</span> ind, each <span class="keyword">in</span> <span class="built_in">enumerate</span>(i):</span><br><span class="line">        <span class="built_in">print</span> (ind, each.shape)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">702594 5490 128</span><br><span class="line">5</span><br><span class="line">0 [128, 18]</span><br><span class="line">1 [128]</span><br><span class="line">2 [128, 17]</span><br><span class="line">3 [128, 17, 1]</span><br><span class="line">4 [128, 17]</span><br></pre></td></tr></table></figure>
<h1>模型部分</h1>
<p>下图是带有 Attention 的 Seq2Seq 模型结构。下面我们分别定义网络的每个部分，最后构建 Seq2Seq 主网络。</p>
<center><img src="https://ai-studio-static-online.cdn.bcebos.com/8a9dda0434a14fb2a0837702e5f2f1096346810702aa4a6ab1fa7dafe548add6" width="600" height="600" ></center>
<br><center>图5：带有attention机制的encoder-decoder原理示意图</center></br>
<h2 id="定义-Encoder">定义 Encoder</h2>
<p>Encoder 部分非常简单，可以直接利用 PaddlePaddle2.0 提供的 RNN 系列 API 的<code>nn.LSTM</code>。</p>
<ol>
<li><code>nn.Embedding</code>：该接口用于构建 Embedding 的一个可调用对象，根据输入的 size (vocab_size, embedding_dim)自动构造一个二维 embedding 矩阵，用于 table-lookup。查表过程如下：</li>
</ol>
<center><img src="https://ai-studio-static-online.cdn.bcebos.com/54276195f4ce44b9ace89c5153300782a744a98343454410898fcfe81333f131" width="700" height="600" ></center>
<br><center>图5：token-to-id & 查表获取向量示意图</center></br>
<ol start="2">
<li><code>nn.LSTM</code>：提供序列，得到<code>encoder_output</code>和<code>encoder_state</code>。</li>
</ol>
<p>参数：</p>
<ul>
<li>input_size (int) 输入的大小。</li>
<li>hidden_size (int) - 隐藏状态大小。</li>
<li>num_layers (int，可选) - 网络层数。默认为 1。</li>
<li>direction (str，可选) - 网络迭代方向，可设置为 forward 或 bidirect（或 bidirectional）。默认为 forward。</li>
<li>time_major (bool，可选) - 指定 input 的第一个维度是否是 time steps。默认为 False。</li>
<li>dropout (float，可选) - dropout 概率，指的是出第一层外每层输入时的 dropout 概率。默认为 0。</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/layer/rnn/LSTM_cn.html">https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/layer/rnn/LSTM_cn.html</a></p>
<p>输出:</p>
<ul>
<li>
<p><code>outputs (Tensor)</code> - 输出，由前向和后向 cell 的输出拼接得到。</p>
<p>如果<code>time_major</code>为 True，则 Tensor 的形状为 <code>[time_steps, batch_size, num_directions * hidden_size]</code></p>
<p>如果<code>time_major</code>为 False，则 Tensor 的形状为 <code>[batch_size, time_steps, num_directions * hidden_size]</code>，当 direction 设置为 bidirectional 时，num_directions 等于 2，否则等于 1。</p>
</li>
<li>
<p><code>final_states (tuple)</code> - 最终状态,一个包含 h 和 c 的元组。</p>
<p>形状为<code>[num_lauers * num_directions, batch_size, hidden_size]</code>,当 direction 设置为 bidirectional 时，num_directions 等于 2，否则等于 1。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Seq2SeqEncoder</span>(nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, embed_dim, hidden_size, num_layers</span>):</span><br><span class="line">        <span class="built_in">super</span>(Seq2SeqEncoder, self).__init__()</span><br><span class="line">        self.embedder = nn.Embedding(vocab_size, embed_dim)</span><br><span class="line">        self.lstm = nn.LSTM(</span><br><span class="line">            input_size=embed_dim,      <span class="comment"># 句子长度</span></span><br><span class="line">            hidden_size=hidden_size,   <span class="comment"># 隐藏层大小</span></span><br><span class="line">            num_layers=num_layers,     <span class="comment"># lstm层数</span></span><br><span class="line">            dropout=<span class="number">0.2</span> <span class="keyword">if</span> num_layers &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0.</span>)  <span class="comment"># 随机丢弃神经元</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, sequence, sequence_length</span>):</span><br><span class="line">        inputs = self.embedder(sequence)</span><br><span class="line">        encoder_output, encoder_state = self.lstm(</span><br><span class="line">            inputs, sequence_length=sequence_length)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># y_out, (h, c)</span></span><br><span class="line">        <span class="comment"># encoder_output [128, 18, 256]  [batch_size,time_steps,hidden_size]</span></span><br><span class="line">        <span class="comment"># encoder_state (tuple) - 最终状态,一个包含h和c的元组。 [2, 128, 256] [2, 128, 256] [num_lauers * num_directions, batch_size, hidden_size]</span></span><br><span class="line">        <span class="keyword">return</span> encoder_output, encoder_state</span><br></pre></td></tr></table></figure>
<h2 id="定义-Decoder">定义 Decoder</h2>
<h3 id="定义-AttentionLayer">定义 AttentionLayer</h3>
<ol>
<li><code>nn.Linear</code>线性变换层传入 2 个参数</li>
</ol>
<ul>
<li>in_features (int) – 线性变换层输入单元的数目。</li>
<li>out_features (int) – 线性变换层输出单元的数目。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/img_convert/bfc49550cd55599e607e2eb1d188149a.png" alt=""></p>
<ol start="2">
<li><code>paddle.matmul</code>用于计算两个 Tensor 的乘积，遵循完整的广播规则，关于广播规则，请参考<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/01_paddle2.0_introduction/basic_concept/broadcasting_cn.html#cn-user-guide-broadcasting">广播 (broadcasting)</a> 。 并且其行为与 numpy.matmul 一致。</li>
</ol>
<ul>
<li>x (Tensor) : 输入变量，类型为 Tensor，数据类型为 float32， float64。</li>
<li>y (Tensor) : 输入变量，类型为 Tensor，数据类型为 float32， float64。</li>
<li>transpose_x (bool，可选) : 相乘前是否转置 x，默认值为 False。</li>
<li>transpose_y (bool，可选) : 相乘前是否转置 y，默认值为 False。</li>
</ul>
<br>
<ol start="3">
<li>
<p><code>paddle.unsqueeze</code>用于向输入 Tensor 的 Shape 中一个或多个位置（axis）插入尺寸为 1 的维度</p>
</li>
<li>
<p><code>paddle.add</code>逐元素相加算子，输入 x 与输入 y 逐元素相加，并将各个位置的输出元素保存到返回结果中。</p>
</li>
</ol>
<p>输入 x 与输入 y 必须可以广播为相同形状。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AttentionLayer</span>(nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, hidden_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(AttentionLayer, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># MLP</span></span><br><span class="line">        self.input_proj = nn.Linear(hidden_size, hidden_size)</span><br><span class="line">        self.output_proj = nn.Linear(hidden_size + hidden_size, hidden_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, hidden, encoder_output, encoder_padding_mask</span>):</span><br><span class="line"></span><br><span class="line">        encoder_output = self.input_proj(encoder_output)</span><br><span class="line"></span><br><span class="line">        attn_scores = paddle.matmul(</span><br><span class="line">            paddle.unsqueeze(hidden, [<span class="number">1</span>]), encoder_output, transpose_y=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># print(&#x27;attention score&#x27;, attn_scores.shape) #[128, 1, 18]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> encoder_padding_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            attn_scores = paddle.add(attn_scores, encoder_padding_mask)</span><br><span class="line"></span><br><span class="line">        attn_scores = F.softmax(attn_scores)</span><br><span class="line"></span><br><span class="line">        attn_out = paddle.squeeze(</span><br><span class="line">            paddle.matmul(attn_scores, encoder_output), [<span class="number">1</span>])</span><br><span class="line">        <span class="comment"># print(&#x27;1 attn_out&#x27;, attn_out.shape) #[128, 256]</span></span><br><span class="line"></span><br><span class="line">        attn_out = paddle.concat([attn_out, hidden], <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># print(&#x27;2 attn_out&#x27;, attn_out.shape) #[128, 512]</span></span><br><span class="line"></span><br><span class="line">        attn_out = self.output_proj(attn_out)</span><br><span class="line">        <span class="comment"># print(&#x27;3 attn_out&#x27;, attn_out.shape) #[128, 256]</span></span><br><span class="line">        <span class="keyword">return</span> attn_out</span><br></pre></td></tr></table></figure>
<h3 id="定义-Seq2SeqDecoderCell">定义 Seq2SeqDecoderCell</h3>
<p>由于 Decoder 部分是带有 attention 的 LSTM，我们不能复用<code>nn.LSTM</code>，所以需要定义<code>Seq2SeqDecoderCell</code></p>
<ol>
<li><code>nn.LayerList</code> 用于保存子层列表，它包含的子层将被正确地注册和添加。列表中的子层可以像常规 python 列表一样被索引。这里添加了 num_layers=2 层 lstm。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Seq2SeqDecoderCell</span>(nn.RNNCellBase):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_layers, input_size, hidden_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(Seq2SeqDecoderCell, self).__init__()</span><br><span class="line">        self.dropout = nn.Dropout(<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># num_layers=2时 第一层输入为input_size + hidden_size 第二层输入为 hidden_size</span></span><br><span class="line">        self.lstm_cells = nn.LayerList([</span><br><span class="line">            nn.LSTMCell(</span><br><span class="line">                input_size=input_size + hidden_size <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> hidden_size,</span><br><span class="line">                hidden_size=hidden_size) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layers)</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">        self.attention_layer = AttentionLayer(hidden_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                step_input,</span></span><br><span class="line"><span class="params">                states,</span></span><br><span class="line"><span class="params">                encoder_output,</span></span><br><span class="line"><span class="params">                encoder_padding_mask=<span class="literal">None</span></span>):</span><br><span class="line"></span><br><span class="line">        lstm_states, input_feed = states</span><br><span class="line">        new_lstm_states = []</span><br><span class="line"></span><br><span class="line">        step_input = paddle.concat([step_input, input_feed], <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> i, lstm_cell <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.lstm_cells):</span><br><span class="line">            out, new_lstm_state = lstm_cell(step_input, lstm_states[i])</span><br><span class="line">            step_input = self.dropout(out)</span><br><span class="line">            new_lstm_states.append(new_lstm_state)</span><br><span class="line">        out = self.attention_layer(step_input, encoder_output,</span><br><span class="line">                                   encoder_padding_mask)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out, [new_lstm_states, out]</span><br></pre></td></tr></table></figure>
<h3 id="定义-Seq2SeqDecoder">定义 Seq2SeqDecoder</h3>
<p>有了<code>Seq2SeqDecoderCell</code>，就可以构建<code>Seq2SeqDecoder</code>了</p>
<br>
<ol>
<li><code>paddle.nn.RNN</code> 该 OP 是循环神经网络（RNN）的封装，将输入的 Cell 封装为一个循环神经网络。它能够重复执行 cell.forward() 直到遍历完 input 中的所有 Tensor。</li>
</ol>
<ul>
<li>cell (RNNCellBase) - RNNCellBase 类的一个实例。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Seq2SeqDecoder</span>(nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, embed_dim, hidden_size, num_layers</span>):</span><br><span class="line">        <span class="built_in">super</span>(Seq2SeqDecoder, self).__init__()</span><br><span class="line">        self.embedder = nn.Embedding(vocab_size, embed_dim)</span><br><span class="line">        self.lstm_attention = nn.RNN(</span><br><span class="line">            Seq2SeqDecoderCell(num_layers, embed_dim, hidden_size))</span><br><span class="line">        self.output_layer = nn.Linear(hidden_size, vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, trg, decoder_initial_states, encoder_output,</span></span><br><span class="line"><span class="params">                encoder_padding_mask</span>):</span><br><span class="line">        inputs = self.embedder(trg)</span><br><span class="line"></span><br><span class="line">        decoder_output, _ = self.lstm_attention(</span><br><span class="line">            inputs,</span><br><span class="line">            initial_states=decoder_initial_states,</span><br><span class="line">            encoder_output=encoder_output,</span><br><span class="line">            encoder_padding_mask=encoder_padding_mask)</span><br><span class="line">        predict = self.output_layer(decoder_output)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> predict</span><br></pre></td></tr></table></figure>
<h2 id="构建主网络-Seq2SeqAttnModel">构建主网络 Seq2SeqAttnModel</h2>
<p>Encoder 和 Decoder 定义好之后，网络就可以构建起来了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Seq2SeqAttnModel</span>(nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, embed_dim, hidden_size, num_layers,</span></span><br><span class="line"><span class="params">                 eos_id=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Seq2SeqAttnModel, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.eos_id = eos_id</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.INF = <span class="number">1e9</span></span><br><span class="line">        self.encoder = Seq2SeqEncoder(vocab_size, embed_dim, hidden_size,</span><br><span class="line">                                      num_layers)</span><br><span class="line">        self.decoder = Seq2SeqDecoder(vocab_size, embed_dim, hidden_size,</span><br><span class="line">                                      num_layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, src, src_length, trg</span>):</span><br><span class="line">        <span class="comment"># encoder_output 各时刻的输出h</span></span><br><span class="line">        <span class="comment"># encoder_final_state 最后时刻的输出h，和记忆信号c</span></span><br><span class="line">        encoder_output, encoder_final_state = self.encoder(src, src_length)</span><br><span class="line">        <span class="comment"># print(&#x27;encoder_output shape&#x27;, encoder_output.shape)  #  [128, 18, 256]  [batch_size,time_steps,hidden_size]</span></span><br><span class="line">        <span class="comment"># print(&#x27;encoder_final_states shape&#x27;, encoder_final_state[0].shape, encoder_final_state[1].shape) #[2, 128, 256] [2, 128, 256] [num_lauers * num_directions, batch_size, hidden_size]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Transfer shape of encoder_final_states to [num_layers, 2, batch_size, hidden_size]？？？</span></span><br><span class="line">        encoder_final_states = [</span><br><span class="line">            (encoder_final_state[<span class="number">0</span>][i], encoder_final_state[<span class="number">1</span>][i])</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_layers)</span><br><span class="line">        ]</span><br><span class="line">        <span class="comment"># print(&#x27;encoder_final_states shape&#x27;, encoder_final_states[0][0].shape, encoder_final_states[0][1].shape) #[128, 256] [128, 256]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Construct decoder initial states: use input_feed and the shape is</span></span><br><span class="line">        <span class="comment"># [[h,c] * num_layers, input_feed], consistent with Seq2SeqDecoderCell.states</span></span><br><span class="line">        decoder_initial_states = [</span><br><span class="line">            encoder_final_states,</span><br><span class="line">            self.decoder.lstm_attention.cell.get_initial_states(</span><br><span class="line">                batch_ref=encoder_output, shape=[self.hidden_size])</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Build attention mask to avoid paying attention on padddings</span></span><br><span class="line">        src_mask = (src != self.eos_id).astype(paddle.get_default_dtype())</span><br><span class="line">        <span class="comment"># print (&#x27;src_mask shape&#x27;, src_mask.shape)  #[128, 18]</span></span><br><span class="line">        <span class="comment"># print(src_mask[0, :])</span></span><br><span class="line"></span><br><span class="line">        encoder_padding_mask = (src_mask - <span class="number">1.0</span>) * self.INF</span><br><span class="line">        <span class="comment"># print (&#x27;encoder_padding_mask&#x27;, encoder_padding_mask.shape)  #[128, 18]</span></span><br><span class="line">        <span class="comment"># print(encoder_padding_mask[0, :])</span></span><br><span class="line"></span><br><span class="line">        encoder_padding_mask = paddle.unsqueeze(encoder_padding_mask, [<span class="number">1</span>])</span><br><span class="line">        <span class="comment"># print(&#x27;encoder_padding_mask&#x27;, encoder_padding_mask.shape)  #[128, 1, 18]</span></span><br><span class="line"></span><br><span class="line">        predict = self.decoder(trg, decoder_initial_states, encoder_output,</span><br><span class="line">                               encoder_padding_mask)</span><br><span class="line">        <span class="comment"># print(&#x27;predict&#x27;, predict.shape)   #[128, 17, 7931]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> predict</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="定义损失函数">定义损失函数</h2>
<p>这里使用的是交叉熵损失函数，我们需要将 padding 位置的 loss 置为 0，因此需要在损失函数中引入<code>trg_mask</code>参数，由于 PaddlePaddle 框架提供的<code>paddle.nn.CrossEntropyLoss</code>不能接受<code>trg_mask</code>参数，因此在这里需要重新定义：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CrossEntropyCriterion</span>(nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(CrossEntropyCriterion, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, predict, label, trg_mask</span>):</span><br><span class="line">        cost = F.softmax_with_cross_entropy(</span><br><span class="line">            logits=predict, label=label, soft_label=<span class="literal">False</span>)</span><br><span class="line">        cost = paddle.squeeze(cost, axis=[<span class="number">2</span>])</span><br><span class="line">        masked_cost = cost * trg_mask</span><br><span class="line">        batch_mean_cost = paddle.mean(masked_cost, axis=[<span class="number">0</span>])</span><br><span class="line">        seq_cost = paddle.<span class="built_in">sum</span>(batch_mean_cost)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> seq_cost</span><br></pre></td></tr></table></figure>
<h1>执行过程</h1>
<h2 id="训练过程">训练过程</h2>
<p>使用高层 API 执行训练，需要调用<code>prepare</code>和<code>fit</code>函数。</p>
<p>在<code>prepare</code>函数中，配置优化器、损失函数，以及评价指标。其中评价指标使用的是 PaddleNLP 提供的困惑度计算 API <code>paddlenlp.metrics.Perplexity</code>。</p>
<p>如果你安装了 VisualDL，可以在 fit 中添加一个 callbacks 参数使用 VisualDL 观测你的训练过程，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model.fit(train_data=train_loader,</span><br><span class="line">            epochs=max_epoch,</span><br><span class="line">            eval_freq=<span class="number">1</span>,</span><br><span class="line">            save_freq=<span class="number">1</span>,</span><br><span class="line">            save_dir=model_path,</span><br><span class="line">            log_freq=log_freq,</span><br><span class="line">            callbacks=[paddle.callbacks.VisualDL(<span class="string">&#x27;./log&#x27;</span>)])</span><br></pre></td></tr></table></figure>
<p>在这里，由于对联生成任务没有明确的评价指标，因此，可以在保存的多个模型中，通过人工评判生成结果选择最好的模型。</p>
<p>本项目中，为了便于演示，已经将训练好的模型参数载入模型，并省略了训练过程。读者自己实验的时候，可以尝试自行修改超参数，调用下面被注释掉的<code>fit</code>函数，重新进行训练。</p>
<p>如果读者想要在更短的时间内得到效果不错的模型，可以使用预训练模型技术，例如<a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/1339888">《预训练模型 ERNIE-GEN 自动写诗》</a>项目为大家展示了如何利用预训练的生成模型进行训练。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">model = paddle.Model(Seq2SeqAttnModel(vocab_size, hidden_size, hidden_size, num_layers, pad_id))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">optimizer = paddle.optimizer.Adam(</span><br><span class="line">    learning_rate=learning_rate, parameters=model.parameters())</span><br><span class="line"></span><br><span class="line">model.load(<span class="string">&#x27;couplet_models/model_18&#x27;</span>)</span><br><span class="line"></span><br><span class="line">model.prepare(optimizer, CrossEntropyCriterion(), Perplexity())</span><br><span class="line"></span><br><span class="line">model.fit(train_data=train_loader,</span><br><span class="line">            epochs=<span class="number">1</span>,</span><br><span class="line">            eval_freq=<span class="number">1</span>,</span><br><span class="line">            save_freq=<span class="number">5</span>,</span><br><span class="line">            save_dir=model_path,</span><br><span class="line">            log_freq=log_freq)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">The loss value printed in the log is the current step, and the metric is the average value of previous step.</span><br><span class="line">Epoch 1/1</span><br><span class="line">step  200/5490 - loss: 29.0412 - Perplexity: 28.2248 - 72ms/step</span><br><span class="line">step  400/5490 - loss: 31.3796 - Perplexity: 28.4654 - 72ms/step</span><br><span class="line">step  600/5490 - loss: 30.2077 - Perplexity: 28.4107 - 72ms/step</span><br><span class="line">step  800/5490 - loss: 30.8788 - Perplexity: 28.4995 - 73ms/step</span><br><span class="line">step 1000/5490 - loss: 28.7426 - Perplexity: 28.7224 - 72ms/step</span><br><span class="line">step 1200/5490 - loss: 32.3817 - Perplexity: 28.8973 - 71ms/step</span><br><span class="line">step 1400/5490 - loss: 31.8954 - Perplexity: 28.9987 - 71ms/step</span><br><span class="line">step 1600/5490 - loss: 30.3898 - Perplexity: 29.0871 - 71ms/step</span><br><span class="line">step 1800/5490 - loss: 32.1190 - Perplexity: 29.1689 - 72ms/step</span><br><span class="line">step 2000/5490 - loss: 32.3143 - Perplexity: 29.2302 - 72ms/step</span><br><span class="line">step 2200/5490 - loss: 31.6980 - Perplexity: 29.2954 - 71ms/step</span><br><span class="line">step 2400/5490 - loss: 29.9607 - Perplexity: 29.3576 - 71ms/step</span><br><span class="line">step 2600/5490 - loss: 31.6618 - Perplexity: 29.3990 - 71ms/step</span><br><span class="line">step 2800/5490 - loss: 35.0776 - Perplexity: 29.4590 - 71ms/step</span><br><span class="line">step 3000/5490 - loss: 30.2568 - Perplexity: 29.5161 - 71ms/step</span><br><span class="line">step 3200/5490 - loss: 29.4113 - Perplexity: 29.5687 - 70ms/step</span><br><span class="line">step 3400/5490 - loss: 32.5356 - Perplexity: 29.6236 - 71ms/step</span><br><span class="line">step 3600/5490 - loss: 30.4489 - Perplexity: 29.6678 - 71ms/step</span><br><span class="line">step 3800/5490 - loss: 30.7146 - Perplexity: 29.6957 - 71ms/step</span><br><span class="line">step 4000/5490 - loss: 31.3794 - Perplexity: 29.7266 - 71ms/step</span><br><span class="line">step 4200/5490 - loss: 33.3526 - Perplexity: 29.7954 - 71ms/step</span><br><span class="line">step 4400/5490 - loss: 30.6265 - Perplexity: 29.8421 - 71ms/step</span><br><span class="line">step 4600/5490 - loss: 30.8788 - Perplexity: 29.8787 - 71ms/step</span><br><span class="line">step 4800/5490 - loss: 28.6094 - Perplexity: 29.9268 - 71ms/step</span><br><span class="line">step 5000/5490 - loss: 31.5489 - Perplexity: 29.9706 - 71ms/step</span><br><span class="line">step 5200/5490 - loss: 31.6076 - Perplexity: 30.0078 - 71ms/step</span><br><span class="line">step 5400/5490 - loss: 31.7482 - Perplexity: 30.0651 - 72ms/step</span><br><span class="line">step 5490/5490 - loss: 31.3067 - Perplexity: 30.0837 - 72ms/step</span><br><span class="line">save checkpoint at /home/aistudio/couplet_models/0</span><br><span class="line">save checkpoint at /home/aistudio/couplet_models/final</span><br></pre></td></tr></table></figure>
<h2 id="模型预测-3">模型预测</h2>
<h3 id="定义预测网络-Seq2SeqAttnInferModel">定义预测网络 Seq2SeqAttnInferModel</h3>
<p>预测网络继承上面的主网络<code>Seq2SeqAttnModel</code>，定义子类<code>Seq2SeqAttnInferModel</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Seq2SeqAttnInferModel</span>(<span class="title class_ inherited__">Seq2SeqAttnModel</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 vocab_size,</span></span><br><span class="line"><span class="params">                 embed_dim,</span></span><br><span class="line"><span class="params">                 hidden_size,</span></span><br><span class="line"><span class="params">                 num_layers,</span></span><br><span class="line"><span class="params">                 bos_id=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 eos_id=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 beam_size=<span class="number">4</span>,</span></span><br><span class="line"><span class="params">                 max_out_len=<span class="number">256</span></span>):</span><br><span class="line">        self.bos_id = bos_id</span><br><span class="line">        self.beam_size = beam_size</span><br><span class="line">        self.max_out_len = max_out_len</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        <span class="built_in">super</span>(Seq2SeqAttnInferModel, self).__init__(</span><br><span class="line">            vocab_size, embed_dim, hidden_size, num_layers, eos_id)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Dynamic decoder for inference</span></span><br><span class="line">        self.beam_search_decoder = nn.BeamSearchDecoder(</span><br><span class="line">            self.decoder.lstm_attention.cell,</span><br><span class="line">            start_token=bos_id,</span><br><span class="line">            end_token=eos_id,</span><br><span class="line">            beam_size=beam_size,</span><br><span class="line">            embedding_fn=self.decoder.embedder,</span><br><span class="line">            output_fn=self.decoder.output_layer)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, src, src_length</span>):</span><br><span class="line">        encoder_output, encoder_final_state = self.encoder(src, src_length)</span><br><span class="line"></span><br><span class="line">        encoder_final_state = [</span><br><span class="line">            (encoder_final_state[<span class="number">0</span>][i], encoder_final_state[<span class="number">1</span>][i])</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_layers)</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Initial decoder initial states</span></span><br><span class="line">        decoder_initial_states = [</span><br><span class="line">            encoder_final_state,</span><br><span class="line">            self.decoder.lstm_attention.cell.get_initial_states(</span><br><span class="line">                batch_ref=encoder_output, shape=[self.hidden_size])</span><br><span class="line">        ]</span><br><span class="line">        <span class="comment"># Build attention mask to avoid paying attention on paddings</span></span><br><span class="line">        src_mask = (src != self.eos_id).astype(paddle.get_default_dtype())</span><br><span class="line"></span><br><span class="line">        encoder_padding_mask = (src_mask - <span class="number">1.0</span>) * self.INF</span><br><span class="line">        encoder_padding_mask = paddle.unsqueeze(encoder_padding_mask, [<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Tile the batch dimension with beam_size</span></span><br><span class="line">        encoder_output = nn.BeamSearchDecoder.tile_beam_merge_with_batch(</span><br><span class="line">            encoder_output, self.beam_size)</span><br><span class="line">        encoder_padding_mask = nn.BeamSearchDecoder.tile_beam_merge_with_batch(</span><br><span class="line">            encoder_padding_mask, self.beam_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Dynamic decoding with beam search</span></span><br><span class="line">        seq_output, _ = nn.dynamic_decode(</span><br><span class="line">            decoder=self.beam_search_decoder,</span><br><span class="line">            inits=decoder_initial_states,</span><br><span class="line">            max_step_num=self.max_out_len,</span><br><span class="line">            encoder_output=encoder_output,</span><br><span class="line">            encoder_padding_mask=encoder_padding_mask)</span><br><span class="line">        <span class="keyword">return</span> seq_output</span><br></pre></td></tr></table></figure>
<h2 id="解码部分">解码部分</h2>
<p>接下来对我们的任务选择 beam search 解码方式，可以指定 beam_size 为 10。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">post_process_seq</span>(<span class="params">seq, bos_idx, eos_idx, output_bos=<span class="literal">False</span>, output_eos=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Post-process the decoded sequence.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    eos_pos = <span class="built_in">len</span>(seq) - <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i, idx <span class="keyword">in</span> <span class="built_in">enumerate</span>(seq):</span><br><span class="line">        <span class="keyword">if</span> idx == eos_idx:</span><br><span class="line">            eos_pos = i</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    seq = [</span><br><span class="line">        idx <span class="keyword">for</span> idx <span class="keyword">in</span> seq[:eos_pos + <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> (output_bos <span class="keyword">or</span> idx != bos_idx) <span class="keyword">and</span> (output_eos <span class="keyword">or</span> idx != eos_idx)</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">return</span> seq</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">beam_size = <span class="number">10</span></span><br><span class="line"><span class="comment"># init_from_ckpt = &#x27;./couplet_models/0&#x27; # for test</span></span><br><span class="line"><span class="comment"># infer_output_file = &#x27;./infer_output.txt&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># test_loader, vocab_size, pad_id, bos_id, eos_id = create_data_loader(test_ds, batch_size)</span></span><br><span class="line"><span class="comment"># vocab, _ = CoupletDataset.get_vocab()</span></span><br><span class="line"><span class="comment"># trg_idx2word = vocab.idx_to_token</span></span><br><span class="line"></span><br><span class="line">model = paddle.Model(</span><br><span class="line">    Seq2SeqAttnInferModel(</span><br><span class="line">        vocab_size,</span><br><span class="line">        hidden_size,</span><br><span class="line">        hidden_size,</span><br><span class="line">        num_layers,</span><br><span class="line">        bos_id=bos_id,</span><br><span class="line">        eos_id=eos_id,</span><br><span class="line">        beam_size=beam_size,</span><br><span class="line">        max_out_len=<span class="number">256</span>))</span><br><span class="line"></span><br><span class="line">model.prepare()</span><br></pre></td></tr></table></figure>
<p>在预测之前，我们需要将训练好的模型参数 load 进预测网络，之后我们就可以根据对联的上联，生成对联的下联啦！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load(<span class="string">&#x27;couplet_models/final&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">test_ds = CoupletDataset.get_datasets([<span class="string">&#x27;test&#x27;</span>])</span><br><span class="line">idx = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> test_loader():</span><br><span class="line">    inputs = data[:<span class="number">2</span>]</span><br><span class="line">    finished_seq = model.predict_batch(inputs=<span class="built_in">list</span>(inputs))[<span class="number">0</span>]</span><br><span class="line">    finished_seq = finished_seq[:, :, np.newaxis] <span class="keyword">if</span> <span class="built_in">len</span>(</span><br><span class="line">        finished_seq.shape) == <span class="number">2</span> <span class="keyword">else</span> finished_seq</span><br><span class="line">    finished_seq = np.transpose(finished_seq, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ins <span class="keyword">in</span> finished_seq:</span><br><span class="line">        <span class="keyword">for</span> beam <span class="keyword">in</span> ins:</span><br><span class="line">            id_list = post_process_seq(beam, bos_id, eos_id)</span><br><span class="line">            word_list_l = [trg_idx2word[<span class="built_in">id</span>] <span class="keyword">for</span> <span class="built_in">id</span> <span class="keyword">in</span> test_ds[idx][<span class="number">0</span>]][<span class="number">1</span>:-<span class="number">1</span>]</span><br><span class="line">            word_list_r = [trg_idx2word[<span class="built_in">id</span>] <span class="keyword">for</span> <span class="built_in">id</span> <span class="keyword">in</span> id_list]</span><br><span class="line">            sequence = <span class="string">&quot;上联: &quot;</span>+<span class="string">&quot; &quot;</span>.join(word_list_l)+<span class="string">&quot;\t下联: &quot;</span>+<span class="string">&quot; &quot;</span>.join(word_list_r) + <span class="string">&quot;\n&quot;</span></span><br><span class="line">            <span class="built_in">print</span>(sequence)</span><br><span class="line">            idx += <span class="number">1</span></span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<h1>PaddleNLP 更多教程</h1>
<ul>
<li><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/1283423">使用 seq2vec 模块进行句子情感分析</a></li>
<li><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/1294333">使用预训练模型 ERNIE 优化情感分析</a></li>
<li><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/1317771">使用 BiGRU-CRF 模型完成快递单信息抽取</a></li>
<li><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/1329361">使用预训练模型 ERNIE 优化快递单信息抽取</a></li>
<li><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/1339888">使用预训练模型 ERNIE-GEN 实现智能写诗</a></li>
<li><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/1290873">使用 TCN 网络完成新冠疫情病例数预测</a></li>
<li><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/1339612">使用预训练模型完成阅读理解</a></li>
<li><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/1468469">自定义数据集实现文本多分类任务</a></li>
</ul>
<h1>加入交流群，一起学习吧</h1>
<p>现在就加入 PaddleNLP 的 QQ 技术交流群，一起交流 NLP 技术吧！</p>
<img src="https://ai-studio-static-online.cdn.bcebos.com/d953727af0c24a7c806ab529495f0904f22f809961be420b8c88cdf59b837394" width="200" height="250" >
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="http://example.com">YUAN Tingyi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2022/06/01/febcf959471d4ccb8df3760a6117820a/">http://example.com/2022/06/01/febcf959471d4ccb8df3760a6117820a/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/2.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/gh/overtrue/share.js@master/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/06/01/63e0d330af4f4b7c818e86e056b93ab8/"><img class="prev-cover" src="/img/6.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">paddle2.0高层API实现人脸关键点检测(人脸关键点检测综述_自定义网络_paddleHub_趣味ps)</div></div></a></div><div class="next-post pull-right"><a href="/2022/06/01/4b627c671c26401e94c82e1860ce030d/"><img class="next-cover" src="/img/5.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">paddle2.0高层API快速实现LeNet(MNIST手写数字识别)</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div><div id="comment-switch"><span class="first-comment">Valine</span><span class="switch-btn"></span><span class="second-comment">Disqus</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">YUAN Tingyi</div><div class="author-info__description">XianrenYty</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">28</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/XianrenYty"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E5%AF%B9%E8%81%94%E9%83%A8%E5%88%86%E7%BB%93%E6%9E%9C"><span class="toc-number">1.</span> <span class="toc-text">生成对联部分结果</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number"></span> <span class="toc-text">数据部分</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D-2"><span class="toc-number">1.</span> <span class="toc-text">数据集介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.</span> <span class="toc-text">加载数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E9%80%A0-dataloder-2"><span class="toc-number">3.</span> <span class="toc-text">构造 dataloder</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number"></span> <span class="toc-text">模型部分</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-Encoder"><span class="toc-number">1.</span> <span class="toc-text">定义 Encoder</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-Decoder"><span class="toc-number">2.</span> <span class="toc-text">定义 Decoder</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-AttentionLayer"><span class="toc-number">2.1.</span> <span class="toc-text">定义 AttentionLayer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-Seq2SeqDecoderCell"><span class="toc-number">2.2.</span> <span class="toc-text">定义 Seq2SeqDecoderCell</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-Seq2SeqDecoder"><span class="toc-number">2.3.</span> <span class="toc-text">定义 Seq2SeqDecoder</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E4%B8%BB%E7%BD%91%E7%BB%9C-Seq2SeqAttnModel"><span class="toc-number">3.</span> <span class="toc-text">构建主网络 Seq2SeqAttnModel</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">4.</span> <span class="toc-text">定义损失函数</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number"></span> <span class="toc-text">执行过程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="toc-number">1.</span> <span class="toc-text">训练过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B-3"><span class="toc-number">2.</span> <span class="toc-text">模型预测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E9%A2%84%E6%B5%8B%E7%BD%91%E7%BB%9C-Seq2SeqAttnInferModel"><span class="toc-number">2.1.</span> <span class="toc-text">定义预测网络 Seq2SeqAttnInferModel</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E7%A0%81%E9%83%A8%E5%88%86"><span class="toc-number">3.</span> <span class="toc-text">解码部分</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number"></span> <span class="toc-text">PaddleNLP 更多教程</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number"></span> <span class="toc-text">加入交流群，一起学习吧</span></a></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/06/01/fd61228310d24c999c625f49b503f7ce/" title="train_test_split 参数详解"><img src="/img/8.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="train_test_split 参数详解"/></a><div class="content"><a class="title" href="/2022/06/01/fd61228310d24c999c625f49b503f7ce/" title="train_test_split 参数详解">train_test_split 参数详解</a><time datetime="2022-06-01T12:52:00.000Z" title="Created 2022-06-01 20:52:00">2022-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/01/224bdd4444be4fe0b7826959bc6b40a4/" title="StandardScaler(sklearn)参数详解"><img src="/img/1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="StandardScaler(sklearn)参数详解"/></a><div class="content"><a class="title" href="/2022/06/01/224bdd4444be4fe0b7826959bc6b40a4/" title="StandardScaler(sklearn)参数详解">StandardScaler(sklearn)参数详解</a><time datetime="2022-06-01T12:51:39.966Z" title="Created 2022-06-01 20:51:39">2022-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/01/2fd9e712ce6b4a49a24775586e47e44b/" title="八大排序算法(Python实现)"><img src="/img/6.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="八大排序算法(Python实现)"/></a><div class="content"><a class="title" href="/2022/06/01/2fd9e712ce6b4a49a24775586e47e44b/" title="八大排序算法(Python实现)">八大排序算法(Python实现)</a><time datetime="2022-06-01T12:51:26.086Z" title="Created 2022-06-01 20:51:26">2022-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/01/9d8547900901416593ba964e6757c6c3/" title="ResNet"><img src="/img/2.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ResNet"/></a><div class="content"><a class="title" href="/2022/06/01/9d8547900901416593ba964e6757c6c3/" title="ResNet">ResNet</a><time datetime="2022-06-01T12:50:56.055Z" title="Created 2022-06-01 20:50:56">2022-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/01/b6a6cbce3d7f45a8b2511edf86fb5a24/" title="Paddle高层API实现图像分类（CIFAR-100数据集_ResNet101）"><img src="/img/8.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Paddle高层API实现图像分类（CIFAR-100数据集_ResNet101）"/></a><div class="content"><a class="title" href="/2022/06/01/b6a6cbce3d7f45a8b2511edf86fb5a24/" title="Paddle高层API实现图像分类（CIFAR-100数据集_ResNet101）">Paddle高层API实现图像分类（CIFAR-100数据集_ResNet101）</a><time datetime="2022-06-01T12:48:23.363Z" title="Created 2022-06-01 20:48:23">2022-06-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By YUAN Tingyi</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'http://example.com/2022/06/01/febcf959471d4ccb8df3760a6117820a/'
    this.page.identifier = '2022/06/01/febcf959471d4ccb8df3760a6117820a/'
    this.page.title = 'paddle2.0高层API实现基于seq2seq的对联生成'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }
}

if ('Valine' === 'Disqus' || !true) {
  if (true) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>