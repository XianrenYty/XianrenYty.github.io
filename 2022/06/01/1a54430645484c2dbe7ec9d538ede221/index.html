<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>paddle2.0高层API实现ResNet50(十二生肖分类实战) | Personnal Blog of YUAN Tingyi</title><meta name="author" content="YUAN Tingyi"><meta name="copyright" content="YUAN Tingyi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="[toc] 『深度学习 7 日打卡营·快速入门特辑』 零基础解锁深度学习神器飞桨框架高层 API，七天时间助你掌握 CV、NLP 领域最火模型及应用。  课程地址  传送门：https:&#x2F;&#x2F;aistudio.baidu.com&#x2F;aistudio&#x2F;course&#x2F;introduce&#x2F;6771  目标   掌握深度学习常用模型基础知识 熟练掌握一种国产开源深度学习框架 具备独立完成相关深度学习任务的能力">
<meta property="og:type" content="article">
<meta property="og:title" content="paddle2.0高层API实现ResNet50(十二生肖分类实战)">
<meta property="og:url" content="http://example.com/2022/06/01/1a54430645484c2dbe7ec9d538ede221/index.html">
<meta property="og:site_name" content="Personnal Blog of YUAN Tingyi">
<meta property="og:description" content="[toc] 『深度学习 7 日打卡营·快速入门特辑』 零基础解锁深度学习神器飞桨框架高层 API，七天时间助你掌握 CV、NLP 领域最火模型及应用。  课程地址  传送门：https:&#x2F;&#x2F;aistudio.baidu.com&#x2F;aistudio&#x2F;course&#x2F;introduce&#x2F;6771  目标   掌握深度学习常用模型基础知识 熟练掌握一种国产开源深度学习框架 具备独立完成相关深度学习任务的能力">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/5.jpg">
<meta property="article:published_time" content="2022-06-01T12:47:45.956Z">
<meta property="article:modified_time" content="2022-06-01T12:47:58.388Z">
<meta property="article:author" content="YUAN Tingyi">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/5.jpg"><link rel="shortcut icon" href="/img/favicon-32x32.png"><link rel="canonical" href="http://example.com/2022/06/01/1a54430645484c2dbe7ec9d538ede221/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'paddle2.0高层API实现ResNet50(十二生肖分类实战)',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-06-01 20:47:58'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">28</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/5.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Personnal Blog of YUAN Tingyi</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">paddle2.0高层API实现ResNet50(十二生肖分类实战)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-06-01T12:47:45.956Z" title="Created 2022-06-01 20:47:45">2022-06-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-06-01T12:47:58.388Z" title="Updated 2022-06-01 20:47:58">2022-06-01</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="paddle2.0高层API实现ResNet50(十二生肖分类实战)"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>[toc]</p>
<p>『深度学习 7 日打卡营·快速入门特辑』</p>
<p>零基础解锁深度学习神器飞桨框架高层 API，七天时间助你掌握 CV、NLP 领域最火模型及应用。</p>
<ol>
<li>课程地址</li>
</ol>
<p>传送门：<a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/course/introduce/6771">https://aistudio.baidu.com/aistudio/course/introduce/6771</a></p>
<ol start="2">
<li>目标</li>
</ol>
<ul>
<li>掌握深度学习常用模型基础知识</li>
<li>熟练掌握一种国产开源深度学习框架</li>
<li>具备独立完成相关深度学习任务的能力</li>
<li>能用所学为 AI 加一份年味</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/img_convert/67c2cc646d638522a2c7a8b82bd0bf73.png"></p>
<h1 id="①-问题定义"><a href="#①-问题定义" class="headerlink" title="① 问题定义"></a>① 问题定义</h1><p>十二生肖分类的本质是图像分类任务，我们采用 CNN 网络结构进行相关实践。</p>
<h1 id="②-数据准备"><a href="#②-数据准备" class="headerlink" title="② 数据准备"></a>② 数据准备</h1><h2 id="2-1-解压缩数据集"><a href="#2-1-解压缩数据集" class="headerlink" title="2.1 解压缩数据集"></a>2.1 解压缩数据集</h2><p>我们将网上获取的数据集以压缩包的方式上传到 aistudio 数据集中，并加载到我们的项目内。</p>
<p>在使用之前我们进行数据集压缩包的一个解压。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!unzip -q -o data/data68755/signs.<span class="built_in">zip</span></span><br></pre></td></tr></table></figure>

<h2 id="2-2-数据标注"><a href="#2-2-数据标注" class="headerlink" title="2.2 数据标注"></a>2.2 数据标注</h2><p>我们先看一下解压缩后的数据集长成什么样子。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── <span class="built_in">test</span></span><br><span class="line">│   ├── dog</span><br><span class="line">│   ├── dragon</span><br><span class="line">│   ├── goat</span><br><span class="line">│   ├── horse</span><br><span class="line">│   ├── monkey</span><br><span class="line">│   ├── ox</span><br><span class="line">│   ├── pig</span><br><span class="line">│   ├── rabbit</span><br><span class="line">│   ├── ratt</span><br><span class="line">│   ├── rooster</span><br><span class="line">│   ├── snake</span><br><span class="line">│   └── tiger</span><br><span class="line">├── train</span><br><span class="line">│   ├── dog</span><br><span class="line">│   ├── dragon</span><br><span class="line">│   ├── goat</span><br><span class="line">│   ├── horse</span><br><span class="line">│   ├── monkey</span><br><span class="line">│   ├── ox</span><br><span class="line">│   ├── pig</span><br><span class="line">│   ├── rabbit</span><br><span class="line">│   ├── ratt</span><br><span class="line">│   ├── rooster</span><br><span class="line">│   ├── snake</span><br><span class="line">│   └── tiger</span><br><span class="line">└── valid</span><br><span class="line">    ├── dog</span><br><span class="line">    ├── dragon</span><br><span class="line">    ├── goat</span><br><span class="line">    ├── horse</span><br><span class="line">    ├── monkey</span><br><span class="line">    ├── ox</span><br><span class="line">    ├── pig</span><br><span class="line">    ├── rabbit</span><br><span class="line">    ├── ratt</span><br><span class="line">    ├── rooster</span><br><span class="line">    ├── snake</span><br><span class="line">    └── tiger</span><br></pre></td></tr></table></figure>

<p>数据集分为 train、valid、test 三个文件夹，每个文件夹内包含 12 个分类文件夹，每个分类文件夹内是具体的样本图片。</p>
<p>我们对这些样本进行一个标注处理，最终生成 train.txt&#x2F;valid.txt&#x2F;test.txt 三个数据标注文件。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># %cd work</span></span><br><span class="line">!ls</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1512224.ipynb  config.py  data	dataset.py  __MACOSX  __pycache__  signs  work</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> get</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集根目录</span></span><br><span class="line">DATA_ROOT = <span class="string">&#x27;signs&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 标签List</span></span><br><span class="line">LABEL_MAP = get(<span class="string">&#x27;LABEL_MAP&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标注生成函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_annotation</span>(<span class="params">mode</span>):</span><br><span class="line">    <span class="comment"># 建立标注文件</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;&#123;&#125;/&#123;&#125;.txt&#x27;</span>.<span class="built_in">format</span>(DATA_ROOT, mode), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="comment"># 对应每个用途的数据文件夹，train/valid/test</span></span><br><span class="line">        train_dir = <span class="string">&#x27;&#123;&#125;/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(DATA_ROOT, mode)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历文件夹，获取里面的分类文件夹</span></span><br><span class="line">        <span class="keyword">for</span> path <span class="keyword">in</span> os.listdir(train_dir):</span><br><span class="line">            <span class="comment"># 标签对应的数字索引，实际标注的时候直接使用数字索引</span></span><br><span class="line">            label_index = LABEL_MAP.index(path)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 图像样本所在的路径</span></span><br><span class="line">            image_path = <span class="string">&#x27;&#123;&#125;/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(train_dir, path)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 遍历所有图像</span></span><br><span class="line">            <span class="keyword">for</span> image <span class="keyword">in</span> os.listdir(image_path):</span><br><span class="line">                <span class="comment"># 图像完整路径和名称</span></span><br><span class="line">                image_file = <span class="string">&#x27;&#123;&#125;/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(image_path, image)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    <span class="comment"># 验证图片格式是否ok</span></span><br><span class="line">                    <span class="keyword">with</span> <span class="built_in">open</span>(image_file, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f_img:</span><br><span class="line">                        image = Image.<span class="built_in">open</span>(io.BytesIO(f_img.read()))</span><br><span class="line">                        image.load()</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">if</span> image.mode == <span class="string">&#x27;RGB&#x27;</span>:</span><br><span class="line">                            f.write(<span class="string">&#x27;&#123;&#125;\t&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(image_file, label_index))</span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">generate_annotation(<span class="string">&#x27;train&#x27;</span>)  <span class="comment"># 生成训练集标注文件</span></span><br><span class="line">generate_annotation(<span class="string">&#x27;valid&#x27;</span>)  <span class="comment"># 生成验证集标注文件</span></span><br><span class="line">generate_annotation(<span class="string">&#x27;test&#x27;</span>)   <span class="comment"># 生成测试集标注文件</span></span><br></pre></td></tr></table></figure>

<h2 id="2-3-数据集定义"><a href="#2-3-数据集定义" class="headerlink" title="2.3 数据集定义"></a>2.3 数据集定义</h2><p>接下来我们使用标注好的文件进行数据集类的定义，方便后续模型训练使用。</p>
<h3 id="2-3-1-导入相关库"><a href="#2-3-1-导入相关库" class="headerlink" title="2.3.1 导入相关库"></a>2.3.1 导入相关库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> get</span><br><span class="line"></span><br><span class="line">paddle.__version__</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;2.0.0&#x27;</span><br></pre></td></tr></table></figure>

<h3 id="2-3-2-导入数据集的定义实现"><a href="#2-3-2-导入数据集的定义实现" class="headerlink" title="2.3.2 导入数据集的定义实现"></a>2.3.2 导入数据集的定义实现</h3><p>我们数据集的代码实现是在 dataset.py 中。</p>
<p>数据增强<code>data_augumentation</code>为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    self.transforms = T.Compose([</span><br><span class="line">    T.RandomResizedCrop(IMAGE_SIZE),    # 随机裁剪大小</span><br><span class="line">    T.RandomHorizontalFlip(0.5),        # 随机水平翻转</span><br><span class="line">    T.ToTensor(),                       # 数据的格式转换和标准化 HWC =&gt; CHW</span><br><span class="line">    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 图像归一化</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> dataset <span class="keyword">import</span> ZodiacDataset</span><br></pre></td></tr></table></figure>

<h3 id="2-3-3-实例化数据集类"><a href="#2-3-3-实例化数据集类" class="headerlink" title="2.3.3 实例化数据集类"></a>2.3.3 实例化数据集类</h3><p>根据所使用的数据集需求实例化数据集类，并查看总样本量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = ZodiacDataset(mode=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">valid_dataset = ZodiacDataset(mode=<span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;训练数据集：&#123;&#125;张；验证数据集：&#123;&#125;张&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(train_dataset), <span class="built_in">len</span>(valid_dataset)))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">训练数据集：7096张；验证数据集：639张</span><br></pre></td></tr></table></figure>

<h1 id="③-模型选择和开发"><a href="#③-模型选择和开发" class="headerlink" title="③ 模型选择和开发"></a>③ 模型选择和开发</h1><h2 id="3-1-网络构建"><a href="#3-1-网络构建" class="headerlink" title="3.1 网络构建"></a>3.1 网络构建</h2><p>本次我们使用 ResNet50 网络来完成我们的案例实践。</p>
<p><strong>1）ResNet 系列网络</strong></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/9fa9fbaf2943b69e4de49a2c1de97acb.png"></p>
<p><strong>2）ResNet50 结构</strong></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/a62bf34558789921ed0297926d15c2d3.png"></p>
<p><strong>3）残差区块</strong></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/9b8b57b52b9aa0e3588efad736ad6f3b.png"></p>
<p><strong>4）ResNet 其他版本</strong><br><img src="https://img-blog.csdnimg.cn/img_convert/2385de78c06da2f1410f5a17686c8458.png"><br><img src="https://img-blog.csdnimg.cn/img_convert/7dbf5144f44583fe0f785b8014fb01ea.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 请补齐模型实例化代码</span></span><br><span class="line"></span><br><span class="line">network = paddle.vision.models.resnet50(num_classes=get(<span class="string">&#x27;num_classes&#x27;</span>), pretrained=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">100%|██████████| 151272/151272 [00:03&lt;00:00, 41104.37it/s]</span><br><span class="line">/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for fc.weight. fc.weight receives a shape [2048, 1000], but the expected shape is [2048, 12].</span><br><span class="line">  warnings.warn((&quot;Skip loading for &#123;&#125;. &quot;.format(key) + str(err)))</span><br><span class="line">/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for fc.bias. fc.bias receives a shape [1000], but the expected shape is [12].</span><br><span class="line">  warnings.warn((&quot;Skip loading for &#123;&#125;. &quot;.format(key) + str(err)))</span><br></pre></td></tr></table></figure>

<p><strong>模型可视化</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = paddle.Model(network)</span><br><span class="line">model.summary((-<span class="number">1</span>, ) + <span class="built_in">tuple</span>(get(<span class="string">&#x27;image_shape&#x27;</span>)))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br></pre></td><td class="code"><pre><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">   Layer (type)         Input Shape          Output Shape         Param #</span><br><span class="line">===============================================================================</span><br><span class="line">     Conv2D-1        [[1, 3, 224, 224]]   [1, 64, 112, 112]        9,408</span><br><span class="line">   BatchNorm2D-1    [[1, 64, 112, 112]]   [1, 64, 112, 112]         256</span><br><span class="line">      ReLU-1        [[1, 64, 112, 112]]   [1, 64, 112, 112]          0</span><br><span class="line">    MaxPool2D-1     [[1, 64, 112, 112]]    [1, 64, 56, 56]           0</span><br><span class="line">     Conv2D-3        [[1, 64, 56, 56]]     [1, 64, 56, 56]         4,096</span><br><span class="line">   BatchNorm2D-3     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256</span><br><span class="line">      ReLU-2         [[1, 256, 56, 56]]    [1, 256, 56, 56]          0</span><br><span class="line">     Conv2D-4        [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864</span><br><span class="line">   BatchNorm2D-4     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256</span><br><span class="line">     Conv2D-5        [[1, 64, 56, 56]]     [1, 256, 56, 56]       16,384</span><br><span class="line">   BatchNorm2D-5     [[1, 256, 56, 56]]    [1, 256, 56, 56]        1,024</span><br><span class="line">     Conv2D-2        [[1, 64, 56, 56]]     [1, 256, 56, 56]       16,384</span><br><span class="line">   BatchNorm2D-2     [[1, 256, 56, 56]]    [1, 256, 56, 56]        1,024</span><br><span class="line"> BottleneckBlock-1   [[1, 64, 56, 56]]     [1, 256, 56, 56]          0</span><br><span class="line">     Conv2D-6        [[1, 256, 56, 56]]    [1, 64, 56, 56]        16,384</span><br><span class="line">   BatchNorm2D-6     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256</span><br><span class="line">      ReLU-3         [[1, 256, 56, 56]]    [1, 256, 56, 56]          0</span><br><span class="line">     Conv2D-7        [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864</span><br><span class="line">   BatchNorm2D-7     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256</span><br><span class="line">     Conv2D-8        [[1, 64, 56, 56]]     [1, 256, 56, 56]       16,384</span><br><span class="line">   BatchNorm2D-8     [[1, 256, 56, 56]]    [1, 256, 56, 56]        1,024</span><br><span class="line"> BottleneckBlock-2   [[1, 256, 56, 56]]    [1, 256, 56, 56]          0</span><br><span class="line">     Conv2D-9        [[1, 256, 56, 56]]    [1, 64, 56, 56]        16,384</span><br><span class="line">   BatchNorm2D-9     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256</span><br><span class="line">      ReLU-4         [[1, 256, 56, 56]]    [1, 256, 56, 56]          0</span><br><span class="line">     Conv2D-10       [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864</span><br><span class="line">  BatchNorm2D-10     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256</span><br><span class="line">     Conv2D-11       [[1, 64, 56, 56]]     [1, 256, 56, 56]       16,384</span><br><span class="line">  BatchNorm2D-11     [[1, 256, 56, 56]]    [1, 256, 56, 56]        1,024</span><br><span class="line"> BottleneckBlock-3   [[1, 256, 56, 56]]    [1, 256, 56, 56]          0</span><br><span class="line">     Conv2D-13       [[1, 256, 56, 56]]    [1, 128, 56, 56]       32,768</span><br><span class="line">  BatchNorm2D-13     [[1, 128, 56, 56]]    [1, 128, 56, 56]         512</span><br><span class="line">      ReLU-5         [[1, 512, 28, 28]]    [1, 512, 28, 28]          0</span><br><span class="line">     Conv2D-14       [[1, 128, 56, 56]]    [1, 128, 28, 28]       147,456</span><br><span class="line">  BatchNorm2D-14     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512</span><br><span class="line">     Conv2D-15       [[1, 128, 28, 28]]    [1, 512, 28, 28]       65,536</span><br><span class="line">  BatchNorm2D-15     [[1, 512, 28, 28]]    [1, 512, 28, 28]        2,048</span><br><span class="line">     Conv2D-12       [[1, 256, 56, 56]]    [1, 512, 28, 28]       131,072</span><br><span class="line">  BatchNorm2D-12     [[1, 512, 28, 28]]    [1, 512, 28, 28]        2,048</span><br><span class="line"> BottleneckBlock-4   [[1, 256, 56, 56]]    [1, 512, 28, 28]          0</span><br><span class="line">     Conv2D-16       [[1, 512, 28, 28]]    [1, 128, 28, 28]       65,536</span><br><span class="line">  BatchNorm2D-16     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512</span><br><span class="line">      ReLU-6         [[1, 512, 28, 28]]    [1, 512, 28, 28]          0</span><br><span class="line">     Conv2D-17       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456</span><br><span class="line">  BatchNorm2D-17     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512</span><br><span class="line">     Conv2D-18       [[1, 128, 28, 28]]    [1, 512, 28, 28]       65,536</span><br><span class="line">  BatchNorm2D-18     [[1, 512, 28, 28]]    [1, 512, 28, 28]        2,048</span><br><span class="line"> BottleneckBlock-5   [[1, 512, 28, 28]]    [1, 512, 28, 28]          0</span><br><span class="line">     Conv2D-19       [[1, 512, 28, 28]]    [1, 128, 28, 28]       65,536</span><br><span class="line">  BatchNorm2D-19     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512</span><br><span class="line">      ReLU-7         [[1, 512, 28, 28]]    [1, 512, 28, 28]          0</span><br><span class="line">     Conv2D-20       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456</span><br><span class="line">  BatchNorm2D-20     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512</span><br><span class="line">     Conv2D-21       [[1, 128, 28, 28]]    [1, 512, 28, 28]       65,536</span><br><span class="line">  BatchNorm2D-21     [[1, 512, 28, 28]]    [1, 512, 28, 28]        2,048</span><br><span class="line"> BottleneckBlock-6   [[1, 512, 28, 28]]    [1, 512, 28, 28]          0</span><br><span class="line">     Conv2D-22       [[1, 512, 28, 28]]    [1, 128, 28, 28]       65,536</span><br><span class="line">  BatchNorm2D-22     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512</span><br><span class="line">      ReLU-8         [[1, 512, 28, 28]]    [1, 512, 28, 28]          0</span><br><span class="line">     Conv2D-23       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456</span><br><span class="line">  BatchNorm2D-23     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512</span><br><span class="line">     Conv2D-24       [[1, 128, 28, 28]]    [1, 512, 28, 28]       65,536</span><br><span class="line">  BatchNorm2D-24     [[1, 512, 28, 28]]    [1, 512, 28, 28]        2,048</span><br><span class="line"> BottleneckBlock-7   [[1, 512, 28, 28]]    [1, 512, 28, 28]          0</span><br><span class="line">     Conv2D-26       [[1, 512, 28, 28]]    [1, 256, 28, 28]       131,072</span><br><span class="line">  BatchNorm2D-26     [[1, 256, 28, 28]]    [1, 256, 28, 28]        1,024</span><br><span class="line">      ReLU-9        [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">     Conv2D-27       [[1, 256, 28, 28]]    [1, 256, 14, 14]       589,824</span><br><span class="line">  BatchNorm2D-27     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">     Conv2D-28       [[1, 256, 14, 14]]   [1, 1024, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-28    [[1, 1024, 14, 14]]   [1, 1024, 14, 14]        4,096</span><br><span class="line">     Conv2D-25       [[1, 512, 28, 28]]   [1, 1024, 14, 14]       524,288</span><br><span class="line">  BatchNorm2D-25    [[1, 1024, 14, 14]]   [1, 1024, 14, 14]        4,096</span><br><span class="line"> BottleneckBlock-8   [[1, 512, 28, 28]]   [1, 1024, 14, 14]          0</span><br><span class="line">     Conv2D-29      [[1, 1024, 14, 14]]    [1, 256, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-29     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">      ReLU-10       [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">     Conv2D-30       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824</span><br><span class="line">  BatchNorm2D-30     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">     Conv2D-31       [[1, 256, 14, 14]]   [1, 1024, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-31    [[1, 1024, 14, 14]]   [1, 1024, 14, 14]        4,096</span><br><span class="line"> BottleneckBlock-9  [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">     Conv2D-32      [[1, 1024, 14, 14]]    [1, 256, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-32     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">      ReLU-11       [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">     Conv2D-33       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824</span><br><span class="line">  BatchNorm2D-33     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">     Conv2D-34       [[1, 256, 14, 14]]   [1, 1024, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-34    [[1, 1024, 14, 14]]   [1, 1024, 14, 14]        4,096</span><br><span class="line">BottleneckBlock-10  [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">     Conv2D-35      [[1, 1024, 14, 14]]    [1, 256, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-35     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">      ReLU-12       [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">     Conv2D-36       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824</span><br><span class="line">  BatchNorm2D-36     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">     Conv2D-37       [[1, 256, 14, 14]]   [1, 1024, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-37    [[1, 1024, 14, 14]]   [1, 1024, 14, 14]        4,096</span><br><span class="line">BottleneckBlock-11  [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">     Conv2D-38      [[1, 1024, 14, 14]]    [1, 256, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-38     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">      ReLU-13       [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">     Conv2D-39       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824</span><br><span class="line">  BatchNorm2D-39     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">     Conv2D-40       [[1, 256, 14, 14]]   [1, 1024, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-40    [[1, 1024, 14, 14]]   [1, 1024, 14, 14]        4,096</span><br><span class="line">BottleneckBlock-12  [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">     Conv2D-41      [[1, 1024, 14, 14]]    [1, 256, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-41     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">      ReLU-14       [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">     Conv2D-42       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824</span><br><span class="line">  BatchNorm2D-42     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024</span><br><span class="line">     Conv2D-43       [[1, 256, 14, 14]]   [1, 1024, 14, 14]       262,144</span><br><span class="line">  BatchNorm2D-43    [[1, 1024, 14, 14]]   [1, 1024, 14, 14]        4,096</span><br><span class="line">BottleneckBlock-13  [[1, 1024, 14, 14]]   [1, 1024, 14, 14]          0</span><br><span class="line">     Conv2D-45      [[1, 1024, 14, 14]]    [1, 512, 14, 14]       524,288</span><br><span class="line">  BatchNorm2D-45     [[1, 512, 14, 14]]    [1, 512, 14, 14]        2,048</span><br><span class="line">      ReLU-15        [[1, 2048, 7, 7]]     [1, 2048, 7, 7]           0</span><br><span class="line">     Conv2D-46       [[1, 512, 14, 14]]     [1, 512, 7, 7]       2,359,296</span><br><span class="line">  BatchNorm2D-46      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048</span><br><span class="line">     Conv2D-47        [[1, 512, 7, 7]]     [1, 2048, 7, 7]       1,048,576</span><br><span class="line">  BatchNorm2D-47     [[1, 2048, 7, 7]]     [1, 2048, 7, 7]         8,192</span><br><span class="line">     Conv2D-44      [[1, 1024, 14, 14]]    [1, 2048, 7, 7]       2,097,152</span><br><span class="line">  BatchNorm2D-44     [[1, 2048, 7, 7]]     [1, 2048, 7, 7]         8,192</span><br><span class="line">BottleneckBlock-14  [[1, 1024, 14, 14]]    [1, 2048, 7, 7]           0</span><br><span class="line">     Conv2D-48       [[1, 2048, 7, 7]]      [1, 512, 7, 7]       1,048,576</span><br><span class="line">  BatchNorm2D-48      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048</span><br><span class="line">      ReLU-16        [[1, 2048, 7, 7]]     [1, 2048, 7, 7]           0</span><br><span class="line">     Conv2D-49        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296</span><br><span class="line">  BatchNorm2D-49      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048</span><br><span class="line">     Conv2D-50        [[1, 512, 7, 7]]     [1, 2048, 7, 7]       1,048,576</span><br><span class="line">  BatchNorm2D-50     [[1, 2048, 7, 7]]     [1, 2048, 7, 7]         8,192</span><br><span class="line">BottleneckBlock-15   [[1, 2048, 7, 7]]     [1, 2048, 7, 7]           0</span><br><span class="line">     Conv2D-51       [[1, 2048, 7, 7]]      [1, 512, 7, 7]       1,048,576</span><br><span class="line">  BatchNorm2D-51      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048</span><br><span class="line">      ReLU-17        [[1, 2048, 7, 7]]     [1, 2048, 7, 7]           0</span><br><span class="line">     Conv2D-52        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296</span><br><span class="line">  BatchNorm2D-52      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048</span><br><span class="line">     Conv2D-53        [[1, 512, 7, 7]]     [1, 2048, 7, 7]       1,048,576</span><br><span class="line">  BatchNorm2D-53     [[1, 2048, 7, 7]]     [1, 2048, 7, 7]         8,192</span><br><span class="line">BottleneckBlock-16   [[1, 2048, 7, 7]]     [1, 2048, 7, 7]           0</span><br><span class="line">AdaptiveAvgPool2D-1  [[1, 2048, 7, 7]]     [1, 2048, 1, 1]           0</span><br><span class="line">     Linear-1           [[1, 2048]]            [1, 12]            24,588</span><br><span class="line">===============================================================================</span><br><span class="line">Total params: 23,585,740</span><br><span class="line">Trainable params: 23,479,500</span><br><span class="line">Non-trainable params: 106,240</span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">Input size (MB): 0.57</span><br><span class="line">Forward/backward pass size (MB): 261.48</span><br><span class="line">Params size (MB): 89.97</span><br><span class="line">Estimated Total Size (MB): 352.02</span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;&#x27;total_params&#x27;: 23585740, &#x27;trainable_params&#x27;: 23479500&#125;</span><br></pre></td></tr></table></figure>

<h2 id="超参数配置"><a href="#超参数配置" class="headerlink" title="超参数配置"></a>超参数配置</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">CONFIG = &#123;</span><br><span class="line">&#x27;model_save_dir&#x27;: &quot;./output/zodiac&quot;,</span><br><span class="line">&#x27;num_classes&#x27;: 12,</span><br><span class="line">&#x27;total_images&#x27;: 7096,</span><br><span class="line">&#x27;epochs&#x27;: 20,</span><br><span class="line">&#x27;batch_size&#x27;: 32,</span><br><span class="line">&#x27;image_shape&#x27;: [3, 224, 224],</span><br><span class="line">&#x27;LEARNING_RATE&#x27;: &#123;</span><br><span class="line">    &#x27;params&#x27;: &#123;</span><br><span class="line">        &#x27;lr&#x27;: 0.00375</span><br><span class="line">    &#125;</span><br><span class="line">&#125;,</span><br><span class="line">&#x27;OPTIMIZER&#x27;: &#123;</span><br><span class="line">    &#x27;params&#x27;: &#123;</span><br><span class="line">        &#x27;momentum&#x27;: 0.9</span><br><span class="line">    &#125;,</span><br><span class="line">    &#x27;regularizer&#x27;: &#123;</span><br><span class="line">        &#x27;function&#x27;: &#x27;L2&#x27;,</span><br><span class="line">        &#x27;factor&#x27;: 0.000001</span><br><span class="line">    &#125;</span><br><span class="line">&#125;,</span><br><span class="line">&#x27;LABEL_MAP&#x27;: [</span><br><span class="line">    &quot;ratt&quot;,</span><br><span class="line">    &quot;ox&quot;,</span><br><span class="line">    &quot;tiger&quot;,</span><br><span class="line">    &quot;rabbit&quot;,</span><br><span class="line">    &quot;dragon&quot;,</span><br><span class="line">    &quot;snake&quot;,</span><br><span class="line">    &quot;horse&quot;,</span><br><span class="line">    &quot;goat&quot;,</span><br><span class="line">    &quot;monkey&quot;,</span><br><span class="line">    &quot;rooster&quot;,</span><br><span class="line">    &quot;dog&quot;,</span><br><span class="line">    &quot;pig&quot;,</span><br><span class="line">]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="④-模型训练和优化"><a href="#④-模型训练和优化" class="headerlink" title="④ 模型训练和优化"></a>④ 模型训练和优化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">EPOCHS = get(<span class="string">&#x27;epochs&#x27;</span>)</span><br><span class="line">BATCH_SIZE = get(<span class="string">&#x27;batch_size&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请补齐模型训练过程代码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_optim</span>(<span class="params">parameters</span>):</span><br><span class="line">    step_each_epoch = get(<span class="string">&#x27;total_images&#x27;</span>) // get(<span class="string">&#x27;batch_size&#x27;</span>)</span><br><span class="line">    lr = paddle.optimizer.lr.CosineAnnealingDecay(learning_rate=get(<span class="string">&#x27;LEARNING_RATE.params.lr&#x27;</span>),</span><br><span class="line">                                                  T_max=step_each_epoch * EPOCHS)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> paddle.optimizer.Momentum(learning_rate=lr,</span><br><span class="line">                                     parameters=parameters,</span><br><span class="line">                                     weight_decay=paddle.regularizer.L2Decay(get(<span class="string">&#x27;OPTIMIZER.regularizer.factor&#x27;</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练配置</span></span><br><span class="line">model.prepare(create_optim(network.parameters()),  <span class="comment"># 优化器</span></span><br><span class="line">              paddle.nn.CrossEntropyLoss(),        <span class="comment"># 损失函数</span></span><br><span class="line">              paddle.metric.Accuracy(topk=(<span class="number">1</span>, <span class="number">5</span>))) <span class="comment"># 评估指标</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练可视化VisualDL工具的回调函数</span></span><br><span class="line">visualdl = paddle.callbacks.VisualDL(log_dir=<span class="string">&#x27;visualdl_log&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动模型全流程训练</span></span><br><span class="line">model.fit(train_dataset,            <span class="comment"># 训练数据集</span></span><br><span class="line">          valid_dataset,            <span class="comment"># 评估数据集</span></span><br><span class="line">          epochs=EPOCHS,            <span class="comment"># 总的训练轮次</span></span><br><span class="line">          batch_size=BATCH_SIZE,    <span class="comment"># 批次计算的样本量大小</span></span><br><span class="line">          shuffle=<span class="literal">True</span>,             <span class="comment"># 是否打乱样本集</span></span><br><span class="line">          verbose=<span class="number">1</span>,                <span class="comment"># 日志展示格式</span></span><br><span class="line">          save_dir=<span class="string">&#x27;./chk_points/&#x27;</span>, <span class="comment"># 分阶段的训练模型存储路径</span></span><br><span class="line">          callbacks=[visualdl])     <span class="comment"># 回调函数使用</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line">The loss value printed in the log is the current step, and the metric is the average value of previous step.</span><br><span class="line">Epoch 1/20</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from &#x27;collections&#x27; instead of from &#x27;collections.abc&#x27; is deprecated, and in 3.8 it will stop working</span><br><span class="line">  return (isinstance(seq, collections.Sequence) and</span><br><span class="line">/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:636: UserWarning: When training, we now always track global mean and variance.</span><br><span class="line">  &quot;When training, we now always track global mean and variance.&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">step 222/222 [==============================] - loss: 0.5499 - acc_top1: 0.7851 - acc_top5: 0.9548 - 734ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/0</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.3935 - acc_top1: 0.9092 - acc_top5: 0.9922 - 812ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 2/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.3459 - acc_top1: 0.8519 - acc_top5: 0.9790 - 732ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/1</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.7412 - acc_top1: 0.8983 - acc_top5: 0.9890 - 833ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 3/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.4244 - acc_top1: 0.8671 - acc_top5: 0.9817 - 728ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/2</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.5254 - acc_top1: 0.9218 - acc_top5: 0.9984 - 819ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 4/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.2774 - acc_top1: 0.8878 - acc_top5: 0.9858 - 738ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/3</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.3364 - acc_top1: 0.9280 - acc_top5: 0.9969 - 823ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 5/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.2692 - acc_top1: 0.8922 - acc_top5: 0.9884 - 728ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/4</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.2550 - acc_top1: 0.9311 - acc_top5: 0.9969 - 804ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 6/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.5775 - acc_top1: 0.9121 - acc_top5: 0.9894 - 727ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/5</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.5690 - acc_top1: 0.9531 - acc_top5: 0.9969 - 821ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 7/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.2791 - acc_top1: 0.9136 - acc_top5: 0.9897 - 731ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/6</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.5091 - acc_top1: 0.9609 - acc_top5: 0.9969 - 820ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 8/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.1944 - acc_top1: 0.9253 - acc_top5: 0.9920 - 734ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/7</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.2852 - acc_top1: 0.9531 - acc_top5: 0.9953 - 821ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 9/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.3202 - acc_top1: 0.9287 - acc_top5: 0.9927 - 735ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/8</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.4450 - acc_top1: 0.9531 - acc_top5: 0.9969 - 824ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 10/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.1250 - acc_top1: 0.9359 - acc_top5: 0.9925 - 745ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/9</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.4062 - acc_top1: 0.9609 - acc_top5: 0.9953 - 844ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 11/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.0311 - acc_top1: 0.9366 - acc_top5: 0.9917 - 737ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/10</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.1610 - acc_top1: 0.9577 - acc_top5: 1.0000 - 831ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 12/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.2705 - acc_top1: 0.9479 - acc_top5: 0.9938 - 726ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/11</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.1312 - acc_top1: 0.9577 - acc_top5: 1.0000 - 811ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 13/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.1966 - acc_top1: 0.9548 - acc_top5: 0.9942 - 729ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/12</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.3287 - acc_top1: 0.9562 - acc_top5: 1.0000 - 833ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 14/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.2755 - acc_top1: 0.9563 - acc_top5: 0.9956 - 740ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/13</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.1597 - acc_top1: 0.9546 - acc_top5: 0.9969 - 811ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 15/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.1340 - acc_top1: 0.9589 - acc_top5: 0.9945 - 741ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/14</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.3858 - acc_top1: 0.9531 - acc_top5: 0.9937 - 828ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 16/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.0603 - acc_top1: 0.9600 - acc_top5: 0.9975 - 741ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/15</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.1964 - acc_top1: 0.9656 - acc_top5: 0.9984 - 826ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 17/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.0447 - acc_top1: 0.9581 - acc_top5: 0.9955 - 740ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/16</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.1808 - acc_top1: 0.9703 - acc_top5: 0.9969 - 818ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 18/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.5067 - acc_top1: 0.9625 - acc_top5: 0.9956 - 741ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/17</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.2021 - acc_top1: 0.9656 - acc_top5: 0.9984 - 833ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 19/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.0673 - acc_top1: 0.9593 - acc_top5: 0.9946 - 738ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/18</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.5409 - acc_top1: 0.9577 - acc_top5: 0.9969 - 836ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 20/20</span><br><span class="line">step 222/222 [==============================] - loss: 0.1440 - acc_top1: 0.9596 - acc_top5: 0.9965 - 742ms/step</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/19</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.2487 - acc_top1: 0.9640 - acc_top5: 0.9984 - 809ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">save checkpoint at /home/aistudio/chk_points/final</span><br></pre></td></tr></table></figure>

<h2 id="VisualDL-训练过程可视化展示"><a href="#VisualDL-训练过程可视化展示" class="headerlink" title="VisualDL 训练过程可视化展示"></a>VisualDL 训练过程可视化展示</h2><p><code>visualdl = paddle.callbacks.VisualDL(log_dir=&#39;VisualDL_log&#39;)</code></p>
<h3 id="模型存储"><a href="#模型存储" class="headerlink" title="模型存储"></a>模型存储</h3><p>将我们训练得到的模型进行保存，以便后续评估和测试使用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.save(get(<span class="string">&#x27;model_save_dir&#x27;</span>))</span><br></pre></td></tr></table></figure>

<h1 id="⑤-模型评估和测试"><a href="#⑤-模型评估和测试" class="headerlink" title="⑤ 模型评估和测试"></a>⑤ 模型评估和测试</h1><h2 id="5-1-批量预测测试"><a href="#5-1-批量预测测试" class="headerlink" title="5.1 批量预测测试"></a>5.1 批量预测测试</h2><h3 id="5-1-1-测试数据集"><a href="#5-1-1-测试数据集" class="headerlink" title="5.1.1 测试数据集"></a>5.1.1 测试数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">predict_dataset = ZodiacDataset(mode=<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据集样本量：&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(predict_dataset)))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">测试数据集样本量：646</span><br></pre></td></tr></table></figure>

<h3 id="5-1-2-执行预测"><a href="#5-1-2-执行预测" class="headerlink" title="5.1.2 执行预测"></a>5.1.2 执行预测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> paddle.static <span class="keyword">import</span> InputSpec</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请补充网络结构</span></span><br><span class="line">network = paddle.vision.models.resnet50(num_classes=get(<span class="string">&#x27;num_classes&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型封装</span></span><br><span class="line">model_2 = paddle.Model(network, inputs=[InputSpec(shape=[-<span class="number">1</span>] + get(<span class="string">&#x27;image_shape&#x27;</span>), dtype=<span class="string">&#x27;float32&#x27;</span>, name=<span class="string">&#x27;image&#x27;</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请补充模型文件加载代码</span></span><br><span class="line"><span class="comment"># 训练好的模型加载</span></span><br><span class="line">model_2.load(get(<span class="string">&#x27;model_save_dir&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型配置</span></span><br><span class="line">model_2.prepare()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行预测</span></span><br><span class="line">result = model_2.predict(predict_dataset)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Predict begin...</span><br><span class="line">step 646/646 [==============================] - 33ms/step</span><br><span class="line">Predict samples: 646</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 样本映射</span></span><br><span class="line">LABEL_MAP = get(<span class="string">&#x27;LABEL_MAP&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机取样本展示</span></span><br><span class="line">indexs = np.random.randint(<span class="number">1</span>, <span class="number">646</span>, size=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> indexs:</span><br><span class="line">    predict_label = np.argmax(result[<span class="number">0</span>][idx])</span><br><span class="line">    real_label = predict_dataset[idx][<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;样本ID：&#123;&#125;, 真实标签：&#123;&#125;, 预测值：&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(idx, LABEL_MAP[real_label], LABEL_MAP[predict_label]))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">样本ID：393, 真实标签：pig, 预测值：pig</span><br><span class="line">样本ID：107, 真实标签：monkey, 预测值：monkey</span><br><span class="line">样本ID：466, 真实标签：tiger, 预测值：tiger</span><br><span class="line">样本ID：279, 真实标签：horse, 预测值：horse</span><br><span class="line">样本ID：425, 真实标签：pig, 预测值：pig</span><br><span class="line">样本ID：127, 真实标签：monkey, 预测值：monkey</span><br><span class="line">样本ID：432, 真实标签：tiger, 预测值：tiger</span><br><span class="line">样本ID：377, 真实标签：pig, 预测值：pig</span><br><span class="line">样本ID：99, 真实标签：dragon, 预测值：dragon</span><br><span class="line">样本ID：322, 真实标签：dog, 预测值：dog</span><br><span class="line">样本ID：460, 真实标签：tiger, 预测值：tiger</span><br><span class="line">样本ID：554, 真实标签：ox, 预测值：ox</span><br><span class="line">样本ID：77, 真实标签：dragon, 预测值：dragon</span><br><span class="line">样本ID：335, 真实标签：dog, 预测值：dog</span><br><span class="line">样本ID：398, 真实标签：pig, 预测值：pig</span><br><span class="line">样本ID：176, 真实标签：snake, 预测值：snake</span><br><span class="line">样本ID：207, 真实标签：snake, 预测值：snake</span><br><span class="line">样本ID：29, 真实标签：rooster, 预测值：rooster</span><br><span class="line">样本ID：476, 真实标签：tiger, 预测值：tiger</span><br><span class="line">样本ID：424, 真实标签：pig, 预测值：pig</span><br></pre></td></tr></table></figure>

<h1 id="⑥-模型部署"><a href="#⑥-模型部署" class="headerlink" title="⑥ 模型部署"></a>⑥ 模型部署</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_2.save(<span class="string">&#x27;infer/zodiac&#x27;</span>, training=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/vision/models/resnet.py:145</span><br><span class="line">The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.</span><br><span class="line">  op_type, op_type, EXPRESSION_MAP[method_name]))</span><br></pre></td></tr></table></figure>

<h2 id="MobileNet-V2-测试"><a href="#MobileNet-V2-测试" class="headerlink" title="MobileNet_V2 测试"></a>MobileNet_V2 测试</h2><p>由于<code>ResNet</code>模型和计算量都比较大，在 AI_Studio 的 GPU 下跑 20 个 Epoch 还是跑了很久，这里测试一下用<code>MobileNet</code>来进行训练，测试运算效率和准确性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">network = paddle.vision.models.mobilenet_v2(num_classes=get(<span class="string">&#x27;num_classes&#x27;</span>), pretrained=<span class="literal">True</span>)</span><br><span class="line">model_lite = paddle.Model(network)</span><br><span class="line">model_lite.summary((-<span class="number">1</span>, ) + <span class="built_in">tuple</span>(get(<span class="string">&#x27;image_shape&#x27;</span>)))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br></pre></td><td class="code"><pre><span class="line">100%|██████████| 20795/20795 [00:00&lt;00:00, 44614.48it/s]</span><br><span class="line">/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for classifier.1.weight. classifier.1.weight receives a shape [1280, 1000], but the expected shape is [1280, 12].</span><br><span class="line">  warnings.warn((&quot;Skip loading for &#123;&#125;. &quot;.format(key) + str(err)))</span><br><span class="line">/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for classifier.1.bias. classifier.1.bias receives a shape [1000], but the expected shape is [12].</span><br><span class="line">  warnings.warn((&quot;Skip loading for &#123;&#125;. &quot;.format(key) + str(err)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">   Layer (type)         Input Shape          Output Shape         Param #</span><br><span class="line">===============================================================================</span><br><span class="line">    Conv2D-160       [[1, 3, 224, 224]]   [1, 32, 112, 112]         864</span><br><span class="line">  BatchNorm2D-107   [[1, 32, 112, 112]]   [1, 32, 112, 112]         128</span><br><span class="line">      ReLU6-1       [[1, 32, 112, 112]]   [1, 32, 112, 112]          0</span><br><span class="line">    Conv2D-161      [[1, 32, 112, 112]]   [1, 32, 112, 112]         288</span><br><span class="line">  BatchNorm2D-108   [[1, 32, 112, 112]]   [1, 32, 112, 112]         128</span><br><span class="line">      ReLU6-2       [[1, 32, 112, 112]]   [1, 32, 112, 112]          0</span><br><span class="line">    Conv2D-162      [[1, 32, 112, 112]]   [1, 16, 112, 112]         512</span><br><span class="line">  BatchNorm2D-109   [[1, 16, 112, 112]]   [1, 16, 112, 112]         64</span><br><span class="line">InvertedResidual-1  [[1, 32, 112, 112]]   [1, 16, 112, 112]          0</span><br><span class="line">    Conv2D-163      [[1, 16, 112, 112]]   [1, 96, 112, 112]        1,536</span><br><span class="line">  BatchNorm2D-110   [[1, 96, 112, 112]]   [1, 96, 112, 112]         384</span><br><span class="line">      ReLU6-3       [[1, 96, 112, 112]]   [1, 96, 112, 112]          0</span><br><span class="line">    Conv2D-164      [[1, 96, 112, 112]]    [1, 96, 56, 56]          864</span><br><span class="line">  BatchNorm2D-111    [[1, 96, 56, 56]]     [1, 96, 56, 56]          384</span><br><span class="line">      ReLU6-4        [[1, 96, 56, 56]]     [1, 96, 56, 56]           0</span><br><span class="line">    Conv2D-165       [[1, 96, 56, 56]]     [1, 24, 56, 56]         2,304</span><br><span class="line">  BatchNorm2D-112    [[1, 24, 56, 56]]     [1, 24, 56, 56]          96</span><br><span class="line">InvertedResidual-2  [[1, 16, 112, 112]]    [1, 24, 56, 56]           0</span><br><span class="line">    Conv2D-166       [[1, 24, 56, 56]]     [1, 144, 56, 56]        3,456</span><br><span class="line">  BatchNorm2D-113    [[1, 144, 56, 56]]    [1, 144, 56, 56]         576</span><br><span class="line">      ReLU6-5        [[1, 144, 56, 56]]    [1, 144, 56, 56]          0</span><br><span class="line">    Conv2D-167       [[1, 144, 56, 56]]    [1, 144, 56, 56]        1,296</span><br><span class="line">  BatchNorm2D-114    [[1, 144, 56, 56]]    [1, 144, 56, 56]         576</span><br><span class="line">      ReLU6-6        [[1, 144, 56, 56]]    [1, 144, 56, 56]          0</span><br><span class="line">    Conv2D-168       [[1, 144, 56, 56]]    [1, 24, 56, 56]         3,456</span><br><span class="line">  BatchNorm2D-115    [[1, 24, 56, 56]]     [1, 24, 56, 56]          96</span><br><span class="line">InvertedResidual-3   [[1, 24, 56, 56]]     [1, 24, 56, 56]           0</span><br><span class="line">    Conv2D-169       [[1, 24, 56, 56]]     [1, 144, 56, 56]        3,456</span><br><span class="line">  BatchNorm2D-116    [[1, 144, 56, 56]]    [1, 144, 56, 56]         576</span><br><span class="line">      ReLU6-7        [[1, 144, 56, 56]]    [1, 144, 56, 56]          0</span><br><span class="line">    Conv2D-170       [[1, 144, 56, 56]]    [1, 144, 28, 28]        1,296</span><br><span class="line">  BatchNorm2D-117    [[1, 144, 28, 28]]    [1, 144, 28, 28]         576</span><br><span class="line">      ReLU6-8        [[1, 144, 28, 28]]    [1, 144, 28, 28]          0</span><br><span class="line">    Conv2D-171       [[1, 144, 28, 28]]    [1, 32, 28, 28]         4,608</span><br><span class="line">  BatchNorm2D-118    [[1, 32, 28, 28]]     [1, 32, 28, 28]          128</span><br><span class="line">InvertedResidual-4   [[1, 24, 56, 56]]     [1, 32, 28, 28]           0</span><br><span class="line">    Conv2D-172       [[1, 32, 28, 28]]     [1, 192, 28, 28]        6,144</span><br><span class="line">  BatchNorm2D-119    [[1, 192, 28, 28]]    [1, 192, 28, 28]         768</span><br><span class="line">      ReLU6-9        [[1, 192, 28, 28]]    [1, 192, 28, 28]          0</span><br><span class="line">    Conv2D-173       [[1, 192, 28, 28]]    [1, 192, 28, 28]        1,728</span><br><span class="line">  BatchNorm2D-120    [[1, 192, 28, 28]]    [1, 192, 28, 28]         768</span><br><span class="line">     ReLU6-10        [[1, 192, 28, 28]]    [1, 192, 28, 28]          0</span><br><span class="line">    Conv2D-174       [[1, 192, 28, 28]]    [1, 32, 28, 28]         6,144</span><br><span class="line">  BatchNorm2D-121    [[1, 32, 28, 28]]     [1, 32, 28, 28]          128</span><br><span class="line">InvertedResidual-5   [[1, 32, 28, 28]]     [1, 32, 28, 28]           0</span><br><span class="line">    Conv2D-175       [[1, 32, 28, 28]]     [1, 192, 28, 28]        6,144</span><br><span class="line">  BatchNorm2D-122    [[1, 192, 28, 28]]    [1, 192, 28, 28]         768</span><br><span class="line">     ReLU6-11        [[1, 192, 28, 28]]    [1, 192, 28, 28]          0</span><br><span class="line">    Conv2D-176       [[1, 192, 28, 28]]    [1, 192, 28, 28]        1,728</span><br><span class="line">  BatchNorm2D-123    [[1, 192, 28, 28]]    [1, 192, 28, 28]         768</span><br><span class="line">     ReLU6-12        [[1, 192, 28, 28]]    [1, 192, 28, 28]          0</span><br><span class="line">    Conv2D-177       [[1, 192, 28, 28]]    [1, 32, 28, 28]         6,144</span><br><span class="line">  BatchNorm2D-124    [[1, 32, 28, 28]]     [1, 32, 28, 28]          128</span><br><span class="line">InvertedResidual-6   [[1, 32, 28, 28]]     [1, 32, 28, 28]           0</span><br><span class="line">    Conv2D-178       [[1, 32, 28, 28]]     [1, 192, 28, 28]        6,144</span><br><span class="line">  BatchNorm2D-125    [[1, 192, 28, 28]]    [1, 192, 28, 28]         768</span><br><span class="line">     ReLU6-13        [[1, 192, 28, 28]]    [1, 192, 28, 28]          0</span><br><span class="line">    Conv2D-179       [[1, 192, 28, 28]]    [1, 192, 14, 14]        1,728</span><br><span class="line">  BatchNorm2D-126    [[1, 192, 14, 14]]    [1, 192, 14, 14]         768</span><br><span class="line">     ReLU6-14        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0</span><br><span class="line">    Conv2D-180       [[1, 192, 14, 14]]    [1, 64, 14, 14]        12,288</span><br><span class="line">  BatchNorm2D-127    [[1, 64, 14, 14]]     [1, 64, 14, 14]          256</span><br><span class="line">InvertedResidual-7   [[1, 32, 28, 28]]     [1, 64, 14, 14]           0</span><br><span class="line">    Conv2D-181       [[1, 64, 14, 14]]     [1, 384, 14, 14]       24,576</span><br><span class="line">  BatchNorm2D-128    [[1, 384, 14, 14]]    [1, 384, 14, 14]        1,536</span><br><span class="line">     ReLU6-15        [[1, 384, 14, 14]]    [1, 384, 14, 14]          0</span><br><span class="line">    Conv2D-182       [[1, 384, 14, 14]]    [1, 384, 14, 14]        3,456</span><br><span class="line">  BatchNorm2D-129    [[1, 384, 14, 14]]    [1, 384, 14, 14]        1,536</span><br><span class="line">     ReLU6-16        [[1, 384, 14, 14]]    [1, 384, 14, 14]          0</span><br><span class="line">    Conv2D-183       [[1, 384, 14, 14]]    [1, 64, 14, 14]        24,576</span><br><span class="line">  BatchNorm2D-130    [[1, 64, 14, 14]]     [1, 64, 14, 14]          256</span><br><span class="line">InvertedResidual-8   [[1, 64, 14, 14]]     [1, 64, 14, 14]           0</span><br><span class="line">    Conv2D-184       [[1, 64, 14, 14]]     [1, 384, 14, 14]       24,576</span><br><span class="line">  BatchNorm2D-131    [[1, 384, 14, 14]]    [1, 384, 14, 14]        1,536</span><br><span class="line">     ReLU6-17        [[1, 384, 14, 14]]    [1, 384, 14, 14]          0</span><br><span class="line">    Conv2D-185       [[1, 384, 14, 14]]    [1, 384, 14, 14]        3,456</span><br><span class="line">  BatchNorm2D-132    [[1, 384, 14, 14]]    [1, 384, 14, 14]        1,536</span><br><span class="line">     ReLU6-18        [[1, 384, 14, 14]]    [1, 384, 14, 14]          0</span><br><span class="line">    Conv2D-186       [[1, 384, 14, 14]]    [1, 64, 14, 14]        24,576</span><br><span class="line">  BatchNorm2D-133    [[1, 64, 14, 14]]     [1, 64, 14, 14]          256</span><br><span class="line">InvertedResidual-9   [[1, 64, 14, 14]]     [1, 64, 14, 14]           0</span><br><span class="line">    Conv2D-187       [[1, 64, 14, 14]]     [1, 384, 14, 14]       24,576</span><br><span class="line">  BatchNorm2D-134    [[1, 384, 14, 14]]    [1, 384, 14, 14]        1,536</span><br><span class="line">     ReLU6-19        [[1, 384, 14, 14]]    [1, 384, 14, 14]          0</span><br><span class="line">    Conv2D-188       [[1, 384, 14, 14]]    [1, 384, 14, 14]        3,456</span><br><span class="line">  BatchNorm2D-135    [[1, 384, 14, 14]]    [1, 384, 14, 14]        1,536</span><br><span class="line">     ReLU6-20        [[1, 384, 14, 14]]    [1, 384, 14, 14]          0</span><br><span class="line">    Conv2D-189       [[1, 384, 14, 14]]    [1, 64, 14, 14]        24,576</span><br><span class="line">  BatchNorm2D-136    [[1, 64, 14, 14]]     [1, 64, 14, 14]          256</span><br><span class="line">InvertedResidual-10  [[1, 64, 14, 14]]     [1, 64, 14, 14]           0</span><br><span class="line">    Conv2D-190       [[1, 64, 14, 14]]     [1, 384, 14, 14]       24,576</span><br><span class="line">  BatchNorm2D-137    [[1, 384, 14, 14]]    [1, 384, 14, 14]        1,536</span><br><span class="line">     ReLU6-21        [[1, 384, 14, 14]]    [1, 384, 14, 14]          0</span><br><span class="line">    Conv2D-191       [[1, 384, 14, 14]]    [1, 384, 14, 14]        3,456</span><br><span class="line">  BatchNorm2D-138    [[1, 384, 14, 14]]    [1, 384, 14, 14]        1,536</span><br><span class="line">     ReLU6-22        [[1, 384, 14, 14]]    [1, 384, 14, 14]          0</span><br><span class="line">    Conv2D-192       [[1, 384, 14, 14]]    [1, 96, 14, 14]        36,864</span><br><span class="line">  BatchNorm2D-139    [[1, 96, 14, 14]]     [1, 96, 14, 14]          384</span><br><span class="line">InvertedResidual-11  [[1, 64, 14, 14]]     [1, 96, 14, 14]           0</span><br><span class="line">    Conv2D-193       [[1, 96, 14, 14]]     [1, 576, 14, 14]       55,296</span><br><span class="line">  BatchNorm2D-140    [[1, 576, 14, 14]]    [1, 576, 14, 14]        2,304</span><br><span class="line">     ReLU6-23        [[1, 576, 14, 14]]    [1, 576, 14, 14]          0</span><br><span class="line">    Conv2D-194       [[1, 576, 14, 14]]    [1, 576, 14, 14]        5,184</span><br><span class="line">  BatchNorm2D-141    [[1, 576, 14, 14]]    [1, 576, 14, 14]        2,304</span><br><span class="line">     ReLU6-24        [[1, 576, 14, 14]]    [1, 576, 14, 14]          0</span><br><span class="line">    Conv2D-195       [[1, 576, 14, 14]]    [1, 96, 14, 14]        55,296</span><br><span class="line">  BatchNorm2D-142    [[1, 96, 14, 14]]     [1, 96, 14, 14]          384</span><br><span class="line">InvertedResidual-12  [[1, 96, 14, 14]]     [1, 96, 14, 14]           0</span><br><span class="line">    Conv2D-196       [[1, 96, 14, 14]]     [1, 576, 14, 14]       55,296</span><br><span class="line">  BatchNorm2D-143    [[1, 576, 14, 14]]    [1, 576, 14, 14]        2,304</span><br><span class="line">     ReLU6-25        [[1, 576, 14, 14]]    [1, 576, 14, 14]          0</span><br><span class="line">    Conv2D-197       [[1, 576, 14, 14]]    [1, 576, 14, 14]        5,184</span><br><span class="line">  BatchNorm2D-144    [[1, 576, 14, 14]]    [1, 576, 14, 14]        2,304</span><br><span class="line">     ReLU6-26        [[1, 576, 14, 14]]    [1, 576, 14, 14]          0</span><br><span class="line">    Conv2D-198       [[1, 576, 14, 14]]    [1, 96, 14, 14]        55,296</span><br><span class="line">  BatchNorm2D-145    [[1, 96, 14, 14]]     [1, 96, 14, 14]          384</span><br><span class="line">InvertedResidual-13  [[1, 96, 14, 14]]     [1, 96, 14, 14]           0</span><br><span class="line">    Conv2D-199       [[1, 96, 14, 14]]     [1, 576, 14, 14]       55,296</span><br><span class="line">  BatchNorm2D-146    [[1, 576, 14, 14]]    [1, 576, 14, 14]        2,304</span><br><span class="line">     ReLU6-27        [[1, 576, 14, 14]]    [1, 576, 14, 14]          0</span><br><span class="line">    Conv2D-200       [[1, 576, 14, 14]]     [1, 576, 7, 7]         5,184</span><br><span class="line">  BatchNorm2D-147     [[1, 576, 7, 7]]      [1, 576, 7, 7]         2,304</span><br><span class="line">     ReLU6-28         [[1, 576, 7, 7]]      [1, 576, 7, 7]           0</span><br><span class="line">    Conv2D-201        [[1, 576, 7, 7]]      [1, 160, 7, 7]        92,160</span><br><span class="line">  BatchNorm2D-148     [[1, 160, 7, 7]]      [1, 160, 7, 7]          640</span><br><span class="line">InvertedResidual-14  [[1, 96, 14, 14]]      [1, 160, 7, 7]           0</span><br><span class="line">    Conv2D-202        [[1, 160, 7, 7]]      [1, 960, 7, 7]        153,600</span><br><span class="line">  BatchNorm2D-149     [[1, 960, 7, 7]]      [1, 960, 7, 7]         3,840</span><br><span class="line">     ReLU6-29         [[1, 960, 7, 7]]      [1, 960, 7, 7]           0</span><br><span class="line">    Conv2D-203        [[1, 960, 7, 7]]      [1, 960, 7, 7]         8,640</span><br><span class="line">  BatchNorm2D-150     [[1, 960, 7, 7]]      [1, 960, 7, 7]         3,840</span><br><span class="line">     ReLU6-30         [[1, 960, 7, 7]]      [1, 960, 7, 7]           0</span><br><span class="line">    Conv2D-204        [[1, 960, 7, 7]]      [1, 160, 7, 7]        153,600</span><br><span class="line">  BatchNorm2D-151     [[1, 160, 7, 7]]      [1, 160, 7, 7]          640</span><br><span class="line">InvertedResidual-15   [[1, 160, 7, 7]]      [1, 160, 7, 7]           0</span><br><span class="line">    Conv2D-205        [[1, 160, 7, 7]]      [1, 960, 7, 7]        153,600</span><br><span class="line">  BatchNorm2D-152     [[1, 960, 7, 7]]      [1, 960, 7, 7]         3,840</span><br><span class="line">     ReLU6-31         [[1, 960, 7, 7]]      [1, 960, 7, 7]           0</span><br><span class="line">    Conv2D-206        [[1, 960, 7, 7]]      [1, 960, 7, 7]         8,640</span><br><span class="line">  BatchNorm2D-153     [[1, 960, 7, 7]]      [1, 960, 7, 7]         3,840</span><br><span class="line">     ReLU6-32         [[1, 960, 7, 7]]      [1, 960, 7, 7]           0</span><br><span class="line">    Conv2D-207        [[1, 960, 7, 7]]      [1, 160, 7, 7]        153,600</span><br><span class="line">  BatchNorm2D-154     [[1, 160, 7, 7]]      [1, 160, 7, 7]          640</span><br><span class="line">InvertedResidual-16   [[1, 160, 7, 7]]      [1, 160, 7, 7]           0</span><br><span class="line">    Conv2D-208        [[1, 160, 7, 7]]      [1, 960, 7, 7]        153,600</span><br><span class="line">  BatchNorm2D-155     [[1, 960, 7, 7]]      [1, 960, 7, 7]         3,840</span><br><span class="line">     ReLU6-33         [[1, 960, 7, 7]]      [1, 960, 7, 7]           0</span><br><span class="line">    Conv2D-209        [[1, 960, 7, 7]]      [1, 960, 7, 7]         8,640</span><br><span class="line">  BatchNorm2D-156     [[1, 960, 7, 7]]      [1, 960, 7, 7]         3,840</span><br><span class="line">     ReLU6-34         [[1, 960, 7, 7]]      [1, 960, 7, 7]           0</span><br><span class="line">    Conv2D-210        [[1, 960, 7, 7]]      [1, 320, 7, 7]        307,200</span><br><span class="line">  BatchNorm2D-157     [[1, 320, 7, 7]]      [1, 320, 7, 7]         1,280</span><br><span class="line">InvertedResidual-17   [[1, 160, 7, 7]]      [1, 320, 7, 7]           0</span><br><span class="line">    Conv2D-211        [[1, 320, 7, 7]]     [1, 1280, 7, 7]        409,600</span><br><span class="line">  BatchNorm2D-158    [[1, 1280, 7, 7]]     [1, 1280, 7, 7]         5,120</span><br><span class="line">     ReLU6-35        [[1, 1280, 7, 7]]     [1, 1280, 7, 7]           0</span><br><span class="line">AdaptiveAvgPool2D-3  [[1, 1280, 7, 7]]     [1, 1280, 1, 1]           0</span><br><span class="line">     Dropout-1          [[1, 1280]]           [1, 1280]              0</span><br><span class="line">     Linear-4           [[1, 1280]]            [1, 12]            15,372</span><br><span class="line">===============================================================================</span><br><span class="line">Total params: 2,273,356</span><br><span class="line">Trainable params: 2,205,132</span><br><span class="line">Non-trainable params: 68,224</span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">Input size (MB): 0.57</span><br><span class="line">Forward/backward pass size (MB): 152.87</span><br><span class="line">Params size (MB): 8.67</span><br><span class="line">Estimated Total Size (MB): 162.12</span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;&#x27;total_params&#x27;: 2273356, &#x27;trainable_params&#x27;: 2205132&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">EPOCHS = <span class="number">10</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 请补齐模型训练过程代码</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练配置</span></span><br><span class="line">model_lite.prepare(paddle.optimizer.Adam(learning_rate=<span class="number">0.0001</span>, parameters=model_lite.parameters()),  <span class="comment"># 优化器</span></span><br><span class="line">              paddle.nn.CrossEntropyLoss(),        <span class="comment"># 损失函数</span></span><br><span class="line">              paddle.metric.Accuracy(topk=(<span class="number">1</span>, <span class="number">5</span>))) <span class="comment"># 评估指标</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练可视化VisualDL工具的回调函数</span></span><br><span class="line">visualdl = paddle.callbacks.VisualDL(log_dir=<span class="string">&#x27;./mobilenet/visualdl_log&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动模型全流程训练</span></span><br><span class="line">model_lite.fit( train_dataset,            <span class="comment"># 训练数据集</span></span><br><span class="line">                valid_dataset,            <span class="comment"># 评估数据集</span></span><br><span class="line">                epochs=EPOCHS,            <span class="comment"># 总的训练轮次</span></span><br><span class="line">                batch_size=BATCH_SIZE,    <span class="comment"># 批次计算的样本量大小</span></span><br><span class="line">                shuffle=<span class="literal">True</span>,             <span class="comment"># 是否打乱样本集</span></span><br><span class="line">                verbose=<span class="number">1</span>,                <span class="comment"># 日志展示格式</span></span><br><span class="line">                save_dir=<span class="string">&#x27;./mobilenet/chk_points/&#x27;</span>, <span class="comment"># 分阶段的训练模型存储路径</span></span><br><span class="line">                callbacks=[visualdl])     <span class="comment"># 回调函数使用</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">The loss value printed in the log is the current step, and the metric is the average value of previous step.</span><br><span class="line">Epoch 1/10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:636: UserWarning: When training, we now always track global mean and variance.</span><br><span class="line">  &quot;When training, we now always track global mean and variance.&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">step 222/222 [==============================] - loss: 0.2848 - acc_top1: 0.8271 - acc_top5: 0.9762 - 690ms/step</span><br><span class="line">save checkpoint at /home/aistudio/mobilenet/chk_points/0</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.5077 - acc_top1: 0.9124 - acc_top5: 0.9906 - 803ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 2/10</span><br><span class="line">step 222/222 [==============================] - loss: 0.2549 - acc_top1: 0.8541 - acc_top5: 0.9800 - 689ms/step</span><br><span class="line">save checkpoint at /home/aistudio/mobilenet/chk_points/1</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.3955 - acc_top1: 0.9218 - acc_top5: 0.9937 - 813ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 3/10</span><br><span class="line">step 222/222 [==============================] - loss: 0.3388 - acc_top1: 0.8660 - acc_top5: 0.9842 - 693ms/step</span><br><span class="line">save checkpoint at /home/aistudio/mobilenet/chk_points/2</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.2251 - acc_top1: 0.9390 - acc_top5: 0.9937 - 817ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 4/10</span><br><span class="line">step 222/222 [==============================] - loss: 0.6369 - acc_top1: 0.8773 - acc_top5: 0.9845 - 688ms/step</span><br><span class="line">save checkpoint at /home/aistudio/mobilenet/chk_points/3</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.3293 - acc_top1: 0.9311 - acc_top5: 0.9937 - 813ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 5/10</span><br><span class="line">step 222/222 [==============================] - loss: 0.4066 - acc_top1: 0.8908 - acc_top5: 0.9872 - 696ms/step</span><br><span class="line">save checkpoint at /home/aistudio/mobilenet/chk_points/4</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.2782 - acc_top1: 0.9343 - acc_top5: 0.9937 - 808ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 6/10</span><br><span class="line">step 222/222 [==============================] - loss: 0.3100 - acc_top1: 0.8961 - acc_top5: 0.9876 - 686ms/step</span><br><span class="line">save checkpoint at /home/aistudio/mobilenet/chk_points/5</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.4607 - acc_top1: 0.9390 - acc_top5: 0.9937 - 810ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 7/10</span><br><span class="line">step 222/222 [==============================] - loss: 0.1829 - acc_top1: 0.9016 - acc_top5: 0.9887 - 688ms/step</span><br><span class="line">save checkpoint at /home/aistudio/mobilenet/chk_points/6</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.3421 - acc_top1: 0.9264 - acc_top5: 0.9969 - 815ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 8/10</span><br><span class="line">step 222/222 [==============================] - loss: 0.4560 - acc_top1: 0.8932 - acc_top5: 0.9870 - 688ms/step</span><br><span class="line">save checkpoint at /home/aistudio/mobilenet/chk_points/7</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.1464 - acc_top1: 0.9343 - acc_top5: 0.9922 - 830ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 9/10</span><br><span class="line">step 222/222 [==============================] - loss: 0.4075 - acc_top1: 0.9040 - acc_top5: 0.9873 - 686ms/step</span><br><span class="line">save checkpoint at /home/aistudio/mobilenet/chk_points/8</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.5118 - acc_top1: 0.9468 - acc_top5: 0.9953 - 820ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">Epoch 10/10</span><br><span class="line">step 222/222 [==============================] - loss: 0.0882 - acc_top1: 0.9094 - acc_top5: 0.9866 - 686ms/step</span><br><span class="line">save checkpoint at /home/aistudio/mobilenet/chk_points/9</span><br><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 20/20 [==============================] - loss: 0.1651 - acc_top1: 0.9468 - acc_top5: 0.9953 - 821ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">save checkpoint at /home/aistudio/mobilenet/chk_points/final</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">KeyError                                  Traceback (most recent call last)</span><br><span class="line"></span><br><span class="line">&lt;ipython-input-49-266b4a21aaf0&gt; in &lt;module&gt;</span><br><span class="line">     23                 callbacks=[visualdl])     # 回调函数使用</span><br><span class="line">     24</span><br><span class="line">---&gt; 25 model.save(get(&#x27;./mobilenet/model&#x27;))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">~/config.py in get(full_path)</span><br><span class="line">     43             config = CONFIG</span><br><span class="line">     44</span><br><span class="line">---&gt; 45         config = config[name]</span><br><span class="line">     46</span><br><span class="line">     47     return config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">KeyError: &#x27;&#x27;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.save(<span class="string">&#x27;./mobilenet/model&#x27;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line">val = model_lite.evaluate(valid_dataset, verbose=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(val)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Eval begin...</span><br><span class="line">The loss value printed in the log is the current batch, and the metric is the average value of previous step.</span><br><span class="line">step 639/639 [==============================] - loss: 1.0871e-04 - acc_top1: 0.9374 - acc_top5: 0.9890 - 46ms/step</span><br><span class="line">Eval samples: 639</span><br><span class="line">&#123;&#x27;loss&#x27;: [0.000108712964], &#x27;acc_top1&#x27;: 0.9374021909233177, &#x27;acc_top5&#x27;: 0.9890453834115805&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 执行预测</span></span><br><span class="line">pred = model_lite.predict(predict_dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 样本映射</span></span><br><span class="line">LABEL_MAP = get(<span class="string">&#x27;LABEL_MAP&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机取样本展示</span></span><br><span class="line">indexs = np.random.randint(<span class="number">1</span>, <span class="number">646</span>, size=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> indexs:</span><br><span class="line">    predict_label = np.argmax(pred[<span class="number">0</span>][idx])</span><br><span class="line">    real_label = predict_dataset[idx][<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    real_label = predict_dataset[idx][<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;样本ID：&#123;&#125;, 真实标签：&#123;&#125;, 预测值：&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(idx, LABEL_MAP[real_label], LABEL_MAP[predict_label]))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Predict begin...</span><br><span class="line">step 646/646 [==============================] - 42ms/step</span><br><span class="line">Predict samples: 646</span><br><span class="line">样本ID：611, 真实标签：ratt, 预测值：dragon</span><br><span class="line">样本ID：42, 真实标签：rooster, 预测值：dragon</span><br><span class="line">样本ID：11, 真实标签：rooster, 预测值：rooster</span><br><span class="line">样本ID：625, 真实标签：ratt, 预测值：ratt</span><br><span class="line">样本ID：263, 真实标签：goat, 预测值：goat</span><br><span class="line">样本ID：635, 真实标签：ratt, 预测值：ratt</span><br><span class="line">样本ID：78, 真实标签：dragon, 预测值：dragon</span><br><span class="line">样本ID：567, 真实标签：ox, 预测值：ox</span><br><span class="line">样本ID：280, 真实标签：horse, 预测值：horse</span><br><span class="line">样本ID：406, 真实标签：pig, 预测值：pig</span><br><span class="line">样本ID：167, 真实标签：snake, 预测值：snake</span><br><span class="line">样本ID：19, 真实标签：rooster, 预测值：rooster</span><br><span class="line">样本ID：41, 真实标签：rooster, 预测值：rooster</span><br><span class="line">样本ID：406, 真实标签：pig, 预测值：pig</span><br><span class="line">样本ID：497, 真实标签：rabbit, 预测值：rabbit</span><br><span class="line">样本ID：71, 真实标签：dragon, 预测值：dragon</span><br><span class="line">样本ID：300, 真实标签：horse, 预测值：horse</span><br><span class="line">样本ID：247, 真实标签：goat, 预测值：goat</span><br><span class="line">样本ID：450, 真实标签：tiger, 预测值：tiger</span><br><span class="line">样本ID：82, 真实标签：dragon, 预测值：dragon</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="http://example.com">YUAN Tingyi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2022/06/01/1a54430645484c2dbe7ec9d538ede221/">http://example.com/2022/06/01/1a54430645484c2dbe7ec9d538ede221/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/5.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/gh/overtrue/share.js@master/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/06/01/24aa2ecdd35b4df9b7f071254f4fb025/"><img class="prev-cover" src="/img/3.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">paddle2.0实现DNN（minst数据集）</div></div></a></div><div class="next-post pull-right"><a href="/2022/06/01/234b53c9dbdf4d4595e8b9f095173105/"><img class="next-cover" src="/img/7.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">paddle2.0高层API实现自定义数据集文本分类中的情感分析任务</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">YUAN Tingyi</div><div class="author-info__description">XianrenYty</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">28</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/XianrenYty"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E2%91%A0-%E9%97%AE%E9%A2%98%E5%AE%9A%E4%B9%89"><span class="toc-number">1.</span> <span class="toc-text">① 问题定义</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E2%91%A1-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87"><span class="toc-number">2.</span> <span class="toc-text">② 数据准备</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-%E8%A7%A3%E5%8E%8B%E7%BC%A9%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 解压缩数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-%E6%95%B0%E6%8D%AE%E6%A0%87%E6%B3%A8"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 数据标注</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%AE%9A%E4%B9%89"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 数据集定义</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-1-%E5%AF%BC%E5%85%A5%E7%9B%B8%E5%85%B3%E5%BA%93"><span class="toc-number">2.3.1.</span> <span class="toc-text">2.3.1 导入相关库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-2-%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%AE%9A%E4%B9%89%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.3.2.</span> <span class="toc-text">2.3.2 导入数据集的定义实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-3-%E5%AE%9E%E4%BE%8B%E5%8C%96%E6%95%B0%E6%8D%AE%E9%9B%86%E7%B1%BB"><span class="toc-number">2.3.3.</span> <span class="toc-text">2.3.3 实例化数据集类</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E2%91%A2-%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E5%BC%80%E5%8F%91"><span class="toc-number">3.</span> <span class="toc-text">③ 模型选择和开发</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-%E7%BD%91%E7%BB%9C%E6%9E%84%E5%BB%BA"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 网络构建</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE"><span class="toc-number">3.2.</span> <span class="toc-text">超参数配置</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E2%91%A3-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%92%8C%E4%BC%98%E5%8C%96"><span class="toc-number">4.</span> <span class="toc-text">④ 模型训练和优化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#VisualDL-%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B1%95%E7%A4%BA"><span class="toc-number">4.1.</span> <span class="toc-text">VisualDL 训练过程可视化展示</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%AD%98%E5%82%A8"><span class="toc-number">4.1.1.</span> <span class="toc-text">模型存储</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E2%91%A4-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E5%92%8C%E6%B5%8B%E8%AF%95"><span class="toc-number">5.</span> <span class="toc-text">⑤ 模型评估和测试</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-%E6%89%B9%E9%87%8F%E9%A2%84%E6%B5%8B%E6%B5%8B%E8%AF%95"><span class="toc-number">5.1.</span> <span class="toc-text">5.1 批量预测测试</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-1-%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">5.1.1.</span> <span class="toc-text">5.1.1 测试数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-2-%E6%89%A7%E8%A1%8C%E9%A2%84%E6%B5%8B"><span class="toc-number">5.1.2.</span> <span class="toc-text">5.1.2 执行预测</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E2%91%A5-%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2"><span class="toc-number">6.</span> <span class="toc-text">⑥ 模型部署</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#MobileNet-V2-%E6%B5%8B%E8%AF%95"><span class="toc-number">6.1.</span> <span class="toc-text">MobileNet_V2 测试</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/06/01/fd61228310d24c999c625f49b503f7ce/" title="train_test_split 参数详解"><img src="/img/8.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="train_test_split 参数详解"/></a><div class="content"><a class="title" href="/2022/06/01/fd61228310d24c999c625f49b503f7ce/" title="train_test_split 参数详解">train_test_split 参数详解</a><time datetime="2022-06-01T12:52:00.000Z" title="Created 2022-06-01 20:52:00">2022-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/01/224bdd4444be4fe0b7826959bc6b40a4/" title="StandardScaler(sklearn)参数详解"><img src="/img/8.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="StandardScaler(sklearn)参数详解"/></a><div class="content"><a class="title" href="/2022/06/01/224bdd4444be4fe0b7826959bc6b40a4/" title="StandardScaler(sklearn)参数详解">StandardScaler(sklearn)参数详解</a><time datetime="2022-06-01T12:51:39.966Z" title="Created 2022-06-01 20:51:39">2022-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/01/2fd9e712ce6b4a49a24775586e47e44b/" title="八大排序算法(Python实现)"><img src="/img/5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="八大排序算法(Python实现)"/></a><div class="content"><a class="title" href="/2022/06/01/2fd9e712ce6b4a49a24775586e47e44b/" title="八大排序算法(Python实现)">八大排序算法(Python实现)</a><time datetime="2022-06-01T12:51:26.086Z" title="Created 2022-06-01 20:51:26">2022-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/01/9d8547900901416593ba964e6757c6c3/" title="ResNet"><img src="/img/9.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ResNet"/></a><div class="content"><a class="title" href="/2022/06/01/9d8547900901416593ba964e6757c6c3/" title="ResNet">ResNet</a><time datetime="2022-06-01T12:50:56.055Z" title="Created 2022-06-01 20:50:56">2022-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/01/b6a6cbce3d7f45a8b2511edf86fb5a24/" title="Paddle高层API实现图像分类（CIFAR-100数据集_ResNet101）"><img src="/img/5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Paddle高层API实现图像分类（CIFAR-100数据集_ResNet101）"/></a><div class="content"><a class="title" href="/2022/06/01/b6a6cbce3d7f45a8b2511edf86fb5a24/" title="Paddle高层API实现图像分类（CIFAR-100数据集_ResNet101）">Paddle高层API实现图像分类（CIFAR-100数据集_ResNet101）</a><time datetime="2022-06-01T12:48:23.363Z" title="Created 2022-06-01 20:48:23">2022-06-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By YUAN Tingyi</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>